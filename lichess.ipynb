{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ-ApUtIwHXG"
      },
      "source": [
        "# Projet Lichess\n",
        "\n",
        "_Traitements et données large échelle_\n",
        "\n",
        "Zoé Marquis & Charlotte Kruzic"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "14ofXS5A2ozH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'**objectif** de ce projet était d’explorer et d’analyser un ensemble de données provenant de LiChess, une plateforme d’échecs en ligne open-source qui accueille quotidiennement des millions de joueurs de tous niveaux, et qui publie les parties jouées et annotées par le moteur d’échecs Stockfish.\n",
        "\n",
        "Nous avons utilisé ces **données** pour réaliser ce projet, plus particulièrement les parties jouées en septembre 2020, disponible sur [Kaggle](https://www.kaggle.com/datasets/noobiedatascientist/lichess-september-2020-data \"Lichess September 2020 data\").\n",
        "\n",
        "Ce jeu de données contenant environ 3.74 millions de parties et 40 colonnes décrivant différents éléments des parties d'échecs (indicateurs de niveau, type de partie, ouvertures, erreurs...), nous avons utilisé Spark, un outil de traitement de données large échelle.\n",
        "\n",
        "Nous avons commencé par répondre aux **troix questions** principales du projet en utilisant ces données, et avons donc analysé les erreurs par catégorie ELO dans les parties Blitz, calculé la probabilité de victoire en fonction de l'ouverture, et cherché à prédire le résultat d'une partie.\n",
        "\n",
        "Enfin, nous avons élargi notre analyse en répondant à des **questions supplémentaires** notamment l'impact des ouvertures jouées sur les matchs nuls, la relation entre l'ELO et la durée d'une partie.\n",
        "\n",
        "Les analyses réalisées dans ce projet ont permis de répondre aux questions principales tout en ouvrant des perspectives intéressantes grâce aux analyses supplémentaires. Les résultats obtenus sont accompagnés de visualisations et d’interprétations détaillées, afin d'avoir une meilleure compréhension des dynamiques des parties sur LiChess."
      ],
      "metadata": {
        "id": "Dtr_LoBx2vS7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoCDA5c1McJt"
      },
      "source": [
        "## Installation et importation des bibliothèques nécessaires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLQJBvTu1Ln_",
        "outputId": "fa39fe69-966f-4251-c5e7-2480aaef61ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (0.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2024.12.14)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIoRHOnTSqmt"
      },
      "outputs": [],
      "source": [
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKCU055GLlsg"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Fq95N2B0pm8"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import os\n",
        "import kagglehub\n",
        "from collections import defaultdict\n",
        "\n",
        "import findspark\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6v1hNJRbMmTS"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.3-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXe-TNDn4Seo"
      },
      "outputs": [],
      "source": [
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.3-bin-hadoop3\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoOwUYVF0r4O"
      },
      "source": [
        "## Préparation des données et de l'environnement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqCvyHSnQMdZ"
      },
      "source": [
        "Nous commençons par charger les données depuis Kaggle, puis nous faisons une analyse exploratoire et prétraitons les données afin d'avoir une base pour nos analyses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so3fXjziQNRq"
      },
      "source": [
        "### Chargement des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dD1y9b60pkk"
      },
      "outputs": [],
      "source": [
        "path = kagglehub.dataset_download(\"noobiedatascientist/lichess-september-2020-data\")\n",
        "print(\"Chemin vers le fichier du dataset : \", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoMmOHTH0pf_"
      },
      "outputs": [],
      "source": [
        "files = os.listdir(path)\n",
        "print(\"Fichiers du dataset : \", files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-C_Fv81N0pbO"
      },
      "outputs": [],
      "source": [
        "filename = f\"{path}/Sept_20_analysis.csv\"\n",
        "print(\"Nom du fichier : \", filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj58yVL60pPQ"
      },
      "outputs": [],
      "source": [
        "# voir le contenu du .txt\n",
        "filename_txt = f\"{path}/Column information.txt\"\n",
        "with open(filename_txt, 'r') as f:\n",
        "    print(f.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHbCTsTR4S6e"
      },
      "source": [
        "### Lancement de Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiPqfPJdY4Lx"
      },
      "outputs": [],
      "source": [
        "# Imports des éléments Spark\n",
        "from pyspark.sql.functions import col, when, isnull, floor, count, min as spark_min, max as spark_max\n",
        "from pyspark.sql.functions import countDistinct, row_number, split, concat_ws, sum as spark_sum, rank\n",
        "from pyspark.ml.functions import vector_to_array\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, MinMaxScaler, StandardScaler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.stat import Correlation, ChiSquareTest\n",
        "from pyspark.ml import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEcWzry24SZ4"
      },
      "outputs": [],
      "source": [
        "findspark.init()\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQTMYx5g4SXb"
      },
      "outputs": [],
      "source": [
        "sc = spark.sparkContext\n",
        "df_spark = spark.read.csv(filename, header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KMIg7qx4ihe"
      },
      "outputs": [],
      "source": [
        "df_spark.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrCaCyNT_rtu"
      },
      "outputs": [],
      "source": [
        "# nombre lignes\n",
        "df_spark.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiSTXCRS4ife"
      },
      "outputs": [],
      "source": [
        "df_spark.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAcsmDlTdOWG"
      },
      "source": [
        "### Préparation générale des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSIXOGwkSCg0"
      },
      "source": [
        "Maintenant que les données sont chargées, nous y ajoutons les catégories ELO basées sur les plages données dans l'énoncé du projet.\n",
        "\n",
        "En plus des 5 catégories définies dans l'énoncé, nous ajoutons \"other lower bound\" et \"other upper bound\" pour les valeurs ELO hors des plages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o89yf5WEXwQT"
      },
      "source": [
        "#### Calcule des catégories ELO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypAzl9Gh6iWY"
      },
      "outputs": [],
      "source": [
        "# Ajout des catégories ELO\n",
        "# Catégorie ELO du joueur Noir\n",
        "df_spark_plus = df_spark.withColumn(\"Black_ELO_category\",\n",
        "                              when((col(\"BlackElo\") >= 1200) & (col(\"BlackElo\") <= 1499), \"occasional player\")\n",
        "                              .when((col(\"BlackElo\") >= 1500) & (col(\"BlackElo\") <= 1799), \"good club player\")\n",
        "                              .when((col(\"BlackElo\") >= 1800) & (col(\"BlackElo\") <= 1999), \"very good club player\")\n",
        "                              .when((col(\"BlackElo\") >= 2000) & (col(\"BlackElo\") <= 2399), \"national and international level\")\n",
        "                              .when((col(\"BlackElo\") >= 2400) & (col(\"BlackElo\") <= 2800), \"GMI, World Champions\")\n",
        "                              .when((col(\"BlackElo\") < 1200), \"other lower bound\")\n",
        "                              .otherwise(\"other upper bound\")\n",
        "                              )\n",
        "\n",
        "# Catégorie ELO du joueur Blanc\n",
        "df_spark_plus = df_spark_plus.withColumn(\"White_ELO_category\",\n",
        "                              when((col(\"WhiteElo\") >= 1200) & (col(\"WhiteElo\") <= 1499), \"occasional player\")\n",
        "                              .when((col(\"WhiteElo\") >= 1500) & (col(\"WhiteElo\") <= 1799), \"good club player\")\n",
        "                              .when((col(\"WhiteElo\") >= 1800) & (col(\"WhiteElo\") <= 1999), \"very good club player\")\n",
        "                              .when((col(\"WhiteElo\") >= 2000) & (col(\"WhiteElo\") <= 2399), \"national and international level\")\n",
        "                              .when((col(\"WhiteElo\") >= 2400) & (col(\"WhiteElo\") <= 2800), \"GMI, World Champions\")\n",
        "                              .when((col(\"WhiteElo\") < 1200), \"other lower bound\")\n",
        "                              .otherwise(\"other upper bound\")\n",
        "                              )\n",
        "\n",
        "# Catégorie ELO moyenne des 2 joueurs\n",
        "df_spark_plus = df_spark_plus.withColumn(\"Avg_ELO_category\", (col(\"BlackElo\") + col(\"WhiteElo\")) / 2)\n",
        "\n",
        "df_spark_plus = df_spark_plus.withColumn(\"Avg_ELO_category\",\n",
        "                              when((col(\"Avg_ELO_category\") >= 1200) & (col(\"Avg_ELO_category\") <= 1499), \"occasional player\")\n",
        "                              .when((col(\"Avg_ELO_category\") >= 1500) & (col(\"Avg_ELO_category\") <= 1799), \"good club player\")\n",
        "                              .when((col(\"Avg_ELO_category\") >= 1800) & (col(\"Avg_ELO_category\") <= 1999), \"very good club player\")\n",
        "                              .when((col(\"Avg_ELO_category\") >= 2000) & (col(\"Avg_ELO_category\") <= 2399), \"national and international level\")\n",
        "                              .when((col(\"Avg_ELO_category\") >= 2400) & (col(\"Avg_ELO_category\") <= 2800), \"GMI, World Champions\")\n",
        "                              .when((col(\"Avg_ELO_category\") < 1200), \"other lower bound\")\n",
        "                              .otherwise(\"other upper bound\")\n",
        "                              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdeN_nAW6iUQ"
      },
      "outputs": [],
      "source": [
        "# vérifier combien de \"other ...\"\n",
        "other_lower_bound_black = df_spark_plus.filter(col(\"Black_ELO_category\") == \"other lower bound\").count()\n",
        "other_lower_bound_white = df_spark_plus.filter(col(\"White_ELO_category\") == \"other lower bound\").count()\n",
        "other_upper_bound_black = df_spark_plus.filter(col(\"Black_ELO_category\") == \"other upper bound\").count()\n",
        "other_upper_bound_white = df_spark_plus.filter(col(\"White_ELO_category\") == \"other upper bound\").count()\n",
        "print(f\"Nombre de parties avec other lower bound pour le joueur noir : {other_lower_bound_black}\")\n",
        "print(f\"Nombre de parties avec other lower bound pour le joueur blanc : {other_lower_bound_white}\")\n",
        "print(f\"Nombre de parties avec other upper bound pour le joueur noir : {other_upper_bound_black}\")\n",
        "print(f\"Nombre de parties avec other upper bound pour le joueur blanc : {other_upper_bound_white}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFVmQEXcF2ep"
      },
      "outputs": [],
      "source": [
        "# répartition du nombre de parties pour avg\n",
        "avg_other_lower_bound = df_spark_plus.filter(col(\"Avg_ELO_category\") == \"other lower bound\").count()\n",
        "avg_occasional_player = df_spark_plus.filter(col(\"Avg_ELO_category\") == \"occasional player\").count()\n",
        "avg_good_club_player = df_spark_plus.filter(col(\"Avg_ELO_category\") == \"good club player\").count()\n",
        "avg_very_good_club_player = df_spark_plus.filter(col(\"Avg_ELO_category\") == \"very good club player\").count()\n",
        "avg_national_international_level = df_spark_plus.filter(col(\"Avg_ELO_category\") == \"national and international level\").count()\n",
        "avg_GMI_World_Champions = df_spark_plus.filter(col(\"Avg_ELO_category\") == \"GMI, World Champions\").count()\n",
        "avg_other_upper_bound = df_spark_plus.filter(col(\"Avg_ELO_category\") == \"other upper bound\").count()\n",
        "\n",
        "# répartition du nombre de parties quand les 2 joueurs sont dans la même catégorie\n",
        "same_player_other_lower_bound = df_spark_plus.filter((col(\"Black_ELO_category\") == \"other lower bound\") & (col(\"White_ELO_category\") == \"other lower bound\")).count()\n",
        "same_player_occasional_player = df_spark_plus.filter((col(\"Black_ELO_category\") == \"occasional player\") & (col(\"White_ELO_category\") == \"occasional player\")).count()\n",
        "same_player_good_club_player = df_spark_plus.filter((col(\"Black_ELO_category\") == \"good club player\") & (col(\"White_ELO_category\") == \"good club player\")).count()\n",
        "same_player_very_good_club_player = df_spark_plus.filter((col(\"Black_ELO_category\") == \"very good club player\") & (col(\"White_ELO_category\") == \"very good club player\")).count()\n",
        "same_player_national_international_level = df_spark_plus.filter((col(\"Black_ELO_category\") == \"national and international level\") & (col(\"White_ELO_category\") == \"national and international level\")).count()\n",
        "same_player_GMI_World_Champions = df_spark_plus.filter((col(\"Black_ELO_category\") == \"GMI, World Champions\") & (col(\"White_ELO_category\") == \"GMI, World Champions\")).count()\n",
        "same_player_other_upper_bound = df_spark_plus.filter((col(\"Black_ELO_category\") == \"other upper bound\") & (col(\"White_ELO_category\") == \"other upper bound\")).count()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzgBXJ82CU2G"
      },
      "outputs": [],
      "source": [
        "# Visualiser la répartition des catégories\n",
        "categories = [\n",
        "    \"other lower bound\", \"occasional player\", \"good club player\",\n",
        "    \"very good club player\", \"national and international level\", \"GMI, World Champions\",\n",
        "    \"other upper bound\"\n",
        "]\n",
        "avg_counts = [\n",
        "    avg_other_lower_bound, avg_occasional_player, avg_good_club_player,\n",
        "    avg_very_good_club_player, avg_national_international_level, avg_GMI_World_Champions,\n",
        "    avg_other_upper_bound\n",
        "]\n",
        "same_player_counts = [\n",
        "    same_player_other_lower_bound, same_player_occasional_player, same_player_good_club_player,\n",
        "    same_player_very_good_club_player, same_player_national_international_level, same_player_GMI_World_Champions,\n",
        "    same_player_other_upper_bound\n",
        "]\n",
        "\n",
        "df_counts = pd.DataFrame({\n",
        "    'Category': categories,\n",
        "    'Avg_ELO_category': avg_counts,\n",
        "    'Same_Player_ELO_category': same_player_counts\n",
        "})\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "df_counts.set_index('Category')[['Avg_ELO_category', 'Same_Player_ELO_category']].plot(kind='bar', ax=plt.gca(), color=['skyblue', 'lightcoral'])\n",
        "plt.xlabel('ELO Categories', fontsize=12)\n",
        "plt.ylabel('Number of Games', fontsize=12)\n",
        "plt.title('Répartition du nombre de parties pour chaque catégorie d\\'ELO', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend(['Avg ELO Category', 'Same Player ELO Category'])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoQZXsVnVaQm"
      },
      "source": [
        "La répartition des données, bien que déséquilibrée entre les catégories, semble réaliste.\n",
        "\n",
        "En effet, le nombre de parties avec des joueurs de niveaux intermédiaires est plus élevé, car ils représentent la plupart des joueurs actifs qui jouent régulièrement. Au contraire, le nombre de parties avec des joueurs ayant des niveaux extrêmes (faible ou élevé) est plus faible. Nous pouvons expliquer cela par le fait que les joueurs de bas niveau évoluent rapidement ou ne jouent pas beaucoup de parties, et les joueurs avec de hauts niveaux sont plus rares dû à la difficulté d'atteindre ces niveaux.\n",
        "\n",
        "Ce déséquilibre naturel pourrait introduire un biais dans l'analyse, car certaines catégories sont sur/sous-représentées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK1JnDk6MMqE"
      },
      "source": [
        "#### Récupérer le nombre de mouvements par joueur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wqo_RBUW7UzI"
      },
      "outputs": [],
      "source": [
        "# Compter le nombre de moves pour chaque joueur (c'est White qui commence)\n",
        "df_spark_plus = df_spark_plus.withColumn(\"white_moves\",\n",
        "                                         when(col(\"Total_moves\") % 2 == 0, col(\"Total_moves\") / 2)\n",
        "                                         .otherwise(floor(col(\"Total_moves\") / 2) + 1)\n",
        "                                         )\n",
        "df_spark_plus = df_spark_plus.withColumn(\"black_moves\",\n",
        "                                         when(col(\"Total_moves\") % 2 == 0, col(\"Total_moves\") / 2)\n",
        "                                         .otherwise(floor(col(\"Total_moves\") / 2))\n",
        "                                         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-NpaXh38W9m"
      },
      "outputs": [],
      "source": [
        "df_spark_plus.select(\"Total_moves\", \"white_moves\", \"black_moves\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rru1FJEWpR5f"
      },
      "source": [
        "#### Exploration des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nwC7P5S8x6B"
      },
      "source": [
        "##### **Valeurs NULL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGSVVh9i7llY"
      },
      "outputs": [],
      "source": [
        "# Calcule valeurs null par colonnes\n",
        "null_counts = df_spark.select(\n",
        "    *[\n",
        "        count(when(col(c).isNull(), c)).alias(c)\n",
        "        for c in df_spark.columns\n",
        "    ]\n",
        ")\n",
        "\n",
        "null_counts.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxLZyOkVNiMc"
      },
      "source": [
        "##### **Colonnes Opening et ECO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41P8vKRnZ6kH"
      },
      "source": [
        "Les colonnes \"Opening\" et \"ECO\" correspondent aux ouvertures et aux codes d'ouvertures, nous regardons si elles sont en liens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfgPipGf5Fdo"
      },
      "outputs": [],
      "source": [
        "# Nombre valeurs opening\n",
        "print(f\"Nombre de valeurs opening : {df_spark.select('Opening').distinct().count()}\")\n",
        "print(f\"Nombre de valeurs ECO : {df_spark.select('ECO').distinct().count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn4f69Fx17ju"
      },
      "outputs": [],
      "source": [
        "#  Checker si une valeur de Opening = une valeur de ECO\n",
        "alignment_check_1 = df_spark.groupBy(\"ECO\").agg(countDistinct(\"Opening\").alias(\"Unique_Openings\"))\n",
        "misaligned_rows_1 = alignment_check_1.filter(col(\"Unique_Openings\") > 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gu0Edcv32tO5"
      },
      "outputs": [],
      "source": [
        "# Afficher les résultats\n",
        "if misaligned_rows_1.count() > 0:\n",
        "    print(\"Il existe plusieurs Openings pour un code ECO.\")\n",
        "    misaligned_rows_1.show(5)\n",
        "    print(\"Nombre de lignes : \", misaligned_rows_1.count())\n",
        "else:\n",
        "    print(\"Il existe un seul Opening pour un code ECO.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPLNZ7I_2wm2"
      },
      "outputs": [],
      "source": [
        "# Checker si une valeur de ECO = une valeur de Opening\n",
        "alignment_check_2 = df_spark.groupBy(\"Opening\").agg(countDistinct(\"ECO\").alias(\"Unique_ECOs\"))\n",
        "misaligned_rows_2 = alignment_check_2.filter(col(\"Unique_ECOs\") > 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-1nR4KR3f8j"
      },
      "outputs": [],
      "source": [
        "# Afficher les résultats\n",
        "if misaligned_rows_2.count() > 0:\n",
        "    print(\"Il existe plusieurs ECO pour un code Opening.\")\n",
        "    misaligned_rows_2.show(5)\n",
        "    print(\"Nombre de lignes : \", misaligned_rows_2.count())\n",
        "else:\n",
        "    print(\"Il existe un seul ECO pour un code Opening.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZaOgJPZaC4H"
      },
      "source": [
        "Nous remarquons qu'un Opening peut avoir plusieurs ECO, et qu'un ECO peut également avoir plusieurs Opening.  \n",
        "Nous allons regarder si c'est normal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb3pNGYNQk5g"
      },
      "outputs": [],
      "source": [
        "# Filtrer pour les ouvertures ayant plusieurs ECO\n",
        "misaligned_rows_2 = alignment_check_2.filter(col(\"Unique_ECOs\") > 1)\n",
        "opening_eco_counts = df_spark.groupBy(\"Opening\", \"ECO\").agg(count(\"*\").alias(\"count\"))\n",
        "multiple_opening_eco_counts = misaligned_rows_2.join(opening_eco_counts, on=\"Opening\", how=\"inner\")\n",
        "multiple_opening_eco_counts.orderBy(\"Opening\", \"count\", ascending=False).show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybFjANGdaKhv"
      },
      "source": [
        "Cela ne semble pas être des erreurs, il n'y a pas de ECO ou Opening largement dominant, nous allons donc garder ces éléments comme cela et les considérer comme 2 colonnes distinctes, n'ayant pas de lien particulier.\n",
        "\n",
        "Après quelques recherche sur internet, nous avons constaté que ce sont bien deux colonnes distinctes. Pour la question 2, comme aucune indication n'est mentionnée dans l'énoncé, nous utiliserons seulement Opening."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsJjnr4o-pZd"
      },
      "source": [
        "##### **Colonnes starting_time, increment, et TimeControl**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iIB1NZuNxY4"
      },
      "source": [
        "Nous allons maintenant vérifier si les colonnes \"starting_time\", \"increment\", et \"TimeControl\" sont bien en accord avec la documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9DqgPll9eQB"
      },
      "outputs": [],
      "source": [
        "# Même nombre null pour starting_time et increment, on vérifie que c'est aligné\n",
        "df_spark.filter(col(\"starting_time\").isNull() & col(\"increment\").isNull()).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5GbM2Wu9vwu"
      },
      "outputs": [],
      "source": [
        "# Afficher les type de game quand ces 2 colonnes sont NULL\n",
        "df_spark.filter(col(\"starting_time\").isNull() & col(\"increment\").isNull()).select(\"Game_type\").distinct().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mw_BCfA-bLo"
      },
      "outputs": [],
      "source": [
        "# Afficher les parties avec type de jeu Correspondence et starting_time ou increment non null\n",
        "df_spark.filter((col(\"Game_type\") == \"Correspondence\") & (col(\"starting_time\").isNotNull() | col(\"increment\").isNotNull())).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW0Dag3m9-dp"
      },
      "source": [
        "Cela correspond à ce qui est attendu.\n",
        "\n",
        "Maintenant, nous vérifions que TimeControl correspond bien à `starting_time+increment`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tERsB8fVQI0"
      },
      "outputs": [],
      "source": [
        "# Extraire starting_time et increment à partir de TimeControl\n",
        "df_spark_check = df_spark.withColumn(\n",
        "    \"starting_time_extracted\",\n",
        "    when(col(\"TimeControl\") != \"-\", split(col(\"TimeControl\"), \"\\+\")[0].cast(\"int\"))\n",
        "    .otherwise(None))\n",
        "\n",
        "df_spark_check = df_spark_check.withColumn(\n",
        "    \"increment_extracted\",\n",
        "    when(col(\"TimeControl\") != \"-\", split(col(\"TimeControl\"), \"\\+\")[1].cast(\"int\"))\n",
        "    .otherwise(None))\n",
        "\n",
        "# Recréer TimeControl avec les colonnes extraites\n",
        "df_spark_check = df_spark_check.withColumn(\n",
        "    \"TimeControl_reconstructed\",\n",
        "    when(col(\"starting_time_extracted\").isNull() & col(\"increment_extracted\").isNull(), \"-\")\n",
        "    .otherwise(concat_ws(\"+\", col(\"starting_time_extracted\"), col(\"increment_extracted\")))\n",
        ")\n",
        "\n",
        "# Comparer TimeControl avec la recréation\n",
        "df_spark_check = df_spark_check.withColumn(\n",
        "    \"is_matching\",\n",
        "    col(\"TimeControl\") == col(\"TimeControl_reconstructed\")\n",
        ")\n",
        "\n",
        "# Checker les résultats\n",
        "df_spark_check.select(\"TimeControl\", \"starting_time\", \"increment\", \"starting_time_extracted\", \"increment_extracted\", \"TimeControl_reconstructed\", \"is_matching\").show(5)\n",
        "mismatch_count = df_spark_check.filter(col(\"is_matching\") == False).count()\n",
        "print(f\"Nombre de différences : {mismatch_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il n'y a pas de différence, cela correspond également à la documentation."
      ],
      "metadata": {
        "id": "yndk3qCWHP1Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir--SwpeQdIE"
      },
      "source": [
        "## Réponses aux questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T74gZM0NPDmJ"
      },
      "source": [
        "### Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XEtPJrWOqkm"
      },
      "source": [
        "***Q1: What is the rate of blunders, errors and inaccuracies per move, per level category and on Blitz type games (Blitz type is by far the most played on these online sites). A game has two players, whose ELOs are most likely different. You will be able to classify a game into a category, either by considering the average ELO of both players, or by considering only the games where both players are in the same category.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GljHcFnAbLcJ"
      },
      "source": [
        "**Hypothèse :** Les joueurs appartenant à des catégories plus expérimentées devraient présenter un taux d'erreurs plus faible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRA97x6ZQFls"
      },
      "outputs": [],
      "source": [
        "# Filtre les parties avec le type de jeu Blitz\n",
        "df_blitz = df_spark_plus.filter(col(\"Game_type\") == \"Blitz\")\n",
        "df_blitz.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQv8TwoKXrxT"
      },
      "source": [
        "#### Calcule des taux par partie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBnGnO-5QbsD"
      },
      "outputs": [],
      "source": [
        "# Calcule taux de blunders\n",
        "df_blitz = df_blitz.withColumn(\"Black_blunders_rate\", col(\"Black_blunders\") / col(\"black_moves\")) \\\n",
        "                   .withColumn(\"White_blunders_rate\", col(\"White_blunders\") / col(\"white_moves\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxP7iixpRX06"
      },
      "outputs": [],
      "source": [
        "# Calcule taux d'errors\n",
        "df_blitz = df_blitz.withColumn(\"Black_errors_rate\", col(\"Black_mistakes\") / col(\"black_moves\")) \\\n",
        "                   .withColumn(\"White_errors_rate\", col(\"White_mistakes\") / col(\"white_moves\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xI1qobZ_R_CU"
      },
      "outputs": [],
      "source": [
        "# Calcule taux d'inaccuracies\n",
        "df_blitz = df_blitz.withColumn(\"Black_inaccuracies_rate\", col(\"Black_inaccuracies\") / col(\"black_moves\")) \\\n",
        "                   .withColumn(\"White_inaccuracies_rate\", col(\"White_inaccuracies\") / col(\"white_moves\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEG83zrNXzT6"
      },
      "source": [
        "#### Calcule des taux moyens par catégorie ELO (on considère le score ELO moyen des 2 joueurs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdklkG0cX6Zh"
      },
      "outputs": [],
      "source": [
        "df_avg_elo_summary = df_blitz.groupBy(\"Avg_ELO_category\").agg(\n",
        "    {\"Black_blunders_rate\": \"avg\", \"White_blunders_rate\": \"avg\",\n",
        "     \"Black_errors_rate\": \"avg\", \"White_errors_rate\": \"avg\",\n",
        "     \"Black_inaccuracies_rate\": \"avg\", \"White_inaccuracies_rate\": \"avg\"}\n",
        ").withColumnRenamed(\"avg(Black_blunders_rate)\", \"Avg_Black_blunders_rate\") \\\n",
        " .withColumnRenamed(\"avg(White_blunders_rate)\", \"Avg_White_blunders_rate\") \\\n",
        " .withColumnRenamed(\"avg(Black_errors_rate)\", \"Avg_Black_errors_rate\") \\\n",
        " .withColumnRenamed(\"avg(White_errors_rate)\", \"Avg_White_errors_rate\") \\\n",
        " .withColumnRenamed(\"avg(Black_inaccuracies_rate)\", \"Avg_Black_inaccuracies_rate\") \\\n",
        " .withColumnRenamed(\"avg(White_inaccuracies_rate)\", \"Avg_White_inaccuracies_rate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUmnTnbIPxTX"
      },
      "outputs": [],
      "source": [
        "df_avg_elo_summary.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsfB62FrYR55"
      },
      "outputs": [],
      "source": [
        "df_avg_elo_summary_pandas = df_avg_elo_summary.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmO5nsP2a2Fz"
      },
      "outputs": [],
      "source": [
        "df_avg_elo_summary_pandas.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff1S4mlyYblk"
      },
      "outputs": [],
      "source": [
        "# Ordonner les catégories de joueurs\n",
        "category_order = [\"other lower bound\", \"occasional player\", \"good club player\", \"very good club player\",\n",
        "                  \"national and international level\", \"GMI, World Champions\", \"other upper bound\"]\n",
        "df_avg_elo_summary_pandas['Avg_ELO_category'] = pd.Categorical(df_avg_elo_summary_pandas['Avg_ELO_category'],  categories=category_order,  ordered=True)\n",
        "df_avg_elo_summary_pandas = df_avg_elo_summary_pandas.sort_values('Avg_ELO_category')\n",
        "\n",
        "\n",
        "categories = df_avg_elo_summary_pandas['Avg_ELO_category']\n",
        "error_types = ['Blunders', 'Errors', 'Inaccuracies']\n",
        "\n",
        "# Données par type d'erreur et catégorie\n",
        "blunders = df_avg_elo_summary_pandas[['Avg_Black_blunders_rate', 'Avg_White_blunders_rate']].mean(axis=1)*100\n",
        "mistakes = df_avg_elo_summary_pandas[['Avg_Black_errors_rate', 'Avg_White_errors_rate']].mean(axis=1)*100\n",
        "inaccuracies = df_avg_elo_summary_pandas[['Avg_Black_inaccuracies_rate', 'Avg_White_inaccuracies_rate']].mean(axis=1)*100\n",
        "\n",
        "# Matrice (erreurs x catégorie)\n",
        "data = np.array([blunders, mistakes, inaccuracies]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTpkiqb2cMMX"
      },
      "outputs": [],
      "source": [
        "# Graphique\n",
        "plt.figure(figsize=(14, 8))\n",
        "x = np.arange(len(error_types))\n",
        "bar_width = 0.1\n",
        "\n",
        "for i, category in enumerate(categories):\n",
        "    plt.bar(x + i * bar_width, data[i], width=bar_width, label=str(category))\n",
        "\n",
        "plt.xlabel('Taux de fautes')\n",
        "plt.ylabel('Pourcentage de taux moyen')\n",
        "plt.title('Moyenne des taux de fautes par catégorie (Catégorie moyenne)')\n",
        "plt.xticks(x + bar_width * (len(categories) - 1) / 2, error_types)\n",
        "plt.legend(title=\"Catégorie ELO\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF6InvGrNm7z"
      },
      "source": [
        "##### **Analyse des taux de blunders, errors et inaccuracies selon les catégories d'ELO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIR-GSCib51F"
      },
      "source": [
        "Lorsque l'on analyse les taux de blunders, errors et inaccuracies en fonction des différentes catégories ELO, plusieurs tendances intéressantes émergent.  \n",
        "En excluant la catégorie \"Other Upper Bound\", on observe une diminution progressive des taux de **bourdes** (blunders) à mesure que les catégories augmentent, avec une chute de moins en moins marquée. Cela suggère qu'il y a une amélioration du niveau des joueurs en fonction de leur catégorie ELO, bien qu'elle soit de moins en moins évidente pour les catégories les plus expérimentées.\n",
        "\n",
        "Concernant les taux d'**erreurs** (errors), la diminution est relativement constante à travers les catégories, mais on remarque une chute plus importante lorsque l'on atteint les deux meilleures catégories (\"National and International Level\" et \"GMI, World Champions\"). Cela indique une amélioration notable dans la gestion des erreurs pour les joueurs de niveau supérieur.\n",
        "\n",
        "Quant aux taux d'**imprécisions** (inaccuracies), la tendance reste assez stable pour les premières catégories, avec une diminution qui s'accélère à mesure que l'on approche des deux catégories les plus élevées. Cette tendance suggère également une amélioration du jeu des joueurs plus expérimentés.\n",
        "\n",
        "En résumé, **les taux diminuent sensiblement à mesure que l'on progresse dans les catégories ELO**, avec une amélioration plus marquée pour les catégories \"National and International Level\" et \"GMI, World Champions\", ce qui reflète probablement un meilleur contrôle stratégique et une plus grande expérience des joueurs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf-oBNyZb8nr"
      },
      "source": [
        "##### **Analyse de la catégorie \"Other Upper Bound\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl0aqSJOb-t9"
      },
      "source": [
        "Lorsque l'on considère la catégorie \"Other Upper Bound\", une tendance différente se dessine.  \n",
        "Les taux de blunders, errors et inaccuracies semblent augmenter pour atteindre une **valeur entre celle des catégories \"Good Club Player\" et \"Very Good Club Player\"**.\n",
        "\n",
        "Cette anomalie pourrait suggérer plusieurs pistes d'interprétation.  \n",
        "Tout d'abord, il est possible que cette catégorie contienne des **données** qui ne sont **pas représentatives** du reste des catégories en raison d'un échantillon trop faible ou non nettoyé correctement.\n",
        "\n",
        "Une autre hypothèse pourrait être que la **performance** des joueurs dans cette catégorie est **influencée** par la moyenne des ELO des deux joueurs, et non seulement par l'ELO individuel.  \n",
        "Par exemple, un joueur avec un ELO élevé qui affronte un adversaire de niveau inférieur pourrait être amené à prendre plus de risques ou adopter des stratégies différentes, ce qui expliquerait certains résultats.  \n",
        "De plus, il est possible qu'une partie classée dans la catégorie \"Other upper bound\" n'inclue qu'un seul joueur avec un ELO très élevé, ce qui fausse la moyenne des deux scores ELO et pourrait influencer l'analyse des performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it5jufdcX3K8"
      },
      "source": [
        "#### Calcule des taux moyens par catégorie ELO (ici on considère seulement les parties où les joueurs sont dans la même catégorie)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUfv1BQDX224"
      },
      "outputs": [],
      "source": [
        "df_same_category = df_blitz.filter(col(\"Black_ELO_category\") == col(\"White_ELO_category\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wwa42HNxhrYe"
      },
      "outputs": [],
      "source": [
        "tot_blitz = df_blitz.count()\n",
        "tot_same_cat = df_same_category.count()\n",
        "print(f\"Nombre de parties total : {tot_blitz}\")\n",
        "print(f\"Nombre de parties avec 2 joueurs de la même catégorie : {tot_blitz}\")\n",
        "print(f\"Pourcentage même catégorie : {tot_same_cat / tot_blitz * 100} %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E8WMVXZYBf6"
      },
      "outputs": [],
      "source": [
        "df_same_category_summary = df_same_category.groupBy(\"Black_ELO_category\").agg(\n",
        "    {\"Black_blunders_rate\": \"avg\", \"White_blunders_rate\": \"avg\",\n",
        "     \"Black_errors_rate\": \"avg\", \"White_errors_rate\": \"avg\",\n",
        "     \"Black_inaccuracies_rate\": \"avg\", \"White_inaccuracies_rate\": \"avg\"}\n",
        ").withColumnRenamed(\"avg(Black_blunders_rate)\", \"Avg_Black_blunders_rate\") \\\n",
        " .withColumnRenamed(\"avg(White_blunders_rate)\", \"Avg_White_blunders_rate\") \\\n",
        " .withColumnRenamed(\"avg(Black_errors_rate)\", \"Avg_Black_errors_rate\") \\\n",
        " .withColumnRenamed(\"avg(White_errors_rate)\", \"Avg_White_errors_rate\") \\\n",
        " .withColumnRenamed(\"avg(Black_inaccuracies_rate)\", \"Avg_Black_inaccuracies_rate\") \\\n",
        " .withColumnRenamed(\"avg(White_inaccuracies_rate)\", \"Avg_White_inaccuracies_rate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_Ye8JmudLX7"
      },
      "outputs": [],
      "source": [
        "df_same_category_summary_pandas = df_same_category_summary.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtSEk6uMfAnG"
      },
      "outputs": [],
      "source": [
        "# Ordonner les catégories de joueurs\n",
        "category_order = [\"other lower bound\", \"occasional player\", \"good club player\", \"very good club player\",\n",
        "                  \"national and international level\", \"GMI, World Champions\", \"other upper bound\"]\n",
        "df_same_category_summary_pandas['Black_ELO_category'] = pd.Categorical(df_same_category_summary_pandas['Black_ELO_category'],  categories=category_order,  ordered=True)\n",
        "df_same_category_summary_pandas = df_same_category_summary_pandas.sort_values('Black_ELO_category')\n",
        "\n",
        "\n",
        "categories = df_same_category_summary_pandas['Black_ELO_category']\n",
        "error_types = ['Blunders', 'Errors', 'Inaccuracies']\n",
        "\n",
        "# Données par type d'erreur et catégorie (moyenne) # TODO : Voir si on fait autrement\n",
        "blunders = df_same_category_summary_pandas[['Avg_Black_blunders_rate', 'Avg_White_blunders_rate']].mean(axis=1)*100\n",
        "mistakes = df_same_category_summary_pandas[['Avg_Black_errors_rate', 'Avg_White_errors_rate']].mean(axis=1)*100\n",
        "inaccuracies = df_same_category_summary_pandas[['Avg_Black_inaccuracies_rate', 'Avg_White_inaccuracies_rate']].mean(axis=1)*100\n",
        "\n",
        "# Matrice (erreurs x catégorie)\n",
        "data = np.array([blunders, mistakes, inaccuracies]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKlJ7m2AeUJA"
      },
      "outputs": [],
      "source": [
        "# Graphique\n",
        "plt.figure(figsize=(14, 8))\n",
        "x = np.arange(len(error_types))\n",
        "bar_width = 0.1\n",
        "for i, category in enumerate(categories):\n",
        "    plt.bar(x + i * bar_width, data[i], width=bar_width, label=str(category))\n",
        "\n",
        "plt.xlabel('Type de fautes')\n",
        "plt.ylabel('Pourcentage de taux moyen')\n",
        "plt.title('Moyenne des taux de fautes par catégorie (Même catégorie entre les joueurs)')\n",
        "plt.xticks(x + bar_width * (len(categories) - 1) / 2, error_types)\n",
        "plt.legend(title=\"Catégorie ELO\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zANho_i7QPRs"
      },
      "source": [
        "Pour ces parties, où les deux joueurs appartiennent à la même catégorie, **les observations sont similaires** à celles faites pour la moyenne des ELO des joueurs.\n",
        "\n",
        "Cependant, pour la catégorie **\"Other upper bound\"**, on ne constate **pas de réaugmentation** des erreurs et inexactitudes, ce qui confirme que la moyenne des ELO des deux joueurs influençait les résultats dans cette catégorie.\n",
        "\n",
        "Inversement, une légère réaugmentation des blunders est observée entre les catégories \"National and International level\" et \"GMI, World Champions\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8vNfmy-g0d7"
      },
      "source": [
        "#### Résultats globaux"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5acBCPUg3nC"
      },
      "source": [
        "Nous observons des **résultats similaires** entre les parties où les catégories sont basées sur la moyenne des ELO des deux joueurs et celles où les deux joueurs appartiennent à la même catégorie ELO. Nous voyons, en effet, que tous **les taux de fautes ont tendance à diminuer** à mesure que la catégorie ELO augmente.\n",
        "\n",
        "Ce résultat est en accord avec l'hypothèse initiale : Les joueurs appartenant à des catégories plus expérimentées devraient présenter un taux d'erreurs plus faible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGmM--xUgI7N"
      },
      "source": [
        "### Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuH5E2dAgNr7"
      },
      "source": [
        "***Q2: Win probability depending on opening:***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSXAN6fCHjm8"
      },
      "source": [
        "**Hypothèse :** L'opening choisi influence significativement les chances de victoire pour les blancs et les noirs. Certains openings sont particulièrement avantageux pour les blancs tandis que d'autres peuvent mieux convenir aux noirs, en fonction du niveau des joueurs et du type de jeu (Blitz, Rapide, Classique).\n",
        "\n",
        "Aux échecs, l'opening désigne les premiers coups joués par chaque joueur. Ces coups établissent la structure de la partie et influencent grandement les stratégies ultérieures. Les blancs ont un avantage naturel en débutant la partie, mais cet avantage peut être renforcé ou annulé en fonction de l'opening choisi par les deux joueurs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbfRaQZbSsUA"
      },
      "source": [
        "#####  **Q2a: With which opening does White have the best chance to win, by level category (*) and by type of game (Blitz, Fast, Classic).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXkg4q_iK6rM"
      },
      "source": [
        "\n",
        "**Premières observations :**   \n",
        "Nous avons constaté que certaines configurations n’étaient jouées que très rarement et aboutissaient systématiquement à une victoire des Blancs.  \n",
        "Cela introduit un biais et ne permet pas d’identifier correctement quel opening offre réellement le plus de chances de gagner.  \n",
        "En effet, plus de 3 800 configurations présentaient une White_win_probability égale à 1.\n",
        "\n",
        "Nous avons donc décidé de conserver uniquement les configurations avec un nombre de parties jouées supérieure à 100 afin d’obtenir des résultats plus pertinents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re_28lZVV6vT"
      },
      "source": [
        "Nous allons analyser les configurations possibles, c'est à dire les combinaisons de `Opening`, `White_ELO_category`, et `Game_type`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u75jGBagKp72"
      },
      "outputs": [],
      "source": [
        "# Calculer le nombre de parties pour chaque configuration\n",
        "config_game_counts = df_spark_plus.groupBy(\"Opening\", \"White_ELO_category\", \"Game_type\").agg(count(\"*\").alias(\"Total_games_count\"))\n",
        "config_game_counts.orderBy(\"Total_games_count\", ascending=False).show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJE5RbW9MnpR"
      },
      "outputs": [],
      "source": [
        "# Nombre total de configurations uniques\n",
        "print(f\"Nombre total de configurations possibles : {config_game_counts.count()}\")\n",
        "print(f\"Nombre de configurations possibles pour les différents types de jeux :\")\n",
        "config_game_counts.groupBy(\"Game_type\").count().orderBy(\"count\", ascending=False).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGq_WayW8ppq"
      },
      "outputs": [],
      "source": [
        "# Nombre d'Opening par configurations\n",
        "df_spark_plus.groupBy(\"White_ELO_category\", \"Game_type\").count().orderBy(\"count\", ascending=False).show(34)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3slS8R76SqZ"
      },
      "source": [
        "Nous pouvons voir que le nombre de parties jouées par type de jeux n'est pas répartie de façon uniforme, et que certaines configurations sont très sous représentées."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGq5eexmMrTo"
      },
      "outputs": [],
      "source": [
        "# Filtrer les configurations avec plus de 100 parties jouées\n",
        "filtered_configurations = config_game_counts.filter(col(\"Total_games_count\") > 100)\n",
        "filtered_configurations.orderBy(\"Total_games_count\", ascending=False).show(5)\n",
        "print(f\"Nombre de configurations avec plus de 100 parties jouées : {filtered_configurations.count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeJ6lm0bN_Pn"
      },
      "outputs": [],
      "source": [
        "filtered_df = df_spark_plus.join(filtered_configurations.select(\"Opening\", \"White_ELO_category\", \"Game_type\"), on=[\"Opening\", \"White_ELO_category\", \"Game_type\"], how=\"inner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E65RvfdqMW5E"
      },
      "outputs": [],
      "source": [
        "# Quels sont les différentes valeurs de Game_type ?\n",
        "filtered_df.select(\"Game_type\").distinct().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vf--LJCMux6"
      },
      "source": [
        "L'énoncé précise \"by type of game (Blitz, Fast, Classic)\" mais on voit bien ici que c'est Blitz, \"Rapid\" et \"Classical\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMtXPRSQNDIy"
      },
      "outputs": [],
      "source": [
        "# Comment sont explicités les différentes fin de partie ?\n",
        "filtered_df.select(\"Result\").distinct().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfCDdQADP7Xz"
      },
      "source": [
        "1-0 : Victoire des blancs  \n",
        "0-1 : Victoire des noirs  \n",
        "1/2-1/2 : Match nul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyMMuNQ3glZd"
      },
      "outputs": [],
      "source": [
        "# Récupération des parties voulues (blancs gagnes +  type de jeux Blitz, Fast, Classic)\n",
        "df_white_wins = filtered_df.filter((col(\"Result\") == \"1-0\") & (col(\"Game_type\").isin([\"Blitz\", \"Rapid\", \"Classical\"])))\n",
        "df_total_games = filtered_df.filter(col(\"Game_type\").isin([\"Blitz\", \"Rapid\", \"Classical\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ax5rSGfWcPiO"
      },
      "outputs": [],
      "source": [
        "# Pour chaque ouverture, catégorie et type de jeu on calcule le nombre de victoires des blancs\n",
        "df_white_wins_groupby = df_white_wins.groupBy(\"Opening\", \"White_ELO_category\", \"Game_type\").agg(count(\"*\").alias(\"White_win_count\"))\n",
        "\n",
        "# Pareil mais on calcule le total de parties jouées\n",
        "df_total_games_groupby = df_total_games.groupBy(\"Opening\", \"White_ELO_category\", \"Game_type\").agg(count(\"*\").alias(\"Total_games_count\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2z0MCCPSeZol"
      },
      "outputs": [],
      "source": [
        "df_white_wins_groupby.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvYom_bSejJU"
      },
      "outputs": [],
      "source": [
        "df_total_games_groupby.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JRCvwm1ezys"
      },
      "outputs": [],
      "source": [
        "# Calcule de la probabilité de gagner en fonction de l'ouverture\n",
        "df_opening_stats = df_white_wins_groupby.join(df_total_games_groupby, on=[\"Opening\", \"White_ELO_category\", \"Game_type\"])\n",
        "df_opening_stats = df_opening_stats.withColumn(\"White_win_probability\", col(\"White_win_count\") / col(\"Total_games_count\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCYS9hr6fazc"
      },
      "outputs": [],
      "source": [
        "df_opening_stats.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bI0zsP9gY4j"
      },
      "outputs": [],
      "source": [
        "df_opening_stats.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5j81vN1RaUaE"
      },
      "outputs": [],
      "source": [
        "# Y a t il toutes les combinaisons de catégorie / type de partie ?\n",
        "df_opening_stats.groupBy(\"White_ELO_category\", \"Game_type\").count().orderBy(\"count\", ascending=False).show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ine3mq-iaweG"
      },
      "source": [
        "Nous pouvons voir que le nombre d'Opening différents (count) pour les combinaisons de catégories ELO et type de jeux n'est pas répartie uniformément, et certaines sont même absentes.\n",
        "\n",
        "Cependant, dans le jeu de données initiale, ces configurations étaient très sous représentées. Notamment :\n",
        "- GMI, World Champions - Rapid -  2163\n",
        "- other upper bound - Blitz - 301\n",
        "- GMI, World Champions - Classical - 232\n",
        "- other upper bound - Rapid - 8\n",
        "- other upper bound - Classical - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DYvuedq_xTv"
      },
      "outputs": [],
      "source": [
        "# Récupération du meilleur opening pour chaque catégorie de joueur et type de partie\n",
        "window_spec = Window.partitionBy(\"White_ELO_category\", \"Game_type\").orderBy(col(\"White_win_probability\").desc())\n",
        "best_openings = df_opening_stats.withColumn(\"rank\", rank().over(window_spec))\n",
        "best_openings = best_openings.filter(col(\"rank\") == 1).select(\"White_ELO_category\", \"Game_type\", \"Opening\", \"White_win_probability\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2faAWk3Dnzp"
      },
      "source": [
        "###### Résultats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2-xcY4-Ddgs"
      },
      "source": [
        "Nous affichons maintenant pour chaque catégorie ELO et type de jeu, l'opening permettant le plus de gagner pour les blancs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQr5WLm9Akvd"
      },
      "outputs": [],
      "source": [
        "best_openings.orderBy(\"White_ELO_category\", \"Game_type\").show(17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L83rRW9pQrtl"
      },
      "outputs": [],
      "source": [
        "best_openings_pandas = best_openings.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2dpsGhbPzrA"
      },
      "outputs": [],
      "source": [
        "best_openings_pandas[\"GameType_Category\"] = (best_openings_pandas[\"Game_type\"] + \" | \" + best_openings_pandas[\"White_ELO_category\"])\n",
        "\n",
        "# Table pivot pour voir le meilleur opening pour chaque configuration\n",
        "pivot_table = best_openings_pandas.pivot_table(\n",
        "    index=\"GameType_Category\",\n",
        "    columns=\"Opening\",\n",
        "    values=\"White_win_probability\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv2RrjNrQ3wW"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
        "plt.title(\"Meilleure opening (plus grande probabilité de victoire) des Blancs pour une catégorie et un Game Type\")\n",
        "plt.xlabel(\"Opening\")\n",
        "plt.ylabel(\"Type de jeu et Catégorie ELO\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRE3qylcSvAR"
      },
      "source": [
        "Nous pouvons voir que l'opening obtenant un meilleur résultat est généralement différent entre les configurations. Cela pourrait montrer qu'il y a un lien entre la victoire, le type de jeu, le niveau du joueur et l'opening choisi.\n",
        "\n",
        "Plus la probabilité de victoire associée à un opening est proche de 0,5, plus la chance de gagner avec cet opening est réduite, même si elle reste légèrement favorable (> 0,5). Cela reflète une situation où l'opening ne confère qu'un léger avantage, sans être déterminant. À l'inverse, une probabilité de victoire élevée, comme 0,83 dans le cas du \"King Knight Opening\" pour les joueurs de très bon niveau en Blitz, indique un opening particulièrement efficace pour maximiser les chances de victoire des blancs dans ce contexte spécifique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSzOqkhIb368"
      },
      "source": [
        "##### **Q2b: same question with black. You don't need to write again the same but only the results with black.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x85Uley0OQT5"
      },
      "outputs": [],
      "source": [
        "# Calculer le nombre de parties pour chaque configuration\n",
        "config_game_counts = df_spark_plus.groupBy(\"Opening\", \"Black_ELO_category\", \"Game_type\").agg(count(\"*\").alias(\"Total_games_count\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psVamhYVOaXO"
      },
      "outputs": [],
      "source": [
        "# Filtrer les configurations avec plus de 100 parties jouées\n",
        "filtered_configurations = config_game_counts.filter(col(\"Total_games_count\") > 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRw162_9ObzZ"
      },
      "outputs": [],
      "source": [
        "filtered_df = df_spark_plus.join(filtered_configurations.select(\"Opening\", \"Black_ELO_category\", \"Game_type\"), on=[\"Opening\", \"Black_ELO_category\", \"Game_type\"], how=\"inner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG4ZJpU3WQXq"
      },
      "outputs": [],
      "source": [
        "df_black_wins = filtered_df.filter((col(\"Result\") == \"0-1\") & (col(\"Game_type\").isin([\"Blitz\", \"Rapid\", \"Classical\"])))\n",
        "df_total_games = filtered_df.filter(col(\"Game_type\").isin([\"Blitz\", \"Rapid\", \"Classical\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuUsplOvdZiD"
      },
      "outputs": [],
      "source": [
        "df_black_wins_groupby = df_black_wins.groupBy(\"Opening\", \"Black_ELO_category\", \"Game_type\").agg(count(\"*\").alias(\"Black_win_count\"))\n",
        "df_total_games_groupby = df_total_games.groupBy(\"Opening\", \"Black_ELO_category\", \"Game_type\").agg(count(\"*\").alias(\"Total_games_count\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypuadmuVdc7l"
      },
      "outputs": [],
      "source": [
        "df_opening_stats = df_black_wins_groupby.join(df_total_games_groupby, on=[\"Opening\", \"Black_ELO_category\", \"Game_type\"])\n",
        "df_opening_stats = df_opening_stats.withColumn(\"Black_win_probability\", col(\"Black_win_count\") / col(\"Total_games_count\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V32knXpTQXXF"
      },
      "source": [
        "Nous affichons maintenant pour chaque catégorie ELO et type de jeu, l'opening (des blancs) permettant le plus de gagner pour les noirs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Vfa2I7odtb1"
      },
      "outputs": [],
      "source": [
        "window_spec = Window.partitionBy(\"Black_ELO_category\", \"Game_type\").orderBy(col(\"Black_win_probability\").desc())\n",
        "best_openings = df_opening_stats.withColumn(\"rank\", rank().over(window_spec))\n",
        "best_openings = best_openings.filter(col(\"rank\") == 1).select(\"Black_ELO_category\", \"Game_type\", \"Opening\", \"Black_win_probability\") # Rank pour garder les égalités\n",
        "best_openings.orderBy(\"Black_ELO_category\", \"Game_type\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Txk0FSCdsrO"
      },
      "outputs": [],
      "source": [
        "best_openings_pandas = best_openings.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuMXExaydc5n"
      },
      "outputs": [],
      "source": [
        "best_openings_pandas[\"GameType_Category\"] = (best_openings_pandas[\"Game_type\"] + \" | \" + best_openings_pandas[\"Black_ELO_category\"])\n",
        "pivot_table = best_openings_pandas.pivot_table(\n",
        "    index=\"GameType_Category\",\n",
        "    columns=\"Opening\",\n",
        "    values=\"Black_win_probability\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9x-fKTidc3n"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
        "plt.title(\"Meilleure opening (plus grande probabilité de victoire) des Noirs pour une catégorie et un Game Type\")\n",
        "plt.xlabel(\"Opening\")\n",
        "plt.ylabel(\"Type de jeu et Catégorie ELO\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "868ZzXFWTPwS"
      },
      "source": [
        "Nous observons que les openings offrant le plus de chances de victoire aux noirs sont différents de ceux favorisant les blancs. De plus, l'opening associé aux meilleures chances de victoire varie également en fonction des configurations, qu'il s'agisse du type de jeu (Blitz, Rapide, Classique) ou du niveau des joueurs.\n",
        "\n",
        "Par exemple, dans les parties classiques pour les joueurs d'un niveau \"other lower bound\", l'opening \"Queen's Pawn Game; Chigorin Variation\" affiche une probabilité de victoire de 0,52, ce qui suggère un léger avantage pour les noirs, bien que réduit.\n",
        "\n",
        "Nous remarquons également que certains openings semblent efficaces à travers différents types de jeu et niveaux, démontrant une certaine polyvalence. Cela souligne l'importance de l'adaptation stratégique des joueurs selon le contexte pour maximiser leurs chances de succès."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Réponse à l'hypothèse :\n",
        "- Les données montrent que l'opening choisi influence effectivement les chances de victoire, et cet impact varie selon plusieurs facteurs :\n",
        "\n",
        "##### Différence entre blancs et noirs :\n",
        "- Certains openings favorisent nettement les blancs, tandis que d'autres conviennent davantage aux noirs. Cela illustre une dynamique stratégique où les choix initiaux de chaque camp influencent fortement l'évolution de la partie.\n",
        "\n",
        "##### Variabilité selon les configurations :\n",
        "- Dans les parties Blitz, par exemple, des openings spécifiques comme le \"King's Knight Opening\" pour les blancs offrent des probabilités de victoire élevées, atteignant 0,83. Cela suggère que la rapidité du jeu peut accentuer l'efficacité de certains openings.\n",
        "- Dans des catégories comme \"other lower bound\" en classique, des openings comme \"Queen's Pawn Game; Chigorin Variation\" n'apportent qu'un avantage limité (0,52), montrant une moindre influence stratégique à ce niveau.\n",
        "\n",
        "##### Proximité avec 0,5 :\n",
        "- Plus la probabilité de victoire liée à un opening est proche de 0,5, moins cet opening semble décisif. Cela signifie qu'il joue un rôle plus neutre dans l'issue de la partie, même s'il reste un léger avantage pour l'un des camps.\n",
        "\n",
        "##### Polyvalence de certains openings :\n",
        "- Certains openings apparaissent comme efficaces à travers différents types de jeux et niveaux de joueurs, indiquant qu'ils peuvent être des choix stratégiques universels."
      ],
      "metadata": {
        "id": "iOaQdq5nDlrw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib5E3BoQP47F"
      },
      "source": [
        "### Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH7Khn9AP6hA"
      },
      "source": [
        "***Q3: (difficult). Does a line of data in the file predict the outcome of the game (column Result), and with what\n",
        "probability? In other words, can any of the variables, such as the number of errors (mistakes, blunders, inacurracies,\n",
        "ts_blunders), the difference in ELO between the two players, etc., explain the outcome (win/loss)? You are free to\n",
        "define explain as you wish. It can be a correlation, linear or not, or any other relationship that allows this prediction.  \n",
        "Note that the ELO is itself computed from a probability (normal distribution) of victory depending on the difference\n",
        "in ELO of the two players. For instance, for a difference of 100 ELO points, the higher ranked player is expected to\n",
        "win with probability 0.64. For a 200 points difference, it is 0.76.  \n",
        "As we have more data than the ELO difference, your prediction should be more accurate than that.***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour répondre à cette question, nous avons adopté une approche combinant des analyses exploratoires et des techniques de machine learning afin d'évaluer la capacité des variables à expliquer ou prédire le résultat d'une partie (colonne *Result*). Cependant, la grande quantité de données disponibles a posé des défis significatifs, notamment en termes de temps d'entraînement pour certains modèles sophistiqués, comme les forêts aléatoires (*Random Forests*) ou les arbres boostés (*Gradient Boosted Trees*), même en réduisant l'échantillon à un pourcentage aléatoire des données.\n",
        "\n",
        "Face à ces contraintes, nous avons opté pour un modèle de régression multinomiale, qui s'est avéré bien plus rapide à entraîner tout en offrant des performances acceptables sur un sous-échantillon de 1 % des données. Cela a toutefois nécessité une adaptation spécifique de la préparation des données. En parallèle, pour mieux comprendre les relations entre les variables et le résultat, nous avons complété l'analyse par des mesures de corrélation, de covariance et des tableaux de contingence (avec test de chi2), afin de capturer des liens potentiellement explicatifs ou prédictifs entre les caractéristiques comme les erreurs (*mistakes*, *blunders*, etc.), la différence d'ELO entre les joueurs, et d'autres variables pertinentes.\n",
        "\n",
        "\n",
        "#### Hypothèse :\n",
        "L'hypothèse principale est que la différence d'ELO est un facteur significatif pour prédire l'issue de la partie, conformément à la théorie sous-jacente à son calcul (probabilité basée sur une distribution normale).\n",
        "\n",
        "Cependant, étant donné la richesse des données, d'autres facteurs pourraient également jouer un rôle dans la prédiction de l'issue de la partie. Ces facteurs incluent :\n",
        "\n",
        "- Nombre d'erreurs (blunders, mistakes, inaccuracies, ts_blunders) : des erreurs fréquentes devraient augmenter les chances de défaite.\n",
        "- Nombre de coups totaux (Total_moves) : des parties plus longues peuvent refléter un jeu plus égalisé ou stratégique.\n",
        "- Niveau de jeu (type de partie : Blitz, Classique, etc.) : les parties rapides pourraient amplifier l'effet des erreurs.\n",
        "- Autres statistiques liées au jeu : comme les renversements de partie (Game_flips), etc."
      ],
      "metadata": {
        "id": "p0RMUIoqopII"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1yxXrgMI2mb"
      },
      "source": [
        "#### Préparation des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJgruJiL1X57"
      },
      "outputs": [],
      "source": [
        "df_spark_plus.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajouter la colonne de différence d'ELO\n",
        "df_spark_plus = df_spark_plus.withColumn(\"ELO_diff\", col(\"WhiteELO\") - col(\"BlackELO\"))"
      ],
      "metadata": {
        "id": "LOktm7kTOpAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjmXfpJhJ9fj"
      },
      "source": [
        "##### **Suppression des colonnes non nécessaires**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMg-uyytJSVn"
      },
      "source": [
        "Nous allons supprimer certaines colonnes du jeu de données qui ne sont pas pertinentes pour la prédiction de la colonne `Result` et/ou qui pourrait introduire un biais.\n",
        "\n",
        "<ins>Suppression des colonnes étant des conséquences du résultat:</ins>\n",
        "* `BlackRatingDiff` :  Variation du classement ELO du joueur noir après la partie\n",
        "* `WhiteRatingDiff` : Variation du classement ELO du joueur blanc après la partie\n",
        "\n",
        "Ces colonnes reflètent directement l'issue de la partie et ne peuvent donc pas être utilisées comme des variables explicatives pour prédire le résultat. Cela nous évite aussi de devoir gérer les valeurs NULL présentes dans ces colonnes.\n",
        "\n",
        "<ins>Suppression des colonnes n'apportant pas d'informations pertinentes :</ins>\n",
        "* `GAME` : Identifiant unique de la partie\n",
        "* `Date`: Date à laquelle la partie a été jouée\n",
        "* `Site`: URL de la partie  \n",
        "* `TimeControl` : Temps de jeu en secondes (temps initial + incrément)\n",
        "* `UTCTime` : Heure à laquelle la partie a été jouée\n",
        "* `Event` : Evenement où la partie a été jouée\n",
        "\n",
        "En plus d'être non pertinentes, certaines de ces données ne sont pas standardisées, cela nous évite donc des traitements supplémentaires non nécessaires.\n",
        "\n",
        "Supprimer les colonnes que nous avons calculées (informations redondantes) :\n",
        "- `Black_ELO_category`\n",
        "- `White_ELO_category`\n",
        "- `Avg_ELO_category`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combien d'instances pour Game_type\n",
        "df_spark_plus.groupBy(\"Game_type\").count().show()"
      ],
      "metadata": {
        "id": "EpdCcfsEVyqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supprimer Game_type = Correspondance pour pouvoir garder starting_time et increment\n",
        "# (où les données peuvent être manquantes)\n",
        "df_spark_plus = df_spark_plus.filter(col(\"Game_type\") != \"Correspondence\")"
      ],
      "metadata": {
        "id": "oDrAkYosYUhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVr43dK_KGwh"
      },
      "outputs": [],
      "source": [
        "# Suppression des colonnes\n",
        "df_preparation = df_spark_plus.drop(\"BlackRatingDiff\", \"WhiteRatingDiff\", \"GAME\", \"Date\", \"Site\", \"TimeControl\", \"UTCTime\", \"Event\",  \"Black_ELO_category\", \"White_ELO_category\", \"Avg_ELO_category\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHKKApAuOq-4"
      },
      "outputs": [],
      "source": [
        "df_preparation.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combien de valeurs nulles par colonne ?\n",
        "df_preparation.select([count(when(col(c).isNull(), c)).alias(c) for c in df_preparation.columns]).show()\n"
      ],
      "metadata": {
        "id": "2RKgwWmqYiNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pas de valeur null, c'est parfait"
      ],
      "metadata": {
        "id": "3pYxSOh7YxTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous réalisons l'analyse de corrélation, de covariance et des tableaux de contingence avant de finaliser la préparation des données, car la normalisation, la standardisation et l'encodage des données catégorielles peuvent influencer l'interprétation des relations entre les variables. En effet, ces techniques de prétraitement modifient l'échelle ou la représentation des données, ce qui peut fausser les résultats des analyses de corrélation ou de covariance si elles sont effectuées après ces transformations.\n",
        "\n",
        "\n",
        "Pourquoi cela est important :\n",
        "\n",
        "Corrélation et Covariance :\n",
        "- La corrélation mesure la force et la direction d'une relation linéaire entre deux variables. Elle peut être affectée par la mise à l'échelle des données. Si ces transformations sont faites après l'analyse de corrélation, il devient plus difficile d'interpréter les relations d'origine.\n",
        "- La covariance, bien que similaire à la corrélation, n'est pas dimensionnée. Elle peut être influencée par les unités de mesure des variables, ce qui peut fausser l'interprétation si les données ne sont pas préparées correctement.\n",
        "- **NB** : Nous avons tout de même besoin d'encoder Result en Result_index avant l'analyse de corrélation et de covariance.\n",
        "\n",
        "Encodage des données catégorielles :\n",
        "- Lorsque nous avons des colonnes catégorielles, il est nécessaire de les encoder. L'encodage peut introduire des relations implicites ou artificielles entre les variables. Cela peut affecter la façon dont les relations entre les catégories sont perçues dans les analyses. Il est donc important d'encodé correctement ces variables avant d'exécuter l'analyse, pour éviter d'introduire de fausses relations ou de perdre des informations importantes."
      ],
      "metadata": {
        "id": "hkcyl3U9vc2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombre de valeurs par Result\n",
        "df_preparation.groupBy(\"Result\").count().show()"
      ],
      "metadata": {
        "id": "RULqpHnaxnlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il y a seulement 72 valeurs indéfinies dans la colonnes Result, nous allons supprimer ces parties d'échec (ces lignes), car elles n'ont pas d'intérêts et sont en trop faible nombre pour apporter un réel résultat à notre analyse."
      ],
      "metadata": {
        "id": "xeWK59Q9xrxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_preparation = df_preparation.filter(col(\"Result\") != \"*\")"
      ],
      "metadata": {
        "id": "ns3Ev9g1xyJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Table de contingence"
      ],
      "metadata": {
        "id": "24DUqRknwNXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sélectionner toutes les colonnes catégorielles dans le DataFrame\n",
        "cat_columns = [col for col, dtype in df_preparation.dtypes if dtype == 'string']\n",
        "cat_columns"
      ],
      "metadata": {
        "id": "mnJQV4RBz9YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction pour créer la table de contingence\n",
        "def create_contingency_table(data, col1, col2):\n",
        "    return data.groupBy(col1, col2).agg(F.count('*').alias('count'))\n",
        "\n",
        "# Exclure 'Result' de cat_columns\n",
        "cat_columns = [col for col in cat_columns if col != 'Result']\n",
        "\n",
        "# Liste pour stocker les résultats\n",
        "contingency_tables = []\n",
        "\n",
        "# Boucle pour générer la table de contingence pour chaque paire de colonnes catégorielles\n",
        "for col in cat_columns:\n",
        "    # Créer la table de contingence\n",
        "    contingency_table = create_contingency_table(df_preparation, col, 'Result')\n",
        "    contingency_table_ord = contingency_table.orderBy(col, 'Result')\n",
        "    print(f\"Contingency Table for {col} and Result :\")\n",
        "    contingency_table_ord.show()\n",
        "\n",
        "    # Convertir la table de contingence en DataFrame Pandas pour l'analyse\n",
        "    contingency_df = contingency_table.toPandas()\n",
        "\n",
        "    # Calculer les proportions de chaque combinaison par rapport au total\n",
        "    contingency_df['Proportion'] = contingency_df['count'] / contingency_df['count'].sum()\n",
        "\n",
        "    # Ajouter la table de contingence à la liste\n",
        "    contingency_tables.append({\n",
        "        \"Variable\": col,\n",
        "        \"Contingency Table\": contingency_df\n",
        "    })\n",
        "\n",
        "    # S'assurer que chaque combinaison existe, remplir les valeurs manquantes avec 0\n",
        "    contingency_df = contingency_df.pivot_table(index=col, columns='Result', values='Proportion', aggfunc='sum', fill_value=0)\n",
        "\n",
        "    # Visualisation de la table de contingence\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    contingency_df.plot(kind='bar', stacked=True)\n",
        "    plt.title(f\"Proportions of {col} and Result\")\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel(\"Proportion\")\n",
        "    plt.legend(title=\"Result\")\n",
        "    plt.show()\n",
        "\n",
        "# Résumé des tables de contingence\n",
        "for result in contingency_tables:\n",
        "    print(f\"Summary for {result['Variable']}:\")\n",
        "    print(result['Contingency Table'].head())  # Affiche les premières lignes pour une vue d'ensemble\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "aP-EqNF05q7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les analyses des tables de contingence pour les relations entre ECO et Result, Opening et Result, Termination et Result, ainsi que Game_type et Result ne révèlent pas de différences significatives en termes de proportions, avec une distribution globalement équilibrée entre les victoires des Blancs, des Noirs et un nombre notablement plus faible de matchs nuls."
      ],
      "metadata": {
        "id": "ztyK3QEgjRKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sélectionner toutes les colonnes catégorielles dans le DataFrame qui ne sont pas Result\n",
        "cat_columns = [col for col, dtype in df_preparation.dtypes if dtype == 'string' and col != 'Result']\n",
        "\n",
        "# Indexation des colonnes catégorielles\n",
        "indexers = [\n",
        "    StringIndexer(inputCol=col_name, outputCol=col_name + \"_index\")\n",
        "    for col_name in cat_columns + ['Result']\n",
        "]\n",
        "\n",
        "# Créer un VectorAssembler pour assembler les colonnes en un vecteur\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[col_name + \"_index\" for col_name in cat_columns],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "# Créer le pipeline\n",
        "pipeline = Pipeline(stages=indexers + [assembler])\n",
        "\n",
        "# Appliquer le pipeline pour transformer les données\n",
        "df_transformed = pipeline.fit(df_preparation).transform(df_preparation)\n",
        "\n",
        "# Liste pour stocker les résultats\n",
        "chi_results = []\n",
        "\n",
        "# Boucle pour générer la table de contingence et effectuer le test chi-deux pour chaque paire de colonnes catégorielles\n",
        "for col in cat_columns:\n",
        "    # Créer un DataFrame avec les colonnes à tester (en utilisant \"features\" comme colonne d'entrée)\n",
        "    df_chi = df_transformed.select(\"features\", col + \"_index\")\n",
        "\n",
        "    # Effectuer le test de chi-deux\n",
        "    chi_result = ChiSquareTest.test(df_chi, \"features\", col + \"_index\").head()\n",
        "\n",
        "    # Afficher le résultat du test de chi-deux\n",
        "    print(f\"Chi-Square Test for {col} and Result:\")\n",
        "    print(f\"Chi-Square Statistic: {chi_result[0]}, p-value: {chi_result[1]}\")\n",
        "\n",
        "    # Ajouter les résultats dans la liste\n",
        "    chi_results.append({\n",
        "        \"Variable\": col,\n",
        "        \"Chi-Square Statistic\": chi_result[0],\n",
        "        \"p-value\": chi_result[1]\n",
        "    })\n",
        "\n",
        "# Créer un DataFrame pour les résultats\n",
        "chi_results_df = spark.createDataFrame(chi_results)\n",
        "\n",
        "# Afficher les résultats\n",
        "chi_results_df.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "iDC-k8HC5rj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les résultats des tests du chi-deux obtenus montrent les valeurs statistiques et les p-values pour différentes variables catégorielles par rapport à la variable cible Result.\n",
        "\n",
        "1. **ECO et Result**\n",
        "\n",
        "Chi-Square Statistic : [0.0, 0.0, 0.0, 0.0]  \n",
        "p-value : [241081, 1368908, 1473, 1473]  \n",
        "L'absence de valeurs supérieures à zéro dans les statistiques du chi-deux (valeurs égales à 0) signifie qu'il n'y a pas d'association entre les catégories de la variable ECO et la variable cible Result. Cela suggère que les différentes catégories de ECO sont indépendantes de Result, du moins selon ce test.\n",
        "\n",
        "Les p-values élevées (241081, 1368908, etc.) confirment l'absence de relation statistique significative entre les deux variables, car une p-value élevée (généralement > 0.05) indique une faible probabilité que l'association observée soit due au hasard.\n",
        "\n",
        "2. **Opening et Result**\n",
        "\n",
        "Chi-Square Statistic : [0.0, 0.0, 0.0, 0.0]  \n",
        "p-value : [1368908, 7772944, 8364, 8364]  \n",
        "Comme pour ECO, les statistiques du chi-deux de Opening sont égales à 0, ce qui indique qu'il n'y a aucune association significative entre cette variable et Result. Les p-values très élevées renforcent cette conclusion : la probabilité que l'absence d'association soit due au hasard est très faible.\n",
        "\n",
        "3. **Termination et Result**\n",
        "\n",
        "Chi-Square Statistic : [0.0, 0.0, 0.0, 0.0]  \n",
        "p-value : [1473, 8364, 9, 9]  \n",
        "Ici encore, la statistique du chi-deux est nulle, ce qui suggère qu'il n'y a pas d'association significative entre Termination et Result. Cependant, les p-values sont légèrement plus petites (9 et 8364), ce qui peut indiquer des zones où une association pourrait potentiellement être présente, mais elles restent suffisamment élevées pour indiquer qu'il n'y a pas de relation forte.\n",
        "\n",
        "4. **Game_type et Result**\n",
        "\n",
        "Chi-Square Statistic : [0.0, 0.0, 0.0, 0.0]  \n",
        "p-value : [1473, 8364, 9, 9]  \n",
        "Comme les résultats pour Termination, la statistique du chi-deux est de 0, ce qui ne montre aucune association significative entre Game_type et Result. Les p-values sont similaires à celles de Termination, ce qui confirme qu'il n'y a pas de lien important entre ces variables.\n",
        "\n",
        "**Conclusion générale :**\n",
        "\n",
        "Les résultats montrent que pour ces variables (ECO, Opening, Termination, Game_type), les tests de chi-deux ne révèlent aucune relation statistiquement significative avec la variable Result. En effet, les statistiques du chi-deux sont toutes nulles (0.0), ce qui suggère que la distribution des catégories de ces variables est indépendante de la variable cible Result. Les p-values élevées corroborent ce constat, car une p-value élevée indique que l'on ne peut pas rejeter l'hypothèse nulle (indépendance entre les variables).\n",
        "\n",
        "Cela signifie que aucune des variables testées (ECO, Opening, Termination, Game_type) n'a de lien évident avec Result dans notre jeu de données, du moins selon le test statistique du chi-deux effectué."
      ],
      "metadata": {
        "id": "JMtDhBRR8iKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On encode Result en donnée numérique."
      ],
      "metadata": {
        "id": "1tawJudh1Mvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Result : colonne cible, 3 valeurs possibles\n",
        "from pyspark.sql.functions import when, col # très capricieux, laissé l'import\n",
        "\n",
        "df_preparation = df_preparation.withColumn(\n",
        "    \"Result_index\",\n",
        "    when(col(\"Result\") == \"1-0\", 0)\n",
        "    .when(col(\"Result\") == \"0-1\", 2)\n",
        "    .when(col(\"Result\") == \"1/2-1/2\", 1) # nul \"moyenne\" des deux autres scénarios\n",
        ")\n",
        "\n",
        "# Vérification\n",
        "df_preparation.select(\"Result\", \"Result_index\").distinct().show()"
      ],
      "metadata": {
        "id": "n9r3E2eLx6K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Corrélation\n",
        "\n",
        "La corrélation mesure la force et la direction de la relation linéaire entre deux variables.\n",
        "\n",
        "- Une corrélation proche de +1 ou -1 indique une forte relation linéaire.\n",
        "- Une corrélation proche de 0 indique peu ou pas de relation linéaire.\n"
      ],
      "metadata": {
        "id": "0h9972uvttNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quelles sont les colonnes numériques ?\n",
        "numeric_cols = [col[0] for col in df_preparation.dtypes if col[1] in [\"int\", \"double\"]]\n",
        "print(f'Les colonnes numériques sont : {numeric_cols}')"
      ],
      "metadata": {
        "id": "ph3VyrclulJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assembler les colonnes numériques en un seul vecteur\n",
        "assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"numeric_features\")\n",
        "assembled_data = assembler.transform(df_preparation)\n",
        "\n",
        "# Calculer la matrice de corrélation\n",
        "correlation_matrix = Correlation.corr(assembled_data, \"numeric_features\").head()[0]\n",
        "\n",
        "# Convertir en DataFrame pour un affichage clair\n",
        "correlation_array = np.array(correlation_matrix.toArray())\n",
        "correlation_df = pd.DataFrame(correlation_array, columns=numeric_cols, index=numeric_cols)\n",
        "print(correlation_df)"
      ],
      "metadata": {
        "id": "28WXBOfVuuSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Créer une heatmap avec seaborn pour une meilleure visualisation\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Utiliser une palette de couleurs allant de -1 à 1 (avec 0 en blanc)\n",
        "sns.heatmap(correlation_df, annot=True, cmap='RdBu', center=0, vmin=-1, vmax=1, fmt=\".2f\", linewidths=0.5)\n",
        "\n",
        "# Ajouter un titre\n",
        "plt.title(\"Matrice de Corrélation\", fontsize=16)\n",
        "\n",
        "# Afficher la heatmap\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uznmGuQq-VjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sélectionner uniquement la dernière ligne (ici 'Result_index')\n",
        "result_corr = correlation_df.loc['Result_index']\n",
        "\n",
        "# Diviser en groupes de 5 colonnes\n",
        "columns = correlation_df.columns\n",
        "step = 5\n",
        "\n",
        "for i in range(0, len(columns), step):\n",
        "    # Sélectionner un sous-ensemble de colonnes\n",
        "    subset_columns = columns[i:i + step]\n",
        "    result_corr_subset = result_corr[subset_columns].to_frame().T\n",
        "\n",
        "    # Afficher les colonnes sélectionnées\n",
        "    print(result_corr_subset)\n",
        "\n",
        "    # Créer une heatmap pour le sous-ensemble\n",
        "    plt.figure(figsize=(10, 1))  # Ajuster la taille pour le sous-ensemble\n",
        "    sns.heatmap(result_corr_subset, annot=True, cmap='coolwarm', center=0, vmin=-1, vmax=1, fmt=\".2f\", linewidths=0.5)\n",
        "    plt.title(f\"Corrélation avec Result_index (Colonnes {i+1} à {i+len(subset_columns)})\", fontsize=14)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "0zh_2PDMsR8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Variables liées à l'ELO**\n",
        "- `BlackElo` (0.029) : Une faible corrélation positive indique que lorsque l'ELO du joueur noir augmente, il y a une légère tendance à une victoire pour Black (classe 2), mais cet effet est négligeable. (Peut-être pas une vistoire de noir, mais on tend alors vers 1 ou 2, match nul ou victoire de noir.)\n",
        "- `WhiteElo` (-0.041) : Une faible corrélation négative suggère qu'un ELO élevé pour White favorise légèrement la victoire de White (classe 0), mais l'effet reste marginal.\n",
        "- `ELO_diff` (-0.167) : Une corrélation négative modérée montre que lorsque la différence d'ELO augmente (en faveur de White), la probabilité de victoire pour White (classe 0) augmente, ce qui est intuitif.\n",
        "\n",
        "##### **Variables temporelles**\n",
        "- `starting_time` (-0.001) et `increment` (-0.000) : Les corrélations quasi nulles montrent que ni le temps de départ ni l'incrément n'ont d'influence significative sur le résultat de la partie.\n",
        "\n",
        "##### **Variables sur le nombre de coups**\n",
        "- `Total_moves` (0.027) : Une faible corrélation positive indique que les parties avec plus de coups sont légèrement associées à des résultats favorisant les matchs nuls (classe 1) ou les victoires de noir (classe 2), mais l'effet est très faible.\n",
        "\n",
        "##### **Blunders**\n",
        "- `Black_blunders` (-0.217) : Une corrélation négative modérée montre que plus le joueur noir commet des blunders, moins il est probable qu'il gagne (classe 2), ce qui est attendu.\n",
        "- `White_blunders` (0.238) : Une corrélation positive modérée montre que plus le joueur blanc fait de blunders, plus il est probable que White perde, ce qui favorise les victoires de Black (classe 2).\n",
        "\n",
        "##### **Mistakes et inaccuracies**\n",
        "- `Black_mistakes` (-0.105) et `Black_inaccuracies` (-0.111) : Des corrélations négatives faibles montrent que les erreurs mineures des noirs réduisent leurs chances de victoire, mais pas de manière aussi significative que les blunders.\n",
        "- `White_mistakes` (0.136) et `White_inaccuracies` (0.143) : Des corrélations positives faibles montrent que les erreurs des blancs augmentent la probabilité de victoire pour Black.\n",
        "\n",
        "##### **Inferior moves (mauvais coups globaux)**\n",
        "- `Black_inferior_moves` (-0.206) : Une corrélation négative modérée montre que des mauvais coups fréquents chez les noirs réduisent leurs chances de victoire (classe 2).\n",
        "- `White_inferior_moves` (0.245) : Une corrélation positive modérée montre que des mauvais coups fréquents chez les blancs augmentent les chances pour Black de gagner (classe 2).\n",
        "\n",
        "##### **Time-sensitive moves (erreurs sous pression de temps)**\n",
        "- `Black_ts_blunders` (-0.120) et `Black_ts_mistakes` (-0.089) : Ces corrélations montrent que les erreurs des noirs sous pression temporelle réduisent leurs chances de victoire, mais l'effet est modéré.\n",
        "- `White_ts_blunders` (0.136) et `White_ts_mistakes` (0.104) : Ces corrélations positives montrent que les erreurs des blancs sous pression temporelle augmentent les chances pour Black de gagner (classe 2).\n",
        "\n",
        "##### **Long moves et bad long moves**\n",
        "- `Black_long_moves` (-0.121) et `Black_bad_long_moves` (-0.126) : Ces corrélations négatives faibles indiquent que des mauvais coups longs chez les noirs réduisent légèrement leurs chances de victoire.\n",
        "- `White_long_moves` (0.127) et `White_bad_long_moves` (0.132) : Ces corrélations positives faibles montrent que les mauvais coups longs chez les blancs augmentent légèrement les chances pour Black de gagner.\n",
        "\n",
        "##### **Game flips (changement de dynamique)**\n",
        "- `Game_flips` (0.022) et `Game_flips_ts` (0.010) : Ces corrélations très faibles montrent que les retournements de situation dans la partie n'ont presque aucun impact sur le résultat final.\n",
        "\n",
        "##### **Synthèse des principaux facteurs :**\n",
        "- Différence d'ELO (`ELO_diff`) a une influence notable, avec une tendance claire : un ELO plus élevé favorise la victoire du joueur plus fort.\n",
        "- Blunders (`Black_blunders` et `White_blunders`) ont l'effet le plus significatif sur le résultat. Les blunders des noirs diminuent leurs chances, tandis que ceux des blancs augmentent les chances de victoire pour Black.\n",
        "- Inferior moves (Black et White) suivent une tendance similaire aux blunders, bien que leur impact soit légèrement plus faible.\n",
        "- Mistakes et inaccuracies ont un impact moindre, mais leur tendance est cohérente avec celle des blunders.\n",
        "- Facteurs temporels et coups longs ont peu d'effet significatif sur le résultat.\n",
        "\n",
        "\n",
        "##### **Conclusion**\n",
        "Les résultats confirment que la performance est fortement liée aux erreurs majeures et à l'ELO des joueurs, tandis que les autres variables comme le temps ou les retournements de jeu ont une influence marginale.\n"
      ],
      "metadata": {
        "id": "kf-3BvATlp75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Covariance\n",
        "\n",
        "- Une covariance positive indique que les deux variables augmentent ensemble.\n",
        "- Une covariance négative indique qu'une variable augmente tandis que l'autre diminue."
      ],
      "metadata": {
        "id": "DL4um5BBuRZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Liste des colonnes numériques sauf \"Result\"\n",
        "numeric_cols_without_result = [col for col in numeric_cols if col != 'Result_index']\n",
        "\n",
        "data = df_preparation\n",
        "\n",
        "# Calculer la covariance entre 'Result' et chaque autre colonne numérique\n",
        "cov_result = []\n",
        "for col in numeric_cols_without_result:\n",
        "    print(f\"Calcul de {col}\")\n",
        "    covariance = data.stat.cov('Result_index', col)\n",
        "    cov_result.append(covariance)\n",
        "\n",
        "# Créer un DataFrame pour afficher les résultats\n",
        "cov_result_df = pd.DataFrame(cov_result, columns=['Covariance'], index=numeric_cols_without_result)\n",
        "\n",
        "# Afficher les covariances\n",
        "print(cov_result_df)\n"
      ],
      "metadata": {
        "id": "x_FBZZ3WAUFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Créer une heatmap pour la matrice de covariance\n",
        "plt.figure(figsize=(10, 8))  # Ajuster la taille pour mieux visualiser\n",
        "\n",
        "# Utiliser une palette de couleurs pour les covariances\n",
        "sns.heatmap(cov_result_df, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5, center=0, vmin=-cov_result_df.max().max(), vmax=cov_result_df.max().max())\n",
        "\n",
        "# Ajouter un titre\n",
        "plt.title(\"Matrice de Covariance\", fontsize=16)\n",
        "\n",
        "# Afficher la heatmap\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jMadPsZ5tmSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Covariances importantes avec Result_index :**\n",
        "- `BlackElo` (9.88) : Une covariance positive suggère que l'ELO plus élevé du joueur noir est associé à une plus grande probabilité de victoire pour Black (classe 2). Cela est logique, car un joueur avec un ELO plus élevé est plus susceptible de gagner, mais l'effet n'est pas très fort.\n",
        "- `WhiteElo` (-14.05) : La covariance négative indique que l'ELO plus élevé du joueur blanc est associé à une probabilité plus faible de match nul ou de victoire pour Black. Cela montre une relation inverse : un joueur blanc plus fort (plus élevé en ELO) augmente la probabilité de victoire pour White (classe 0).\n",
        "- `Total_moves` (0.72) : La covariance positive montre que plus le nombre de coups est élevé, plus la probabilité de match nul (classe 1) augmente. Cela pourrait indiquer que les matchs avec plus de coups sont souvent plus équilibrés et ont une probabilité plus élevée de se terminer par un match nul. (Ceci dit, la probabilité de victoire de Black augmente par la même occasion.)\n",
        "- `Black_blunders` (-0.42) et `White_blunders` (0.46) : Les blunders des noirs et des blancs ont une covariance relativement forte avec le résultat, suggérant que des erreurs (blunders) des noirs diminuent la probabilité de victoire pour Black (classe 2), tandis que les blunders des blancs augmentent la probabilité de victoire pour White (classe 0). Les blunders sont donc un facteur significatif dans le résultat de la partie.\n",
        "- `Black_inferior_moves` (-0.88) et `White_inferior_moves` (1.06) : Les mauvais coups (moves inférieurs) des noirs sont associés négativement avec le résultat pour Black, tandis que les mauvais coups des blancs augmentent la probabilité de victoire de White. Cela montre que les erreurs stratégiques jouent un rôle important dans l'issue du match.\n",
        "- `ELO_diff` (-23.93) : Une forte covariance négative indique que la différence d'ELO a un impact important sur le résultat. Lorsque la différence d'ELO entre les joueurs est importante, cela favorise la victoire de White (classe 0) ou de Black (classe 2), selon qui a le plus grand ELO. Cela est cohérent avec l'idée que des différences d'ELO plus élevées augmentent la probabilité que le joueur avec l'ELO le plus élevé gagne.\n",
        "\n",
        "##### **Covariances faibles ou peu significatives :**\n",
        "- `starting_time` (-0.42) et `increment` (-0.0006) : Ces valeurs faibles indiquent que le temps de départ et l'incrément n'ont qu'un faible impact sur le résultat du match. Cela soutient l'idée que les caractéristiques temporelles, comme le temps de départ ou les incréments, influencent peu le résultat final.\n",
        "- `Black_mistakes` (-0.24) et `White_mistakes` (0.31) : Les erreurs sont légèrement corrélées avec le résultat, mais l'impact est modéré. Les erreurs des noirs réduisent légèrement la probabilité de victoire de Black, tandis que les erreurs des blancs ont un effet inverse.\n",
        "- `Black_ts_moves` (-0.42) et `White_ts_moves` (0.53) : Les mouvements temporels (moves dans la time control) ont une corrélation faible, mais légèrement plus marquée du côté des blancs, où des mouvements dans le cadre du contrôle du temps pourraient favoriser leur victoire.\n",
        "- `Black_long_moves` (-0.13) et `White_long_moves` (0.14) : Les mouvements longs n'ont qu'une faible covariance avec le résultat, bien que les mouvements longs des blancs semblent légèrement augmenter la probabilité de leur victoire.\n",
        "\n",
        "##### **Autres variables et facteurs supplémentaires :**\n",
        "- `Black_bad_long_moves` (-0.08) et `White_bad_long_moves` (0.08) : Bien que faibles, ces covariances suggèrent que les mouvements longs \"mauvais\" des noirs sont légèrement corrélés avec une diminution de leur probabilité de victoire, tandis que ceux des blancs semblent avoir l'effet inverse, mais de manière marginale.\n",
        "- `Game_flips` (0.10) et `Game_flips_ts` (0.01) : Ces valeurs indiquent que les flips du jeu n'ont qu'un très faible impact sur le résultat du match.\n",
        "\n",
        "##### **Conclusion générale :**\n",
        "- L'ELO et la différence d'ELO ont un impact fort sur le résultat du match. Un ELO plus élevé pour l'un des joueurs diminue la probabilité de match nul et favorise la victoire de ce joueur.\n",
        "- Les blunders et les erreurs stratégiques (inferior) jouent un rôle majeur dans le résultat. Les blunders des noirs diminuent leur probabilité de victoire, tandis que les blunders des blancs augmentent les chances de victoire pour White.\n",
        "- Les autres variables temporelles et les mouvements longs n'ont qu'un faible impact sur le résultat, à l'exception de quelques cas où les coups longs peuvent influencer légèrement le résultat."
      ],
      "metadata": {
        "id": "RlFkGZ8vmg2o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CtYRrnxPF6S"
      },
      "source": [
        "#### Encodage des colonnes non numériques"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un véritable défi dans la préparation des données a été l'encodage des colonnes catégorielles, notamment celles avec un très grand nombre de catégories distinctes. Dans de tels cas, utiliser un encodage classique comme le one-hot encoding aurait été impraticable. Cela aurait non seulement multiplié la taille des données de manière exponentielle, mais également introduit des matrices très clairsemées et difficiles à exploiter efficacement dans les modèles.\n",
        "\n",
        "De même, l'encodage par label (Label Encoding), qui associe un entier unique à chaque catégorie, aurait pu introduire un biais implicite d'ordre dans certaines configurations de modèles (notamment les modèles linéaires), ce qui n’était pas souhaitable.\n",
        "\n",
        "Pour surmonter ces limitations, nous avons opté pour le target encoding, une approche plus adaptée. Cette méthode consiste à remplacer chaque catégorie par une valeur numérique calculée en fonction de la cible (par exemple, le taux moyen de victoire pour chaque catégorie). Cela nous a permis de conserver l'information tout en réduisant significativement la complexité des données et en améliorant leur utilisabilité dans les modèles d’apprentissage."
      ],
      "metadata": {
        "id": "Jtq3u-CKp_Ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sauver état de df_preparation\n",
        "df_preparation_original = df_preparation"
      ],
      "metadata": {
        "id": "hbjiSvL2EGcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJPgCitQRLhb"
      },
      "outputs": [],
      "source": [
        "# Observation des types des colonnes pour savoir comment les traiter\n",
        "schema = df_preparation.schema\n",
        "columns_by_type = defaultdict(list)\n",
        "\n",
        "for field in schema:\n",
        "    columns_by_type[str(field.dataType)].append(field.name)\n",
        "\n",
        "for data_type, columns in columns_by_type.items():\n",
        "    print(f\"Type: {data_type}\")\n",
        "    print(f\"Columns: {columns}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESfrjMwKR-kn"
      },
      "source": [
        "Il y a 5 colonnes de type chaine de caractères, nous allons les encoder afin de pouvoir les utiliser dans nos prédictions."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combien de données différentes contiennent chacune de ces colonnes ?\n",
        "for column in columns_by_type[\"StringType()\"]:\n",
        "  distinct_count = df_preparation.select(column).distinct().count()\n",
        "  print(f\"Nombre de valeurs distinctes pour la colonne '{column}': {distinct_count}\")"
      ],
      "metadata": {
        "id": "UD3k7_c1L-Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6usk1trUQq7y"
      },
      "source": [
        "Nous allons gérer ces colonnes de façons différentes, en fonction de leur nombre de valeurs possibles et de leur type.\n",
        "\n",
        "* `Result` : Colonne à prédire (déjà encodée avant l'analyse par corrélation)\n",
        "* `ECO`, `Opening` : Beaucoup de valeurs possibles\n",
        "* `Termination`, `Game_type` : Peu de valeurs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supprimer alors Result\n",
        "df_preparation = df_preparation.drop(\"Result\")"
      ],
      "metadata": {
        "id": "erm3J1pAszs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Game_type : 4 valeurs, pseudo relation d'ordre\n",
        "from pyspark.sql.functions import col # important de laisser l'import de nouveau\n",
        "\n",
        "df_preparation = df_preparation.withColumn(\n",
        "    \"Game_type_encoded\",\n",
        "    when(col(\"Game_type\") == \"Bullet\", 1)\n",
        "    .when(col(\"Game_type\") == \"Blitz\", 2)\n",
        "    .when(col(\"Game_type\") == \"Rapid\", 3)\n",
        "    .when(col(\"Game_type\") == \"Classical\", 4)\n",
        ")\n",
        "\n",
        "# vérifier\n",
        "df_preparation.select(\"Game_type\", \"Game_type_encoded\").distinct().show()"
      ],
      "metadata": {
        "id": "qADtdg8ailGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supprimer Game_type\n",
        "df_preparation = df_preparation.drop(\"Game_type\")"
      ],
      "metadata": {
        "id": "3_SBF0d1s5l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy du df pour pas tout perdre\n",
        "data = df_preparation"
      ],
      "metadata": {
        "id": "s0gOwpOFtsNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import mean\n",
        "# Target encoding pour \"Opening\"\n",
        "avg_opening_result = data.groupBy(\"Opening\").agg(mean(\"Result_index\").alias(\"opening_score\"))\n",
        "data = data.join(avg_opening_result, on=\"Opening\", how=\"left\")\n",
        "\n",
        "# Target encoding pour \"Eco\"\n",
        "avg_eco_result = data.groupBy(\"Eco\").agg(mean(\"Result_index\").alias(\"eco_score\"))\n",
        "data = data.join(avg_eco_result, on=\"Eco\", how=\"left\")\n",
        "\n",
        "# Vérification des colonnes ajoutées\n",
        "data.select(\"Opening\", \"opening_score\", \"Eco\", \"eco_score\").show(10)"
      ],
      "metadata": {
        "id": "U_1vgQP5f5AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supprimer Opening et Eco\n",
        "data = data.drop(\"Opening\", \"Eco\")"
      ],
      "metadata": {
        "id": "F3Q8k_YwvNxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quelles sont les valeurs de Termination ?\n",
        "data.select(\"Termination\").distinct().show()"
      ],
      "metadata": {
        "id": "-Mecma3Kw0Dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Termination : 4 valeurs possibles\n",
        "# One hot encoding pour éviter relations d'ordre implicite\n",
        "\n",
        "# Créer Termination_Abandoned, Termination_Rules_infraction, Termination_Time_forfeit, Termination_Normal\n",
        "\n",
        "data = data.withColumn(\n",
        "    \"Termination_Abandoned\",\n",
        "    when(col(\"Termination\") == \"Abandoned\", 1)\n",
        "    .otherwise(0)\n",
        ")\n",
        "\n",
        "data = data.withColumn(\n",
        "    \"Termination_Rules_infraction\",\n",
        "    when(col(\"Termination\") == \"Rules infraction\", 1)\n",
        "    .otherwise(0)\n",
        ")\n",
        "\n",
        "data = data.withColumn(\n",
        "    \"Termination_Time_forfeit\",\n",
        "    when(col(\"Termination\") == \"Time forfeit\", 1)\n",
        "    .otherwise(0)\n",
        ")\n",
        "\n",
        "data = data.withColumn(\n",
        "    \"Termination_Normal\",\n",
        "    when(col(\"Termination\") == \"Normal\", 1)\n",
        "    .otherwise(0)\n",
        ")\n",
        "\n",
        "# Afficher Termination et les 4 colonnes créées\n",
        "data.select(\"Termination\", \"Termination_Abandoned\", \"Termination_Rules_infraction\", \"Termination_Time_forfeit\", \"Termination_Normal\").show(10)"
      ],
      "metadata": {
        "id": "3N82r5mIg6w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supprimer Termination\n",
        "data = data.drop(\"Termination\")"
      ],
      "metadata": {
        "id": "iCrg4GRGvMG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérifier les colonnes\n",
        "data.printSchema()"
      ],
      "metadata": {
        "id": "ralck60ytWqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv8ZjhTFqi8b"
      },
      "source": [
        "#### Normalisation des données"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quelles sont les colonnes numériques ? (normalement toutes)\n",
        "numeric_cols = [col[0] for col in data.dtypes if col[1] in [\"int\", \"double\"]]\n",
        "print(f'Les colonnes numériques sont : {numeric_cols}')\n",
        "\n",
        "# Quelles sont les colonnes non numériques ?\n",
        "non_numeric_cols = [col[0] for col in data.dtypes if col[1] not in [\"int\", \"double\"]]\n",
        "print(f'Les colonnes non numériques sont : {non_numeric_cols}')"
      ],
      "metadata": {
        "id": "UkJTPBtzqJOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retirer Result_index\n",
        "numeric_cols.remove(\"Result_index\")\n",
        "\n",
        "# Combiner les colonnes numériques dans un seul vecteur pour la standardisation\n",
        "assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"numeric_features\")\n",
        "data = assembler.transform(data)\n",
        "\n",
        "# Standardiser les données\n",
        "scaler = StandardScaler(inputCol=\"numeric_features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
        "scaler_model = scaler.fit(data)\n",
        "data = scaler_model.transform(data)\n",
        "\n",
        "# Transformer le vecteur en colonnes séparées\n",
        "data = data.withColumn(\"scaled_features_array\", vector_to_array(col(\"scaled_features\")))\n",
        "\n",
        "# Réattribuer chaque colonne standardisée à son nom d'origine\n",
        "for i, col_name in enumerate(numeric_cols):\n",
        "    data = data.withColumn(f\"{col_name}_scaled\", col(\"scaled_features_array\")[i])\n",
        "\n",
        "# Supprimer les colonnes intermédiaires si nécessaire\n",
        "data = data.drop(\"numeric_features\", \"scaled_features\", \"scaled_features_array\")\n",
        "\n",
        "# Afficher un aperçu des données\n",
        "data.select(*[f\"{col}_scaled\" for col in numeric_cols]).show(5)\n"
      ],
      "metadata": {
        "id": "PFcGwlQ9qNHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraire toutes les colonnes scaled et Result_index\n",
        "scaled_cols = [col_name for col_name in data.columns if \"_scaled\" in col_name]\n",
        "df_scaled = data.select(*scaled_cols, \"Result_index\")\n",
        "\n",
        "feature_columns = df_scaled.columns\n",
        "feature_columns"
      ],
      "metadata": {
        "id": "xq7Rgn-HJN7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_columns.remove(\"Result_index\")"
      ],
      "metadata": {
        "id": "exF8M-u6JjX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zCZFAy8qnZU"
      },
      "outputs": [],
      "source": [
        "# Combinaison des colonnes finales\n",
        "assembler_final = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "df_final = assembler_final.transform(df_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxIagKMupKsY"
      },
      "outputs": [],
      "source": [
        "df_final.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_features = df_final.select(\"features\", \"Result_index\")"
      ],
      "metadata": {
        "id": "t2Mgiocv07kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train test split"
      ],
      "metadata": {
        "id": "XpfBp44y0BtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diviser les données en 80% pour l'entrainement et 20% pour le test\n",
        "train_data, test_data = df_features.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "0hKL2ThT0BcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utiliser un sous-ensemble des données (1% des données d'entraînement)\n",
        "small_train_data = train_data.sample(withReplacement=False, fraction=0.01, seed=1234)\n"
      ],
      "metadata": {
        "id": "9QcSQrnj3WdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Régression multinomiale\n"
      ],
      "metadata": {
        "id": "RS8VcQvf_FrP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour entraîner notre modèle de régression multinomiale, nous avons utilisé un sous-échantillon représentant 1 % des données d'entraînement afin de réduire le temps de calcul et d’optimiser les performances. Le modèle a été évalué sur un ensemble de test distinct."
      ],
      "metadata": {
        "id": "9DMT2bYVwpyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Environ 5 minutes avec un sous sample à 1%\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"Result_index\", family=\"multinomial\")\n",
        "model = lr.fit(small_train_data)"
      ],
      "metadata": {
        "id": "ZjZCRWtv_J16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test_data)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Result_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "VALpM1HY_bnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le modèle a obtenu une précision (accuracy) de 92,11 %, ce qui signifie que 92 % des prédictions effectuées étaient correctes. Cela indique que le modèle est capable de bien prédire les résultats des parties (victoire des Blancs, victoire des Noirs ou match nul) à partir des caractéristiques utilisées.\n",
        "\n",
        "Etant donné que les classes dans les données cibles (Result_index) sont relativement équilibrées, la précision est une métrique appropriée pour évaluer la performance du modèle.\n",
        "\n",
        "$$ \\text{Accuracy} = \\frac{\\text{Nombre de prédictions correctes}}{\\text{Nombre total de prédictions}} $$\n",
        "\n",
        "Ce modèle de régression multinomiale s'est révélé efficace pour prédire le résultat des parties avec des performances élevées, même sur un sous-échantillon réduit des données. Cela valide l’approche choisie et la pertinence des caractéristiques sélectionnées pour la prédiction.\n"
      ],
      "metadata": {
        "id": "Zd6hKtM6wq_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Récupérer les noms des caractéristiques utilisées dans le modèle\n",
        "feature_names = assembler.getInputCols()"
      ],
      "metadata": {
        "id": "35w2HdJtBjm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intercept pour chaque classe\n",
        "intercepts = model.interceptVector\n",
        "print(\"Intercepts pour chaque classe :\")\n",
        "for i, intercept in enumerate(intercepts):\n",
        "    print(f\"Classe {i}: {intercept}\")"
      ],
      "metadata": {
        "id": "krupteQpBcEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Coefficient matrix : chaque ligne représente les coefficients pour une classe\n",
        "coeff_matrix = model.coefficientMatrix\n",
        "coeff_matrix\n"
      ],
      "metadata": {
        "id": "J_9PW1jH_bez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher les coefficients pour chaque classe\n",
        "for i in range(coeff_matrix.numRows):\n",
        "    print(f\"Classe {i}:\")\n",
        "    for j in range(coeff_matrix.numCols):\n",
        "        print(f\"  {feature_names[j]}: {coeff_matrix[i, j]}\")\n",
        "    print(f\"Intercept: {intercepts[i]}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "AYiTGHUIB7It"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boucle pour afficher les 5 facteurs les plus influents pour chaque classe\n",
        "for i in range(coeff_matrix.numRows):\n",
        "    print(f\"Classe {i}:\")\n",
        "\n",
        "    # Extraire les coefficients pour la classe i\n",
        "    class_coeffs = [coeff_matrix[i, j] for j in range(coeff_matrix.numCols)]  # Liste des coefficients\n",
        "\n",
        "    # Créer une liste de tuples (coefficient, feature_name) et trier par valeur absolue des coefficients\n",
        "    feature_coeffs = [(feature_names[j], class_coeffs[j]) for j in range(len(class_coeffs))]\n",
        "\n",
        "    # Trier les caractéristiques par valeur absolue décroissante des coefficients\n",
        "    feature_coeffs_sorted = sorted(feature_coeffs, key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "    # Afficher les 5 facteurs les plus influents\n",
        "    for feature, coeff in feature_coeffs_sorted[:5]:\n",
        "        print(f\"  {feature}: {coeff}\")\n",
        "\n",
        "    # Afficher l'intercept de la classe\n",
        "    print(f\"Intercept: {intercepts[i]}\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "eAHUCjrKBQX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classe 0 : White gagne :**\n",
        "\n",
        "- `black_moves` (-40.48) : Plus le joueur noir joue de coups, moins il est probable que White gagne.\n",
        "- `white_moves` (40.22) : Plus le joueur blanc joue de coups, plus il est probable qu'il gagne.\n",
        "\n",
        "  **NB importante :** Les variables `white_moves` et `black_moves` sont naturellement corrélées, car les joueurs alternent leurs coups tout au long de la partie. Un grand nombre de coups totaux implique donc nécessairement une contribution importante des deux joueurs. Cela reflète davantage la durée globale de la partie (longue ou courte) qu'une performance individuelle.\n",
        "\n",
        "- `Black_blunders` (1.27) : Les erreurs majeures des noirs augmentent significativement la probabilité de victoire pour White.\n",
        "- `White_blunders` (-1.20) : Les blunders des blancs réduisent la probabilité de victoire pour White.\n",
        "- `Black_inferior_moves` (0.71) : Les mauvais coups globaux des noirs favorisent également la victoire de White.\n",
        "- `Intercept` (0.811) : Cela indique une tendance de base légèrement positive pour White, en l'absence de contribution des autres variables.\n",
        "\n",
        "**Classe 1 : Match nul :**\n",
        "\n",
        "- `white_moves` (0.64) : Une légère augmentation des mouvements du joueur blanc favorise les matchs nuls. Cet indicateur est peu pertinent, comme déjà expliqué, le nombre de coups joué par white et black est similaire.\n",
        "- `Termination_Normal` (0.32) : Les parties qui se terminent normalement (pas par abandon ou dépassement de temps) favorisent un match nul. Ce qui est logique.\n",
        "- `Termination_Time_forfeit` (-0.32) : Un abandon dû au dépassement de temps réduit la probabilité d'un match nul. Ce qui est aussi logique, un forfait implique un gagnant.\n",
        "- `Game_flips` (0.25) : Les retournements de situation augmentent la probabilité de match nul, ce qui reflète une dynamique équilibrée dans ces parties.\n",
        "- `Total_moves` (0.22) : Un nombre total élevé de mouvements est associé aux matchs nuls.\n",
        "- `Intercept` (-1.49) : Cela indique une tendance de base négative pour les matchs nuls, sauf si les variables les favorisent.\n",
        "\n",
        "**Classe 2 : Black gagne :**\n",
        "\n",
        "- `white_moves` (-40.86) : Plus le joueur blanc joue de coups, moins il est probable que Black gagne.\n",
        "- `black_moves` (40.66) : Plus le joueur noir joue de coups, plus il est probable qu'il gagne.\n",
        "\n",
        "  Comme dit précédemment, les variables `white_moves` et `black_moves` sont naturellement liées.\n",
        "\n",
        "- `White_blunders` (1.21) : Les erreurs majeures des blancs augmentent significativement la probabilité de victoire pour Black.\n",
        "- `Black_blunders` (-1.14) : Les blunders des noirs réduisent la probabilité de victoire pour eux.\n",
        "- `White_inferior_moves` (0.69) : Les mauvais coups globaux des blancs favorisent également la victoire de Black.\n",
        "- `Intercept` (0.678) : Cela indique une légère tendance de base favorable à Black.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "Ces résultats mettent en évidence des dynamiques intéressantes dans les parties d'échecs :\n",
        "- Les blunders et les mauvais coups (inferior moves) sont des indicateurs clés pour prédire le résultat, avec des impacts inverses selon le joueur (Blanc ou Noir).\n",
        "- Les parties longues et équilibrées semblent favoriser les matchs nuls, tandis que l'activité d'un joueur, mesurée par le nombre de coups, est un facteur déterminant pour les victoires.\n",
        "\n"
      ],
      "metadata": {
        "id": "LjOTMufDNKQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conclusion question 3\n",
        "\n",
        "Les différentes approches ont permis d'identifier les variables significativement liées au Result :\n",
        "\n",
        "- Corrélation et covariance ont révélé les tendances générales, montrant notamment quels facteurs influencent les chances de victoire pour les Blancs ou les Noirs.\n",
        "- L'approche par Machine Learning a permis d'aller plus loin, en étudiant également les facteurs associés à une issue de match nul, ce qui n'était pas accessible via des analyses statistiques plus simples.\n",
        "\n",
        "Ainsi, ces analyses complémentaires offrent une vision plus globale et détaillée des variables influençant l'issue d'une partie.\n",
        "\n",
        "#### Réponse à l'hypothèse :\n",
        "- ELO_diff comme facteur prédominant :\n",
        "Les résultats confirment que la différence d'ELO est effectivement un facteur significatif pour prédire l'issue de la partie, en accord avec la théorie. Une grande différence d'ELO favorise fortement le joueur mieux classé, comme prévu par le modèle de probabilité basé sur une distribution normale.\n",
        "\n",
        "- Cependant, les résultats montrent que les erreurs (blunders, mistakes) et le contexte (type de partie, dynamique des coups) ajoutent des nuances importantes à cette prédiction. Le facteur temporel lui n'est pas important. Cela suggère que, bien que l'ELO soit un bon indicateur global, l'issue d'une partie peut dépendre de nombreux autres facteurs comportementaux."
      ],
      "metadata": {
        "id": "tW3axEy-N1_Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4fIC5KrhhEm"
      },
      "source": [
        "## Questions supplémentaires"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distribution des parties nulles selon l'ouverture et le niveau"
      ],
      "metadata": {
        "id": "iTfyS-YL1MA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Quelles ouvertures ont une probabilité plus élevée de mener à une partie nulle ?**\n",
        "- **Quelle est la distribution des parties nulles en fonction de l'ouverture et des catégories ELO des joueurs ?**\n",
        "\n",
        "Hypothèses :\n",
        "- Certaines ouvertures pourraient être plus susceptibles de mener à des parties nulles, par exemple des ouvertures symétriques ou très solides qui tendent à se stabiliser.\n",
        "- Les joueurs dans les catégories ELO plus élevées pourraient être plus enclins à jouer des ouvertures qui mènent à des positions équilibrées, avec une probabilité plus élevée de nulles.\n",
        "- Le niveau des joueurs pourrait avoir une influence sur les ouvertures choisies, et des catégories plus faibles (joueurs avec un ELO plus bas) pourraient avoir un taux plus faible de parties nulles, car leurs erreurs stratégiques ou tactiques peuvent rendre la partie plus dynamique et moins susceptible de se terminer par une nulle.\n",
        "- Le type d'ouverture pourrait aussi influencer le taux de parties nulles, certaines ouvertures plus complexes ou agressives entraînant plus de gains et de pertes, alors que des ouvertures plus passives pourraient mener à des parties plus équilibrées et donc à davantage de nulles."
      ],
      "metadata": {
        "id": "AAe5YswC6W_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark_null = df_spark_plus\n",
        "# ne garder que les données où le Result est 1/2-1/2\n",
        "df_spark_null = df_spark_null.filter(col(\"Result\") == \"1/2-1/2\")"
      ],
      "metadata": {
        "id": "1aXsdA5n8Zzh"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution des parties nulles selon l'ouverture\n",
        "distribution_null = df_spark_null.groupBy(\"Opening\") \\\n",
        "                                        .agg(count(\"*\").alias(\"num_draws\"),\n",
        "                                             (count(\"*\") / df_spark.count()).alias(\"draw_rate\")) \\\n",
        "                                        .orderBy(col(\"draw_rate\").desc())\n"
      ],
      "metadata": {
        "id": "FhQ19nc18Zxf"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distribution_null.show(truncate=False)"
      ],
      "metadata": {
        "id": "aOwcZaRD8ZvY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c07f2f97-d6d7-4bf3-88b0-62bc35c1184b"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------+---------+---------------------+\n",
            "|Opening                                      |num_draws|draw_rate            |\n",
            "+---------------------------------------------+---------+---------------------+\n",
            "|Queen's Pawn Game: Mason Attack              |2459     |6.575026290746647E-4 |\n",
            "|Indian Game                                  |1859     |4.970709180357062E-4 |\n",
            "|Sicilian Defense                             |1631     |4.36106867840902E-4  |\n",
            "|Caro-Kann Defense                            |1552     |4.149833592207725E-4 |\n",
            "|Philidor Defense                             |1532     |4.096356355194739E-4 |\n",
            "|Scandinavian Defense: Mieses-Kotroc Variation|1440     |3.850361064935002E-4 |\n",
            "|French Defense: Knight Variation             |1238     |3.3102409711038426E-4|\n",
            "|Pirc Defense                                 |1172     |3.1337660889609883E-4|\n",
            "|Sicilian Defense: Old Sicilian               |1148     |3.0695934045454047E-4|\n",
            "|Scotch Game                                  |1133     |3.029485476785665E-4 |\n",
            "|Modern Defense                               |1132     |3.026811614935016E-4 |\n",
            "|Queen's Pawn Game                            |1132     |3.026811614935016E-4 |\n",
            "|Queen's Pawn Game: Chigorin Variation        |1112     |2.97333437792203E-4  |\n",
            "|Horwitz Defense                              |1070     |2.8610321801947585E-4|\n",
            "|Sicilian Defense: Bowdler Attack             |1007     |2.692578883603852E-4 |\n",
            "|Four Knights Game: Italian Variation         |870      |2.3262598100648972E-4|\n",
            "|French Defense: Exchange Variation           |850      |2.2727825730519113E-4|\n",
            "|Van't Kruijs Opening                         |831      |2.2219791978895744E-4|\n",
            "|Queen's Pawn Game: Zukertort Variation       |766      |2.0481781775973695E-4|\n",
            "|Queen's Pawn                                 |746      |1.9947009405843832E-4|\n",
            "+---------------------------------------------+---------+---------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les résultats montrent que certaines ouvertures spécifiques ont une probabilité plus élevée de mener à des parties nulles.\n",
        "\n",
        "- *Queen's Pawn Game: Mason Attack*, une approche calme et solide, a le taux de nulles le plus élevé, avec un draw rate de 0.065 %.\n",
        "- Les ouvertures classiques et solides comme *Indian Game* (0.050 %), *Sicilian Defense* (0.044 %), et *Caro-Kann Defense* (0.041 %) figurent également parmi les ouvertures avec les taux de nulles les plus élevés, ce qui confirme leur nature équilibrée et stable.\n",
        "\n",
        "Ces résultats sont cohérents avec l'hypothèse selon laquelle des ouvertures symétriques ou solides tendent à stabiliser les positions, augmentant ainsi la probabilité d'un match nul.\n",
        "\n",
        "En revanche, des ouvertures plus agressives ou tactiques, comme celles non mentionnées ici, pourraient entraîner davantage de victoires ou de défaites, réduisant leur draw rate."
      ],
      "metadata": {
        "id": "DcUZsbCS3qzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution des parties nulles en fonction de la catégorie ELO des joueurs\n",
        "distribution_null_by_elo = distribution_null_by_elo = df_spark_null.groupBy(\"Black_ELO_category\", \"White_ELO_category\") \\\n",
        "                                    .agg(count(\"*\").alias(\"num_draws\"),\n",
        "                                         (count(\"*\") / df_spark.count()).alias(\"draw_rate\")) \\\n",
        "                                    .orderBy(col(\"draw_rate\").desc())\n"
      ],
      "metadata": {
        "id": "gk6TWC5D8Zs9"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distribution_null_by_elo.show(truncate = False)"
      ],
      "metadata": {
        "id": "khk9fiAs9HpW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0345f967-2188-4469-f3d0-d19671f213b4"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------------+---------+---------------------+\n",
            "|Black_ELO_category|White_ELO_category|num_draws|draw_rate            |\n",
            "+------------------+------------------+---------+---------------------+\n",
            "|Low rating        |Low rating        |67121    |0.017947228127743214 |\n",
            "|High rating       |High rating       |28864    |0.007717834845714161 |\n",
            "|High rating       |Low rating        |4569     |0.0012216874795616685|\n",
            "|Low rating        |High rating       |4257     |0.00113826298982141  |\n",
            "|GM rating         |GM rating         |2229     |5.960038065097305E-4 |\n",
            "|GM rating         |High rating       |1254     |3.3530227607142315E-4|\n",
            "|High rating       |GM rating         |1157     |3.0936581612012485E-4|\n",
            "|GM rating         |Low rating        |54       |1.4438853993506258E-5|\n",
            "|Low rating        |GM rating         |43       |1.1497605957792021E-5|\n",
            "+------------------+------------------+---------+---------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les résultats montrent que les parties nulles sont plus fréquentes entre joueurs de même niveau, notamment pour les catégories *Low rating* (1,79 %) et *High rating* (0,77 %). Cela peut s'expliquer par un équilibre d'erreurs et de stratégies similaires. En revanche, les *Grands Maîtres* (GM) ont un taux de nulles plus faible (0,59 %) même entre eux, surement car ils savent éviter les positions trop équilibrées.\n",
        "\n",
        "Au contraire, les matchs entre joueurs de niveaux très différents, comme *GM* vs *Low rating*, présentent des taux de nulles très faibles (inférieur à 0,15 %).\n",
        "\n",
        "Ces observations soulignent l'influence du niveau des joueurs sur la probabilité d'une partie nulle."
      ],
      "metadata": {
        "id": "Koqv8pL96-IB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Croiser les données des ouvertures et des catégories ELO des joueurs pour analyser les probabilités de nulles\n",
        "distribution_null_by_opening_elo = df_spark_null.groupBy(\"Opening\", \"Black_ELO_category\", \"White_ELO_category\") \\\n",
        "                                           .agg(count(\"*\").alias(\"num_draws\"),\n",
        "                                                (count(\"*\") / df_spark.count()).alias(\"draw_rate\")) \\\n",
        "                                           .orderBy(col(\"draw_rate\").desc())\n"
      ],
      "metadata": {
        "id": "PcEmTS3p9HnD"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distribution_null_by_opening_elo.show(truncate = False)"
      ],
      "metadata": {
        "id": "lSq56-Fq9Hks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "316d0954-be94-4e74-b151-701854d10236"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------+------------------+------------------+---------+---------------------+\n",
            "|Opening                                      |Black_ELO_category|White_ELO_category|num_draws|draw_rate            |\n",
            "+---------------------------------------------+------------------+------------------+---------+---------------------+\n",
            "|Queen's Pawn Game: Mason Attack              |Low rating        |Low rating        |1878     |5.021512555519399E-4 |\n",
            "|Philidor Defense                             |Low rating        |Low rating        |1347     |3.601691912824617E-4 |\n",
            "|Sicilian Defense                             |Low rating        |Low rating        |1167     |3.1203967797077415E-4|\n",
            "|Scandinavian Defense: Mieses-Kotroc Variation|Low rating        |Low rating        |1049     |2.8048810813311234E-4|\n",
            "|Caro-Kann Defense                            |Low rating        |Low rating        |1032     |2.759425429870085E-4 |\n",
            "|Scotch Game                                  |Low rating        |Low rating        |1008     |2.695252745454502E-4 |\n",
            "|Indian Game                                  |Low rating        |Low rating        |999      |2.671187988798658E-4 |\n",
            "|French Defense: Knight Variation             |Low rating        |Low rating        |952      |2.5455164818181405E-4|\n",
            "|Queen's Pawn Game                            |Low rating        |Low rating        |893      |2.3877586326298314E-4|\n",
            "|Queen's Pawn Game: Chigorin Variation        |Low rating        |Low rating        |892      |2.385084770779182E-4 |\n",
            "|Sicilian Defense: Bowdler Attack             |Low rating        |Low rating        |862      |2.3048689152597028E-4|\n",
            "|Sicilian Defense: Old Sicilian               |Low rating        |Low rating        |794      |2.12304630941555E-4  |\n",
            "|Modern Defense                               |Low rating        |Low rating        |785      |2.0989815527597063E-4|\n",
            "|Four Knights Game: Italian Variation         |Low rating        |Low rating        |753      |2.0134179735389283E-4|\n",
            "|Horwitz Defense                              |Low rating        |Low rating        |738      |1.9733100457791888E-4|\n",
            "|Pirc Defense                                 |Low rating        |Low rating        |722      |1.9305282561688E-4   |\n",
            "|Van't Kruijs Opening                         |Low rating        |Low rating        |661      |1.767422683279192E-4 |\n",
            "|Italian Game: Anti-Fried Liver Defense       |Low rating        |Low rating        |630      |1.6845329659090634E-4|\n",
            "|Indian Game                                  |High rating       |High rating       |599      |1.601643248538935E-4 |\n",
            "|Scandinavian Defense                         |Low rating        |Low rating        |564      |1.5080580837662094E-4|\n",
            "+---------------------------------------------+------------------+------------------+---------+---------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les résultats montrent que les parties nulles sont particulièrement fréquentes pour des ouvertures classiques et solides, comme la *Queen's Pawn Game: Mason Attack* et la *Philidor Defense*. Ces ouvertures favorisent des positions équilibrées et défensives, ce qui augmente les chances de parties sans vainqueur. On peut tout de même retrouver en troisième position la *Sicilian Defense*, une ouverture asymétrique et aggressive.  \n",
        "Les joueurs de faible niveau (*Low rating*) dominent ce tableau, confirmant que leurs parties, bien que souvent marquées par des erreurs mutuelles, aboutissent fréquemment à des matchs nuls.\n",
        "\n",
        "En revanche, les parties impliquant des joueurs de niveaux plus élevés (*High rating*) apparaissent moins souvent dans ce tableau, ici, il n'y en a qu'un sur les vingt premiers. On voit également qu'il n'y a aucun GM dans ces vingt premiers résultats. De plus, nous retrouvons dans ce tableau, seulement des parties avec des joueurs de même niveau.\n",
        "\n",
        "Ces résultats confirment que les ouvertures et le niveau des joueurs influencent significativement les probabilités de matchs nuls"
      ],
      "metadata": {
        "id": "qAjMCVPg9pfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Peut etre changer les hypothèses et y ajouter que un même ELO provoque plus de matchs nuls\n",
        "# Car les types d'openings ca montre un peu mais pas bcp, donc peut etre compléter jsp"
      ],
      "metadata": {
        "id": "dZPOyEnkBknW"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Impact de la différence d'ELO sur la durée d'une partie (en nombre de coups)"
      ],
      "metadata": {
        "id": "0DR_1mJG1PXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothèse à tester : Les parties où la différence d'ELO entre les joueurs est grande ont tendance à durer moins longtemps en nombre de coups. Cela pourrait être dû au fait qu'un joueur plus fort (avec un ELO plus élevé) termine rapidement la partie avec un coup décisif ou un mat, tandis qu'une partie entre des joueurs avec des ELO similaires pourrait durer plus longtemps en raison d'une lutte plus équilibrée.\n",
        "\n",
        "Pour tester notre hypothèse, nous allons calculer la corrélation entre la différence d'ELO et la durée de la partie.\n",
        "\n"
      ],
      "metadata": {
        "id": "mvE7pYqIOK-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark_diff_ELO = df_spark\n",
        "\n",
        "# Ajouter la colonne de différence d'ELO\n",
        "df_spark_diff_ELO = df_spark_diff_ELO.withColumn(\"ELO_diff\", col(\"WhiteELO\") - col(\"BlackELO\"))"
      ],
      "metadata": {
        "id": "YtXjtfL-OyLJ"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Créer un VectorAssembler pour combiner les colonnes en un vecteur\n",
        "assembler = VectorAssembler(inputCols=['ELO_diff', 'Total_moves'], outputCol='features')\n",
        "\n",
        "# Appliquer le VectorAssembler pour transformer les données\n",
        "assembled_data = assembler.transform(df_preparation)\n",
        "\n",
        "# Calcul de la corrélation\n",
        "correlation_matrix = Correlation.corr(assembled_data, 'features', method='pearson')\n",
        "\n",
        "# Affichage de la matrice de corrélation\n",
        "print(f\"Correlation Matrix:\\n{correlation_matrix.head()}\")\n"
      ],
      "metadata": {
        "id": "0kVFpywNPQ9M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71e6ba66-459c-46aa-b6e2-e3ea9afc04af"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation Matrix:\n",
            "Row(pearson(features)=DenseMatrix(2, 2, [1.0, -0.0077, -0.0077, 1.0], False))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Corrélation très faible : La valeur de la corrélation -0.0077 indique une très faible relation entre la différence d'ELO et le nombre de coups dans la partie. La différence d'ELO entre les joueurs ne semble pas avoir un impact significatif sur la durée de la partie (en termes de nombre de coups).\n",
        "\n",
        "La corrélation, ayant une valeur proche de 0, signifie qu'il n'y a pas de lien linéaire évident entre ces deux variables. Et la corrélation, étant négative, indique que si un lien existe, il est inverse, c'est-à-dire que des différences d'ELO plus grandes pourraient être associées à des parties plus courtes, mais dans ce cas, l'effet est tellement faible que cela ne constitue pas une relation significative.\n",
        "\n",
        "\n",
        "**Réflexion sur l'hypothèse :**  \n",
        "L'hypothèse selon laquelle les parties avec une grande différence d'ELO durent moins longtemps n'est pas confirmée par ces résultats. En effet, la corrélation très faible suggère que d'autres facteurs peuvent jouer un rôle plus important dans la durée de la partie que la différence d'ELO entre les joueurs."
      ],
      "metadata": {
        "id": "aIHR_9TPjQw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "6uQu827UPcl1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce projet a permis d’explorer en profondeur un grand ensemble de données issues des parties d'échecs jouées sur Lichess.\n",
        "\n",
        "Grâce aux résultats apportés aux questions proposées et aux problématiques supplémentaires, nous avons pu mettre en lumière plusieurs aspects du jeu d’échecs et offrir des perspectives intéressantes pour mieux comprendre les dynamiques du jeu.\n",
        "\n",
        "Nous avons constaté que le **taux d’erreurs** (blunders, erreurs, imprécisions) varie significativement selon la catégorie ELO des joueurs, avec des taux plus faibles pour les joueurs de haut niveau.\n",
        "\n",
        "Nous avons également vu que certaines **ouvertures** offrent des **probabilités de victoire** plus élevées pour les Blancs ou les Noirs en fonction des niveaux de joueurs et des types de parties.\n",
        "\n",
        "Les modèles prédictifs, en particulier la régression multinomiale, nous ont permis d'atteindre une précision (accuracy) de 92 % dans la **prédiction des résultats** des parties. Bien que ce soit un excellent résultat, il est important de noter que certaines variables, comme la différence d’ELO ou les erreurs commises, montrent une influence limitée lorsqu'elles sont prises isolément. Les interactions complexes entre variables jouent un rôle crucial, et les parties d’échecs restent influencées par des dynamiques stratégiques difficiles à modéliser intégralement.\n",
        "\n",
        "Ensuite, nous avons analysé la **probabilité de parties nulles** en fonction des ouvertures et des catégories ELO. Les joueurs de même niveau, surtout ceux de faible niveau tendent à produire plus de matchs nuls et utiliser des ouvertures classiques et solides. Et enfin, la **corrélation entre la différence d’ELO et la durée des parties** s’est révélée insignifiante, invalidant l’hypothèse d’une relation directe."
      ],
      "metadata": {
        "id": "oeQL2IOMCKhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Zoé : Ajouter ouverture ? j'ai aps d'inspi"
      ],
      "metadata": {
        "id": "F_kU-zYkKyfN"
      },
      "execution_count": 144,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "so3fXjziQNRq",
        "tHbCTsTR4S6e",
        "NAcsmDlTdOWG",
        "o89yf5WEXwQT",
        "gK1JnDk6MMqE",
        "7nwC7P5S8x6B",
        "rxLZyOkVNiMc",
        "T74gZM0NPDmJ",
        "YGmM--xUgI7N",
        "ib5E3BoQP47F"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}