{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ-ApUtIwHXG"
      },
      "source": [
        "# Projet Lichess\n",
        "\n",
        "_Traitements et données large échelle_\n",
        "\n",
        "Zoé Marquis & Charlotte Kruzic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ManTk4Ll02fM"
      },
      "source": [
        "TODO : présenter les objectifs du projet, les différentes questions, les données utilisées\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoCDA5c1McJt"
      },
      "source": [
        "## Installation et importation des bibliothèques nécessaires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLQJBvTu1Ln_",
        "outputId": "16897739-d544-4dcb-817e-e98954f16357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (0.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZIoRHOnTSqmt"
      },
      "outputs": [],
      "source": [
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKCU055GLlsg",
        "outputId": "e12f12b8-9afe-4cb4-dbe4-4c0f7090a67b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7Fq95N2B0pm8"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import os\n",
        "import kagglehub\n",
        "\n",
        "import findspark\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6v1hNJRbMmTS"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.3-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mXe-TNDn4Seo"
      },
      "outputs": [],
      "source": [
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.3-bin-hadoop3\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoOwUYVF0r4O"
      },
      "source": [
        "## Préparation des données et de l'environnement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqCvyHSnQMdZ"
      },
      "source": [
        "Chargement des données, analyse exploratoire et prétraitement des données."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so3fXjziQNRq"
      },
      "source": [
        "### Chargement du fichier de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8dD1y9b60pkk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec3948b7-30a7-4724-ce43-d2c6f13c2c7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/noobiedatascientist/lichess-september-2020-data?dataset_version_number=3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 324M/324M [00:03<00:00, 103MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chemin vers le fichier du dataset :  /root/.cache/kagglehub/datasets/noobiedatascientist/lichess-september-2020-data/versions/3\n"
          ]
        }
      ],
      "source": [
        "path = kagglehub.dataset_download(\"noobiedatascientist/lichess-september-2020-data\")\n",
        "print(\"Chemin vers le fichier du dataset : \", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZoMmOHTH0pf_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0086784-6ba2-4f16-ebfa-3cbc2f233996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fichiers du dataset :  ['Sept_20_analysis.RDS', 'Sept_20_analysis.csv', 'Column information.txt']\n"
          ]
        }
      ],
      "source": [
        "files = os.listdir(path)\n",
        "print(\"Fichiers du dataset : \", files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-C_Fv81N0pbO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb73adff-d505-43ea-c54d-43faeb863d73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nom du fichier :  /root/.cache/kagglehub/datasets/noobiedatascientist/lichess-september-2020-data/versions/3/Sept_20_analysis.csv\n"
          ]
        }
      ],
      "source": [
        "filename = f\"{path}/Sept_20_analysis.csv\"\n",
        "print(\"Nom du fichier : \", filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bj58yVL60pPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ccb1db7-cd07-44a7-b324-4649defc4955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAME: Game ID (not from lichess.org)\n",
            "\n",
            "BlackElo: Elo rating of the player with the black pieces\n",
            "\n",
            "BlackRatingDiff: Rating change (gain/loss) after game conclusion for the player with the black pieces\n",
            "\n",
            "Date: Date the game was played\n",
            "\n",
            "ECO: Game opening (ECO notation)\n",
            "\n",
            "Event: Event where the game was played\n",
            "\n",
            "Opening: Game opening\n",
            "\n",
            "Result: Result of the game\n",
            "\n",
            "\t1-0 -- White victory\n",
            "\t0-1 -- Black victory\n",
            "\t1/2-1/2 -- Draw\n",
            "\t* -- Undecided\n",
            "\t\n",
            "Site: URL of the game\n",
            "\n",
            "Termination: Way the game terminated\n",
            "\n",
            "\tTime forfeit -- One of the players ran out of time\n",
            "\tNormal -- Game terminated with check mate\n",
            "\tRules infraction -- Game terminated due to rule breaking\n",
            "\tAbandoned -- Game was abandoned\n",
            "\t\n",
            "TimeControl: Timecontrol in seconds that was used for the game (Starting time: Increment) \n",
            "\n",
            "UTCTime: Time the game was played\n",
            "\n",
            "WhiteElo: Elo rating of the player with the white pieces\n",
            "\n",
            "WhiteRatingDiff: Rating change (gain/loss) after game conclusion for the player with the white pieces\n",
            "\n",
            "Black_elo_category: ELO category of the player with the black pieces\n",
            "\n",
            "\tLow rating -- Rating below 1900\n",
            "\tHigh rating -- Rating above 1900 and below 2400\n",
            "\tGM rating -- Rating above 2400\n",
            "\t\n",
            "starting_time: The time in seconds that the players have available at the start of the game (taken from TimeControl)\n",
            "\n",
            "\tEMPTY -- Correspondence games\n",
            "\t\n",
            "increment: Time increment in seconds that was used in the game (taken from TimeControl)\n",
            "\n",
            "\tEMPTY -- Correspondence games\n",
            "\n",
            "Game_type: Type of game based on TimeControl\n",
            "\n",
            "\tBullet -- Starting time below 2 minutes\n",
            "\tBlitz -- Starting time between 2 and 10 minutes\n",
            "\tRapid -- Starting time between 10 and 15 minutes\n",
            "\tClassical -- Starting time above 15 minutes or increment 2 minutes or higher\n",
            "\tCorrespondence -- No time information\n",
            "\t\n",
            "Total_moves: Total number of moves in the game\n",
            "\n",
            "Black_blunders: Number of blunders by the player with the black pieces (move annotation ?? in the PGN)\n",
            "\n",
            "White_blunders: Number of blunders by the player with the white pieces (move annotation ?? in the PGN)\n",
            "\n",
            "Black_mistakes: Number of mistakes by the player with the black pieces (move annotation ? in the PGN)\n",
            "\n",
            "White_mistakes: Number of mistakes by the player with the white pieces (move annotation ? in the PGN)\n",
            "\n",
            "Black_inaccuracies: Number of inaccuracies by the player with the black pieces (move annotation ?! in the PGN)\n",
            "\n",
            "White_inaccuracies: Number of inaccuracies by the player with the white pieces (move annotation ?! in the PGN)\n",
            "\n",
            "Black_inferior_moves: Black_blunders + Black_mistakes + Black_inaccuracies \n",
            "\n",
            "White_inferior_moves: White_blunders + White_mistakes + White_inaccuracies\n",
            "\n",
            "Black_ts_moves: Number of moves by the player with the black pieces in time scramble (remaining time less than or equal to 10% of the starting time)\n",
            "\n",
            "White_ts_moves: Number of moves by the player with the white pieces in time scramble (remaining time less than or equal to 10% of the starting time)\n",
            "\n",
            "Black_ts_blunders: Number of blunders by the player with the black pieces in time scramble (remaining time less than or equal to 10% of the starting time)\n",
            "\n",
            "White_ts_blunders: Number of blunders by the player with the white pieces in time scramble (remaining time less than or equal to 10% of the starting time)\n",
            "\n",
            "Black_ts_mistakes: Number of mistakes by the player with the black pieces in time scramble (remaining time less than or equal to 10% of the starting time)\n",
            "\n",
            "White_ts_mistakes: Number of mistakes by the player with the white pieces in time scramble (remaining time less than or equal to 10% of the starting time)\n",
            "\n",
            "Black_long_moves: Number of moves by the player with the black pieces that required more than 10% of the starting time\n",
            "\n",
            "White_long_moves: Number of moves by the player with the white pieces that required more than 10% of the starting time\n",
            "\n",
            "Black_bad_long_moves: Number of long moves by the player with the black pieces that were inferior\n",
            "\n",
            "White_bad_long_moves: Number of long moves by the player with the white pieces that were inferior \n",
            "\n",
            "Game_flips: Number of times in the game where the balance of the game changed\n",
            "\n",
            "Game_flips_ts: Number of times in the game where the balance of the game changed and the players were in time scramble\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# voir le contenu du .txt\n",
        "filename_txt = f\"{path}/Column information.txt\"\n",
        "with open(filename_txt, 'r') as f:\n",
        "    print(f.read())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHbCTsTR4S6e"
      },
      "source": [
        "### Lancement de Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uiPqfPJdY4Lx"
      },
      "outputs": [],
      "source": [
        "# Importation des éléments Spark\n",
        "from pyspark.sql.functions import col, when, isnull, floor, count, min as spark_min, max as spark_max, countDistinct, row_number, split, concat_ws, sum as spark_sum, rank\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YEcWzry24SZ4"
      },
      "outputs": [],
      "source": [
        "findspark.init()\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wQTMYx5g4SXb"
      },
      "outputs": [],
      "source": [
        "sc = spark.sparkContext\n",
        "df_spark = spark.read.csv(filename, header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-KMIg7qx4ihe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b969ac-e749-4b96-a24b-09152d394242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- GAME: integer (nullable = true)\n",
            " |-- BlackElo: integer (nullable = true)\n",
            " |-- BlackRatingDiff: integer (nullable = true)\n",
            " |-- Date: string (nullable = true)\n",
            " |-- ECO: string (nullable = true)\n",
            " |-- Event: string (nullable = true)\n",
            " |-- Opening: string (nullable = true)\n",
            " |-- Result: string (nullable = true)\n",
            " |-- Site: string (nullable = true)\n",
            " |-- Termination: string (nullable = true)\n",
            " |-- TimeControl: string (nullable = true)\n",
            " |-- UTCTime: timestamp (nullable = true)\n",
            " |-- WhiteElo: integer (nullable = true)\n",
            " |-- WhiteRatingDiff: integer (nullable = true)\n",
            " |-- Black_elo_category: string (nullable = true)\n",
            " |-- White_elo_category: string (nullable = true)\n",
            " |-- starting_time: integer (nullable = true)\n",
            " |-- increment: integer (nullable = true)\n",
            " |-- Game_type: string (nullable = true)\n",
            " |-- Total_moves: integer (nullable = true)\n",
            " |-- Black_blunders: integer (nullable = true)\n",
            " |-- White_blunders: integer (nullable = true)\n",
            " |-- Black_mistakes: integer (nullable = true)\n",
            " |-- White_mistakes: integer (nullable = true)\n",
            " |-- Black_inaccuracies: integer (nullable = true)\n",
            " |-- White_inaccuracies: integer (nullable = true)\n",
            " |-- Black_inferior_moves: integer (nullable = true)\n",
            " |-- White_inferior_moves: integer (nullable = true)\n",
            " |-- Black_ts_moves: integer (nullable = true)\n",
            " |-- White_ts_moves: integer (nullable = true)\n",
            " |-- Black_ts_blunders: integer (nullable = true)\n",
            " |-- White_ts_blunders: integer (nullable = true)\n",
            " |-- Black_ts_mistakes: integer (nullable = true)\n",
            " |-- White_ts_mistake: integer (nullable = true)\n",
            " |-- Black_long_moves: integer (nullable = true)\n",
            " |-- White_long_moves: integer (nullable = true)\n",
            " |-- Black_bad_long_moves: integer (nullable = true)\n",
            " |-- White_bad_long_moves: integer (nullable = true)\n",
            " |-- Game_flips: integer (nullable = true)\n",
            " |-- Game_flips_ts: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_spark.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VrCaCyNT_rtu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4b2fa19-2555-4295-b406-0d2d8d2ab14c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3739909"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# nombre lignes\n",
        "df_spark.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XiSTXCRS4ife",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "688593f8-e170-4d39-8cee-44b8e63d068e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+---------------+----------+---+----------------+--------------------+------+--------------------+------------+-----------+-------------------+--------+---------------+------------------+------------------+-------------+---------+---------+-----------+--------------+--------------+--------------+--------------+------------------+------------------+--------------------+--------------------+--------------+--------------+-----------------+-----------------+-----------------+----------------+----------------+----------------+--------------------+--------------------+----------+-------------+\n",
            "|GAME|BlackElo|BlackRatingDiff|      Date|ECO|           Event|             Opening|Result|                Site| Termination|TimeControl|            UTCTime|WhiteElo|WhiteRatingDiff|Black_elo_category|White_elo_category|starting_time|increment|Game_type|Total_moves|Black_blunders|White_blunders|Black_mistakes|White_mistakes|Black_inaccuracies|White_inaccuracies|Black_inferior_moves|White_inferior_moves|Black_ts_moves|White_ts_moves|Black_ts_blunders|White_ts_blunders|Black_ts_mistakes|White_ts_mistake|Black_long_moves|White_long_moves|Black_bad_long_moves|White_bad_long_moves|Game_flips|Game_flips_ts|\n",
            "+----+--------+---------------+----------+---+----------------+--------------------+------+--------------------+------------+-----------+-------------------+--------+---------------+------------------+------------------+-------------+---------+---------+-----------+--------------+--------------+--------------+--------------+------------------+------------------+--------------------+--------------------+--------------+--------------+-----------------+-----------------+-----------------+----------------+----------------+----------------+--------------------+--------------------+----------+-------------+\n",
            "|  11|    1143|              6|2020.09.01|A02|Rated Blitz game|        Bird Opening|   0-1|https://lichess.o...|Time forfeit|      300+0|2025-01-06 00:00:00|    1180|             -7|        Low rating|        Low rating|          300|        0|    Blitz|         66|             4|             2|             0|             3|                 3|                 1|                   7|                   6|             8|             8|                0|                0|                0|               0|               2|               1|                   1|                   1|         8|            0|\n",
            "|  14|    1504|           NULL|2020.09.01|A04|Rated Blitz game|        Réti Opening|   0-1|https://lichess.o...|      Normal|      300+0|2025-01-06 00:00:00|    1381|           NULL|        Low rating|        Low rating|          300|        0|    Blitz|         64|             2|             1|             1|             1|                 7|                 5|                  10|                   7|             0|             0|                0|                0|                0|               0|               0|               1|                   0|                   0|         6|            0|\n",
            "|  29|    1933|              1|2020.09.01|C41|Rated Blitz game|    Philidor Defense|   0-1|https://lichess.o...|Time forfeit|      300+2|2025-01-06 00:00:00|    1485|             -1|       High rating|        Low rating|          300|        2|    Blitz|         70|             0|             1|             1|             2|                 8|                 8|                   9|                  11|             0|             2|                0|                0|                0|               0|               1|               1|                   1|                   0|         5|            0|\n",
            "|  40|    1710|             10|2020.09.01|B23|Rated Blitz game|Sicilian Defense:...|   0-1|https://lichess.o...|      Normal|      180+2|2025-01-06 00:00:00|    2040|            -11|        Low rating|       High rating|          180|        2|    Blitz|         86|             4|             2|             1|             5|                 3|                 4|                   8|                  11|            18|             0|                4|                0|                0|               0|               3|               1|                   1|                   0|         8|            1|\n",
            "|  55|    1598|             -1|2020.09.01|B03|Rated Rapid game|    Alekhine Defense|   1-0|https://lichess.o...|      Normal|      600+0|2025-01-06 00:00:00|    2163|              0|        Low rating|       High rating|          600|        0|    Rapid|         71|             1|             0|             1|             1|                 6|                 2|                   8|                   3|             0|             0|                0|                0|                0|               0|               0|               0|                   0|                   0|         2|            0|\n",
            "+----+--------+---------------+----------+---+----------------+--------------------+------+--------------------+------------+-----------+-------------------+--------+---------------+------------------+------------------+-------------+---------+---------+-----------+--------------+--------------+--------------+--------------+------------------+------------------+--------------------+--------------------+--------------+--------------+-----------------+-----------------+-----------------+----------------+----------------+----------------+--------------------+--------------------+----------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_spark.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAcsmDlTdOWG"
      },
      "source": [
        "### Préparation générale des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSIXOGwkSCg0"
      },
      "source": [
        "Maintenant que les données sont chargées, nous y ajoutons les catégories ELO basées sur les plages données dans l'énoncé du projet.\n",
        "\n",
        "En plus des 5 catégories définies dans l'énoncé, nous ajoutons \"other lower bound\" et \"other upper bound\" pour les valeurs ELO hors des plages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o89yf5WEXwQT"
      },
      "source": [
        "#### Calcule des catégories ELO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ypAzl9Gh6iWY"
      },
      "outputs": [],
      "source": [
        "# Ajout des catégories ELO\n",
        "# Catégorie ELO du joueur Noir\n",
        "df_spark_plus = df_spark.withColumn(\"Black_ELO_category\",\n",
        "                              when((col(\"BlackElo\") >= 1200) & (col(\"BlackElo\") <= 1499), \"occasional player\")\n",
        "                              .when((col(\"BlackElo\") >= 1500) & (col(\"BlackElo\") <= 1799), \"good club player\")\n",
        "                              .when((col(\"BlackElo\") >= 1800) & (col(\"BlackElo\") <= 1999), \"very good club player\")\n",
        "                              .when((col(\"BlackElo\") >= 2000) & (col(\"BlackElo\") <= 2399), \"national and international level\")\n",
        "                              .when((col(\"BlackElo\") >= 2400) & (col(\"BlackElo\") <= 2800), \"GMI, World Champions\")\n",
        "                              .when((col(\"BlackElo\") < 1200), \"other lower bound\")\n",
        "                              .otherwise(\"other upper bound\")\n",
        "                              )\n",
        "\n",
        "# Catégorie ELO du joueur Blanc\n",
        "df_spark_plus = df_spark_plus.withColumn(\"White_ELO_category\",\n",
        "                              when((col(\"WhiteElo\") >= 1200) & (col(\"WhiteElo\") <= 1499), \"occasional player\")\n",
        "                              .when((col(\"WhiteElo\") >= 1500) & (col(\"WhiteElo\") <= 1799), \"good club player\")\n",
        "                              .when((col(\"WhiteElo\") >= 1800) & (col(\"WhiteElo\") <= 1999), \"very good club player\")\n",
        "                              .when((col(\"WhiteElo\") >= 2000) & (col(\"WhiteElo\") <= 2399), \"national and international level\")\n",
        "                              .when((col(\"WhiteElo\") >= 2400) & (col(\"WhiteElo\") <= 2800), \"GMI, World Champions\")\n",
        "                              .when((col(\"WhiteElo\") < 1200), \"other lower bound\")\n",
        "                              .otherwise(\"other upper bound\")\n",
        "                              )\n",
        "\n",
        "# Catégorie ELO moyenne des 2 joueurs\n",
        "df_spark_plus = df_spark_plus.withColumn(\"Avg_ELO_category\", (col(\"BlackElo\") + col(\"WhiteElo\")) / 2)\n",
        "\n",
        "df_spark_plus = df_spark_plus.withColumn(\"Avg_ELO_category\",\n",
        "                              when((col(\"Avg_ELO_category\") >= 1200) & (col(\"Avg_ELO_category\") <= 1499), \"occasional player\")\n",
        "                              .when((col(\"Avg_ELO_category\") >= 1500) & (col(\"Avg_ELO_category\") <= 1799), \"good club player\")\n",
        "                              .when((col(\"Avg_ELO_category\") >= 1800) & (col(\"Avg_ELO_category\") <= 1999), \"very good club player\")\n",
        "                              .when((col(\"Avg_ELO_category\") >= 2000) & (col(\"Avg_ELO_category\") <= 2399), \"national and international level\")\n",
        "                              .when((col(\"Avg_ELO_category\") >= 2400) & (col(\"Avg_ELO_category\") <= 2800), \"GMI, World Champions\")\n",
        "                              .when((col(\"Avg_ELO_category\") < 1200), \"other lower bound\")\n",
        "                              .otherwise(\"other upper bound\")\n",
        "                              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vdeN_nAW6iUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f78a2ca-ed3b-4cd1-ec47-918659b14493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre de parties avec other lower bound pour le joueur noir : 474566\n",
            "Nombre de parties avec other lower bound pour le joueur blanc : 477997\n",
            "Nombre de parties avec other upper bound pour le joueur noir : 1730\n",
            "Nombre de parties avec other upper bound pour le joueur blanc : 1721\n"
          ]
        }
      ],
      "source": [
        "# vérifier combien de \"other ...\"\n",
        "other_lower_bound_black = df_spark_plus.filter(col(\"Black_ELO_category\") == \"other lower bound\").count()\n",
        "other_lower_bound_white = df_spark_plus.filter(col(\"White_ELO_category\") == \"other lower bound\").count()\n",
        "other_upper_bound_black = df_spark_plus.filter(col(\"Black_ELO_category\") == \"other upper bound\").count()\n",
        "other_upper_bound_white = df_spark_plus.filter(col(\"White_ELO_category\") == \"other upper bound\").count()\n",
        "print(f\"Nombre de parties avec other lower bound pour le joueur noir : {other_lower_bound_black}\")\n",
        "print(f\"Nombre de parties avec other lower bound pour le joueur blanc : {other_lower_bound_white}\")\n",
        "print(f\"Nombre de parties avec other upper bound pour le joueur noir : {other_upper_bound_black}\")\n",
        "print(f\"Nombre de parties avec other upper bound pour le joueur blanc : {other_upper_bound_white}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFVmQEXcF2ep"
      },
      "outputs": [],
      "source": [
        "# répartition du nombre de parties pour avg\n",
        "avg_other_lower_bound = df_spark_plus.filter(col(\"Avg_ELO_category\") == \"other lower bound\").count()\n",
        "avg_occasional_player = df_spark_plus.filter(col(\"Avg_ELO_category\") == \"occasional player\").count()\n",
        "avg_good_club_player = df_spark_plus.filter(col(\"Avg_ELO_category\") == \"good club player\").count()\n",
        "avg_very_good_club_player = df_spark_plus.filter(col(\"Avg_ELO_category\") == \"very good club player\").count()\n",
        "avg_national_international_level = df_spark_plus.filter(col(\"Avg_ELO_category\") == \"national and international level\").count()\n",
        "avg_GMI_World_Champions = df_spark_plus.filter(col(\"Avg_ELO_category\") == \"GMI, World Champions\").count()\n",
        "avg_other_upper_bound = df_spark_plus.filter(col(\"Avg_ELO_category\") == \"other upper bound\").count()\n",
        "\n",
        "# répartition du nombre de parties quand les 2 joueurs sont dans la même catégorie\n",
        "same_player_other_lower_bound = df_spark_plus.filter((col(\"Black_ELO_category\") == \"other lower bound\") & (col(\"White_ELO_category\") == \"other lower bound\")).count()\n",
        "same_player_occasional_player = df_spark_plus.filter((col(\"Black_ELO_category\") == \"occasional player\") & (col(\"White_ELO_category\") == \"occasional player\")).count()\n",
        "same_player_good_club_player = df_spark_plus.filter((col(\"Black_ELO_category\") == \"good club player\") & (col(\"White_ELO_category\") == \"good club player\")).count()\n",
        "same_player_very_good_club_player = df_spark_plus.filter((col(\"Black_ELO_category\") == \"very good club player\") & (col(\"White_ELO_category\") == \"very good club player\")).count()\n",
        "same_player_national_international_level = df_spark_plus.filter((col(\"Black_ELO_category\") == \"national and international level\") & (col(\"White_ELO_category\") == \"national and international level\")).count()\n",
        "same_player_GMI_World_Champions = df_spark_plus.filter((col(\"Black_ELO_category\") == \"GMI, World Champions\") & (col(\"White_ELO_category\") == \"GMI, World Champions\")).count()\n",
        "same_player_other_upper_bound = df_spark_plus.filter((col(\"Black_ELO_category\") == \"other upper bound\") & (col(\"White_ELO_category\") == \"other upper bound\")).count()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzgBXJ82CU2G"
      },
      "outputs": [],
      "source": [
        "# Visualiser la répartition des catégories\n",
        "\n",
        "categories = [\n",
        "    \"other lower bound\", \"occasional player\", \"good club player\",\n",
        "    \"very good club player\", \"national and international level\", \"GMI, World Champions\",\n",
        "    \"other upper bound\"\n",
        "]\n",
        "avg_counts = [\n",
        "    avg_other_lower_bound, avg_occasional_player, avg_good_club_player,\n",
        "    avg_very_good_club_player, avg_national_international_level, avg_GMI_World_Champions,\n",
        "    avg_other_upper_bound\n",
        "]\n",
        "same_player_counts = [\n",
        "    same_player_other_lower_bound, same_player_occasional_player, same_player_good_club_player,\n",
        "    same_player_very_good_club_player, same_player_national_international_level, same_player_GMI_World_Champions,\n",
        "    same_player_other_upper_bound\n",
        "]\n",
        "\n",
        "df_counts = pd.DataFrame({\n",
        "    'Category': categories,\n",
        "    'Avg_ELO_category': avg_counts,\n",
        "    'Same_Player_ELO_category': same_player_counts\n",
        "})\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "df_counts.set_index('Category')[['Avg_ELO_category', 'Same_Player_ELO_category']].plot(kind='bar', ax=plt.gca(), color=['skyblue', 'lightcoral'])\n",
        "plt.xlabel('ELO Categories', fontsize=12)\n",
        "plt.ylabel('Number of Games', fontsize=12)\n",
        "plt.title('Répartition du nombre de parties pour chaque catégorie d\\'ELO', fontsize=14)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend(['Avg ELO Category', 'Same Player ELO Category'])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoQZXsVnVaQm"
      },
      "source": [
        "La répartition des données, bien que déséquilibrée entre les catégories, semble réaliste.\n",
        "\n",
        "En effet, le nombre de parties avec des joueurs de niveaux intermédiaires est plus élevé, car ils représentent la plupart des joueurs actifs qui jouent régulièrement. Au contraire, le nombre de parties avec des joueurs ayant des niveaux extrêmes (faible ou élevé) est plus faible. Nous pouvons expliquer cela par le fait que les joueurs de bas niveau évoluent rapidement ou ne jouent pas beaucoup de parties, et les joueurs avec de hauts niveaux sont plus rares dû à la difficulté d'atteindre ces niveaux.\n",
        "\n",
        "Ce déséquilibre naturel pourrait introduire un biais dans l'analyse, car certaines catégories sont sur/sous-représentées."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK1JnDk6MMqE"
      },
      "source": [
        "#### Récupérer le nombre de mouvements par joueur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wqo_RBUW7UzI"
      },
      "outputs": [],
      "source": [
        "# Compter le nombre de moves pour chaque joueur (c'est White qui commence)\n",
        "df_spark_plus = df_spark_plus.withColumn(\"white_moves\",\n",
        "                                         when(col(\"Total_moves\") % 2 == 0, col(\"Total_moves\") / 2)\n",
        "                                         .otherwise(floor(col(\"Total_moves\") / 2) + 1)\n",
        "                                         )\n",
        "df_spark_plus = df_spark_plus.withColumn(\"black_moves\",\n",
        "                                         when(col(\"Total_moves\") % 2 == 0, col(\"Total_moves\") / 2)\n",
        "                                         .otherwise(floor(col(\"Total_moves\") / 2))\n",
        "                                         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-NpaXh38W9m"
      },
      "outputs": [],
      "source": [
        "df_spark_plus.select(\"Total_moves\", \"white_moves\", \"black_moves\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rru1FJEWpR5f"
      },
      "source": [
        "#### Vérification des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQPaHqZypRBO"
      },
      "outputs": [],
      "source": [
        "# TODO : Décider si on garde cette partie\n",
        "# je l'appelerais pas comme ça mai sje pense on garde"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nwC7P5S8x6B"
      },
      "source": [
        "##### **Valeurs NULL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGSVVh9i7llY"
      },
      "outputs": [],
      "source": [
        "# Calcule valeurs null par colonnes\n",
        "null_counts = df_spark.select(\n",
        "    *[\n",
        "        count(when(col(c).isNull(), c)).alias(c)\n",
        "        for c in df_spark.columns\n",
        "    ]\n",
        ")\n",
        "\n",
        "null_counts.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxLZyOkVNiMc"
      },
      "source": [
        "##### **Colonnes Opening et ECO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzX8PA4EQ2vl"
      },
      "outputs": [],
      "source": [
        "# TODO : J'ai checké sur Google, et c'est connu que ECO c'est par comme Opening lol (donc je pense on vire)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41P8vKRnZ6kH"
      },
      "source": [
        "Les colonnes \"Opening\" et \"ECO\" correspondent aux ouvertures et aux codes d'ouvertures, nous regardons si elles sont en liens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfgPipGf5Fdo"
      },
      "outputs": [],
      "source": [
        "# Nombre valeurs opening\n",
        "print(f\"Nombre de valeurs opening : {df_spark.select('Opening').distinct().count()}\")\n",
        "print(f\"Nombre de valeurs ECO : {df_spark.select('ECO').distinct().count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn4f69Fx17ju"
      },
      "outputs": [],
      "source": [
        "#  Checker si une valeur de Opening = une valeur de ECO\n",
        "alignment_check_1 = df_spark.groupBy(\"ECO\").agg(countDistinct(\"Opening\").alias(\"Unique_Openings\"))\n",
        "misaligned_rows_1 = alignment_check_1.filter(col(\"Unique_Openings\") > 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gu0Edcv32tO5"
      },
      "outputs": [],
      "source": [
        "# Afficher les résultats\n",
        "if misaligned_rows_1.count() > 0:\n",
        "    print(\"Il existe plusieurs Openings pour un code ECO.\")\n",
        "    misaligned_rows_1.show(5)\n",
        "    print(\"Nombre de lignes : \", misaligned_rows_1.count())\n",
        "else:\n",
        "    print(\"Il existe un seul Opening pour un code ECO.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPLNZ7I_2wm2"
      },
      "outputs": [],
      "source": [
        "#  Checker si une valeur de ECO = une valeur de Opening\n",
        "alignment_check_2 = df_spark.groupBy(\"Opening\").agg(countDistinct(\"ECO\").alias(\"Unique_ECOs\"))\n",
        "misaligned_rows_2 = alignment_check_2.filter(col(\"Unique_ECOs\") > 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-1nR4KR3f8j"
      },
      "outputs": [],
      "source": [
        "# Afficher les résultats\n",
        "if misaligned_rows_2.count() > 0:\n",
        "    print(\"Il existe plusieurs ECO pour un code Opening.\")\n",
        "    misaligned_rows_2.show(5)\n",
        "    print(\"Nombre de lignes : \", misaligned_rows_2.count())\n",
        "else:\n",
        "    print(\"Il existe un seul ECO pour un code Opening.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZaOgJPZaC4H"
      },
      "source": [
        "Nous remarquons qu'un Opening peut avoir plusieurs ECO, et qu'un ECO peut également avoir plusieurs Opening.  \n",
        "Nous allons regarder si c'est normal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb3pNGYNQk5g"
      },
      "outputs": [],
      "source": [
        "# Filtrer pour les ouvertures ayant plusieurs ECO\n",
        "misaligned_rows_2 = alignment_check_2.filter(col(\"Unique_ECOs\") > 1)\n",
        "opening_eco_counts = df_spark.groupBy(\"Opening\", \"ECO\").agg(count(\"*\").alias(\"count\"))\n",
        "multiple_opening_eco_counts = misaligned_rows_2.join(opening_eco_counts, on=\"Opening\", how=\"inner\")\n",
        "multiple_opening_eco_counts.orderBy(\"Opening\", \"count\", ascending=False).show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybFjANGdaKhv"
      },
      "source": [
        "Cela ne semble pas être des erreurs, il n'y a pas de ECO ou Opening largement dominant, nous allons donc garder ces éléments comme cela et les considérer comme 2 colonnes distinctes, n'ayant pas de lien particulier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsJjnr4o-pZd"
      },
      "source": [
        "##### **Colonnes starting_time, increment, et TimeControl**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iIB1NZuNxY4"
      },
      "source": [
        "Nous allons maintenant vérifier si les colonnes \"starting_time\", \"increment\", et \"TimeControl\" sont bien en accord avec la documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9DqgPll9eQB"
      },
      "outputs": [],
      "source": [
        "# Même nombre null pour starting_time et increment, on vérifie que c'est aligné\n",
        "df_spark.filter(col(\"starting_time\").isNull() & col(\"increment\").isNull()).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5GbM2Wu9vwu"
      },
      "outputs": [],
      "source": [
        "# Afficher les type de game quand ces 2 colonnes sont NULL\n",
        "df_spark.filter(col(\"starting_time\").isNull() & col(\"increment\").isNull()).select(\"Game_type\").distinct().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mw_BCfA-bLo"
      },
      "outputs": [],
      "source": [
        "# Afficher les parties avec type de jeu Correspondence et starting_time ou increment non null\n",
        "df_spark.filter((col(\"Game_type\") == \"Correspondence\") & (col(\"starting_time\").isNotNull() | col(\"increment\").isNotNull())).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW0Dag3m9-dp"
      },
      "source": [
        "Cela correspond à ce qui est attendu.\n",
        "\n",
        "Maintenant, nous vérifions que TimeControl correspond bien à `starting_time+increment`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tERsB8fVQI0"
      },
      "outputs": [],
      "source": [
        "# Extraire starting_time et increment à partir de TimeControl\n",
        "df_spark_check = df_spark.withColumn(\n",
        "    \"starting_time_extracted\",\n",
        "    when(col(\"TimeControl\") != \"-\", split(col(\"TimeControl\"), \"\\+\")[0].cast(\"int\"))\n",
        "    .otherwise(None))\n",
        "\n",
        "df_spark_check = df_spark_check.withColumn(\n",
        "    \"increment_extracted\",\n",
        "    when(col(\"TimeControl\") != \"-\", split(col(\"TimeControl\"), \"\\+\")[1].cast(\"int\"))\n",
        "    .otherwise(None))\n",
        "\n",
        "# Recréer TimeControl avec les colonnes extraites\n",
        "df_spark_check = df_spark_check.withColumn(\n",
        "    \"TimeControl_reconstructed\",\n",
        "    when(col(\"starting_time_extracted\").isNull() & col(\"increment_extracted\").isNull(), \"-\")\n",
        "    .otherwise(concat_ws(\"+\", col(\"starting_time_extracted\"), col(\"increment_extracted\")))\n",
        ")\n",
        "\n",
        "# Comparer TimeControl avec la recréation\n",
        "df_spark_check = df_spark_check.withColumn(\n",
        "    \"is_matching\",\n",
        "    col(\"TimeControl\") == col(\"TimeControl_reconstructed\")\n",
        ")\n",
        "\n",
        "# Checker les résultats\n",
        "df_spark_check.select(\"TimeControl\", \"starting_time\", \"increment\", \"starting_time_extracted\", \"increment_extracted\", \"TimeControl_reconstructed\", \"is_matching\").show(5)\n",
        "mismatch_count = df_spark_check.filter(col(\"is_matching\") == False).count()\n",
        "print(f\"Nombre de différences : {mismatch_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D38qs6o9-vVZ"
      },
      "source": [
        "##### **Colonnes BlackRatingDiff et WhiteRatingDiff**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PH8XgtKj-BK1"
      },
      "outputs": [],
      "source": [
        "df_spark.filter(col(\"BlackRatingDiff\").isNull() & col(\"WhiteRatingDiff\").isNull()).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mK_TlfLt__dN"
      },
      "outputs": [],
      "source": [
        "# pourcentage null\n",
        "prc_missed = round(df_spark.filter(col(\"BlackRatingDiff\").isNull() | col(\"WhiteRatingDiff\").isNull()).count()/df_spark.count()*100,2)\n",
        "print(f\"Pourcentage de NULL : {prc_missed}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir--SwpeQdIE"
      },
      "source": [
        "## Réponses aux questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T74gZM0NPDmJ"
      },
      "source": [
        "### Question 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvLr91m_i4mu"
      },
      "outputs": [],
      "source": [
        "# TODO rregarder au global inferior moves aussi ?\n",
        "# Charlotte : \"si c'est un commentaire pour moi, j'ai pas compris ce que ça veut dire mdrrr\"\n",
        "# pov : j'écris comme le théatre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XEtPJrWOqkm"
      },
      "source": [
        "*Q1: What is the rate of blunders, errors and inaccuracies per move, per level category and on Blitz type games (Blitz type is by far the most played on these online sites). A game has two players, whose ELOs are most likely different. You will be able to classify a game into a category, either by considering the average ELO of both players, or by considering only the games where both players are in the same category.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GljHcFnAbLcJ"
      },
      "source": [
        "**Hypothèse :** Les joueurs appartenant à des catégories plus expérimentées devraient présenter un taux d'erreurs plus faible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRA97x6ZQFls"
      },
      "outputs": [],
      "source": [
        "# Filtre les parties avec le type de jeu Blitz\n",
        "df_blitz = df_spark_plus.filter(col(\"Game_type\") == \"Blitz\")\n",
        "df_blitz.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQv8TwoKXrxT"
      },
      "source": [
        "#### Calcule des taux par partie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBnGnO-5QbsD"
      },
      "outputs": [],
      "source": [
        "# Calcule taux de blunders\n",
        "df_blitz = df_blitz.withColumn(\"Black_blunders_rate\", col(\"Black_blunders\") / col(\"black_moves\")) \\\n",
        "                   .withColumn(\"White_blunders_rate\", col(\"White_blunders\") / col(\"white_moves\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxP7iixpRX06"
      },
      "outputs": [],
      "source": [
        "# Calcule taux d'errors\n",
        "df_blitz = df_blitz.withColumn(\"Black_errors_rate\", col(\"Black_mistakes\") / col(\"black_moves\")) \\\n",
        "                   .withColumn(\"White_errors_rate\", col(\"White_mistakes\") / col(\"white_moves\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xI1qobZ_R_CU"
      },
      "outputs": [],
      "source": [
        "# Calcule taux d'inaccuracies\n",
        "df_blitz = df_blitz.withColumn(\"Black_inaccuracies_rate\", col(\"Black_inaccuracies\") / col(\"black_moves\")) \\\n",
        "                   .withColumn(\"White_inaccuracies_rate\", col(\"White_inaccuracies\") / col(\"white_moves\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEG83zrNXzT6"
      },
      "source": [
        "#### Calcule des taux moyens par catégorie ELO (on considère le score ELO moyen des 2 joueurs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdklkG0cX6Zh"
      },
      "outputs": [],
      "source": [
        "df_avg_elo_summary = df_blitz.groupBy(\"Avg_ELO_category\").agg(\n",
        "    {\"Black_blunders_rate\": \"avg\", \"White_blunders_rate\": \"avg\",\n",
        "     \"Black_errors_rate\": \"avg\", \"White_errors_rate\": \"avg\",\n",
        "     \"Black_inaccuracies_rate\": \"avg\", \"White_inaccuracies_rate\": \"avg\"}\n",
        ").withColumnRenamed(\"avg(Black_blunders_rate)\", \"Avg_Black_blunders_rate\") \\\n",
        " .withColumnRenamed(\"avg(White_blunders_rate)\", \"Avg_White_blunders_rate\") \\\n",
        " .withColumnRenamed(\"avg(Black_errors_rate)\", \"Avg_Black_errors_rate\") \\\n",
        " .withColumnRenamed(\"avg(White_errors_rate)\", \"Avg_White_errors_rate\") \\\n",
        " .withColumnRenamed(\"avg(Black_inaccuracies_rate)\", \"Avg_Black_inaccuracies_rate\") \\\n",
        " .withColumnRenamed(\"avg(White_inaccuracies_rate)\", \"Avg_White_inaccuracies_rate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUmnTnbIPxTX"
      },
      "outputs": [],
      "source": [
        "df_avg_elo_summary.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsfB62FrYR55"
      },
      "outputs": [],
      "source": [
        "df_avg_elo_summary_pandas = df_avg_elo_summary.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmO5nsP2a2Fz"
      },
      "outputs": [],
      "source": [
        "df_avg_elo_summary_pandas.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff1S4mlyYblk"
      },
      "outputs": [],
      "source": [
        "# Ordonner les catégories de joueurs\n",
        "category_order = [\"other lower bound\", \"occasional player\", \"good club player\", \"very good club player\",\n",
        "                  \"national and international level\", \"GMI, World Champions\", \"other upper bound\"]\n",
        "df_avg_elo_summary_pandas['Avg_ELO_category'] = pd.Categorical(df_avg_elo_summary_pandas['Avg_ELO_category'],  categories=category_order,  ordered=True)\n",
        "df_avg_elo_summary_pandas = df_avg_elo_summary_pandas.sort_values('Avg_ELO_category')\n",
        "\n",
        "\n",
        "categories = df_avg_elo_summary_pandas['Avg_ELO_category']\n",
        "error_types = ['Blunders', 'Errors', 'Inaccuracies']\n",
        "\n",
        "# Données par type d'erreur et catégorie\n",
        "blunders = df_avg_elo_summary_pandas[['Avg_Black_blunders_rate', 'Avg_White_blunders_rate']].mean(axis=1)*100\n",
        "mistakes = df_avg_elo_summary_pandas[['Avg_Black_errors_rate', 'Avg_White_errors_rate']].mean(axis=1)*100\n",
        "inaccuracies = df_avg_elo_summary_pandas[['Avg_Black_inaccuracies_rate', 'Avg_White_inaccuracies_rate']].mean(axis=1)*100\n",
        "\n",
        "# Matrice (erreurs x catégorie)\n",
        "data = np.array([blunders, mistakes, inaccuracies]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTpkiqb2cMMX"
      },
      "outputs": [],
      "source": [
        "# Graphique\n",
        "plt.figure(figsize=(14, 8))\n",
        "x = np.arange(len(error_types))\n",
        "bar_width = 0.1\n",
        "\n",
        "for i, category in enumerate(categories):\n",
        "    plt.bar(x + i * bar_width, data[i], width=bar_width, label=str(category))\n",
        "\n",
        "plt.xlabel('Taux de fautes')\n",
        "plt.ylabel('Pourcentage de taux moyen')\n",
        "plt.title('Moyenne des taux de fautes par catégorie (Catégorie moyenne)')\n",
        "plt.xticks(x + bar_width * (len(categories) - 1) / 2, error_types)\n",
        "plt.legend(title=\"Catégorie ELO\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF6InvGrNm7z"
      },
      "source": [
        "##### **Analyse des taux de blunders, errors et inaccuracies selon les catégories d'ELO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIR-GSCib51F"
      },
      "source": [
        "Lorsque l'on analyse les taux de blunders, errors et inaccuracies en fonction des différentes catégories ELO, plusieurs tendances intéressantes émergent.  \n",
        "En excluant la catégorie \"Other Upper Bound\", on observe une diminution progressive des taux de **bourdes** (blunders) à mesure que les catégories augmentent, avec une chute de moins en moins marquée. Cela suggère qu'il y a une amélioration du niveau des joueurs en fonction de leur catégorie ELO, bien qu'elle soit de moins en moins évidente pour les catégories les plus expérimentées.\n",
        "\n",
        "Concernant les taux d'**erreurs** (errors), la diminution est relativement constante à travers les catégories, mais on remarque une chute plus importante lorsque l'on atteint les deux meilleures catégories (\"National and International Level\" et \"GMI, World Champions\"). Cela indique une amélioration notable dans la gestion des erreurs pour les joueurs de niveau supérieur.\n",
        "\n",
        "Quant aux taux d'**imprécisions** (inaccuracies), la tendance reste assez stable pour les premières catégories, avec une diminution qui s'accélère à mesure que l'on approche des deux catégories les plus élevées. Cette tendance suggère également une amélioration du jeu des joueurs plus expérimentés.\n",
        "\n",
        "En résumé, **les taux diminuent sensiblement à mesure que l'on progresse dans les catégories ELO**, avec une amélioration plus marquée pour les catégories \"National and International Level\" et \"GMI, World Champions\", ce qui reflète probablement un meilleur contrôle stratégique et une plus grande expérience des joueurs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf-oBNyZb8nr"
      },
      "source": [
        "##### **Analyse de la catégorie \"Other Upper Bound\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl0aqSJOb-t9"
      },
      "source": [
        "Lorsque l'on considère la catégorie \"Other Upper Bound\", une tendance différente se dessine.  \n",
        "Les taux de blunders, errors et inaccuracies semblent augmenter pour atteindre une **valeur entre celle des catégories \"Good Club Player\" et \"Very Good Club Player\"**.\n",
        "\n",
        "Cette anomalie pourrait suggérer plusieurs pistes d'interprétation.  \n",
        "Tout d'abord, il est possible que cette catégorie contienne des **données** qui ne sont **pas représentatives** du reste des catégories en raison d'un échantillon trop faible ou non nettoyé correctement.\n",
        "\n",
        "Une autre hypothèse pourrait être que la **performance** des joueurs dans cette catégorie est **influencée** par la moyenne des ELO des deux joueurs, et non seulement par l'ELO individuel.  \n",
        "Par exemple, un joueur avec un ELO élevé qui affronte un adversaire de niveau inférieur pourrait être amené à prendre plus de risques ou adopter des stratégies différentes, ce qui expliquerait certains résultats.  \n",
        "De plus, il est possible qu'une partie classée dans la catégorie \"Other upper bound\" n'inclue qu'un seul joueur avec un ELO très élevé, ce qui fausse la moyenne des deux scores ELO et pourrait influencer l'analyse des performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it5jufdcX3K8"
      },
      "source": [
        "#### Calcule des taux moyens par catégorie ELO (ici on considère seulement les parties où les joueurs sont dans la même catégorie)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUfv1BQDX224"
      },
      "outputs": [],
      "source": [
        "df_same_category = df_blitz.filter(col(\"Black_ELO_category\") == col(\"White_ELO_category\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wwa42HNxhrYe"
      },
      "outputs": [],
      "source": [
        "tot_blitz = df_blitz.count()\n",
        "tot_same_cat = df_same_category.count()\n",
        "print(f\"Nombre de parties total : {tot_blitz}\")\n",
        "print(f\"Nombre de parties avec 2 joueurs de la même catégorie : {tot_blitz}\")\n",
        "print(f\"Pourcentage même catégorie : {tot_same_cat / tot_blitz * 100} %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E8WMVXZYBf6"
      },
      "outputs": [],
      "source": [
        "df_same_category_summary = df_same_category.groupBy(\"Black_ELO_category\").agg(\n",
        "    {\"Black_blunders_rate\": \"avg\", \"White_blunders_rate\": \"avg\",\n",
        "     \"Black_errors_rate\": \"avg\", \"White_errors_rate\": \"avg\",\n",
        "     \"Black_inaccuracies_rate\": \"avg\", \"White_inaccuracies_rate\": \"avg\"}\n",
        ").withColumnRenamed(\"avg(Black_blunders_rate)\", \"Avg_Black_blunders_rate\") \\\n",
        " .withColumnRenamed(\"avg(White_blunders_rate)\", \"Avg_White_blunders_rate\") \\\n",
        " .withColumnRenamed(\"avg(Black_errors_rate)\", \"Avg_Black_errors_rate\") \\\n",
        " .withColumnRenamed(\"avg(White_errors_rate)\", \"Avg_White_errors_rate\") \\\n",
        " .withColumnRenamed(\"avg(Black_inaccuracies_rate)\", \"Avg_Black_inaccuracies_rate\") \\\n",
        " .withColumnRenamed(\"avg(White_inaccuracies_rate)\", \"Avg_White_inaccuracies_rate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_Ye8JmudLX7"
      },
      "outputs": [],
      "source": [
        "df_same_category_summary_pandas = df_same_category_summary.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtSEk6uMfAnG"
      },
      "outputs": [],
      "source": [
        "# Ordonner les catégories de joueurs\n",
        "category_order = [\"other lower bound\", \"occasional player\", \"good club player\", \"very good club player\",\n",
        "                  \"national and international level\", \"GMI, World Champions\", \"other upper bound\"]\n",
        "df_same_category_summary_pandas['Black_ELO_category'] = pd.Categorical(df_same_category_summary_pandas['Black_ELO_category'],  categories=category_order,  ordered=True)\n",
        "df_same_category_summary_pandas = df_same_category_summary_pandas.sort_values('Black_ELO_category')\n",
        "\n",
        "\n",
        "categories = df_same_category_summary_pandas['Black_ELO_category']\n",
        "error_types = ['Blunders', 'Errors', 'Inaccuracies']\n",
        "\n",
        "# Données par type d'erreur et catégorie (moyenne) # TODO : Voir si on fait autrement\n",
        "blunders = df_same_category_summary_pandas[['Avg_Black_blunders_rate', 'Avg_White_blunders_rate']].mean(axis=1)*100\n",
        "mistakes = df_same_category_summary_pandas[['Avg_Black_errors_rate', 'Avg_White_errors_rate']].mean(axis=1)*100\n",
        "inaccuracies = df_same_category_summary_pandas[['Avg_Black_inaccuracies_rate', 'Avg_White_inaccuracies_rate']].mean(axis=1)*100\n",
        "\n",
        "# Matrice (erreurs x catégorie)\n",
        "data = np.array([blunders, mistakes, inaccuracies]).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKlJ7m2AeUJA"
      },
      "outputs": [],
      "source": [
        "# Graphique\n",
        "plt.figure(figsize=(14, 8))\n",
        "x = np.arange(len(error_types))\n",
        "bar_width = 0.1\n",
        "for i, category in enumerate(categories):\n",
        "    plt.bar(x + i * bar_width, data[i], width=bar_width, label=str(category))\n",
        "\n",
        "plt.xlabel('Type de fautes')\n",
        "plt.ylabel('Pourcentage de taux moyen')\n",
        "plt.title('Moyenne des taux de fautes par catégorie (Même catégorie entre les joueurs)')\n",
        "plt.xticks(x + bar_width * (len(categories) - 1) / 2, error_types)\n",
        "plt.legend(title=\"Catégorie ELO\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zANho_i7QPRs"
      },
      "source": [
        "Pour ces parties, où les deux joueurs appartiennent à la même catégorie, **les observations sont similaires** à celles faites pour la moyenne des ELO des joueurs.\n",
        "\n",
        "Cependant, pour la catégorie **\"Other upper bound\"**, on ne constate **pas de réaugmentation** des erreurs et inexactitudes, ce qui confirme que la moyenne des ELO des deux joueurs influençait les résultats dans cette catégorie.\n",
        "\n",
        "Inversement, une légère réaugmentation des blunders est observée entre les catégories \"National and International level\" et \"GMI, World Champions\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8vNfmy-g0d7"
      },
      "source": [
        "#### Résultats globaux"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5acBCPUg3nC"
      },
      "source": [
        "Nous observons des **résultats similaires** entre les parties où les catégories sont basées sur la moyenne des ELO des deux joueurs et celles où les deux joueurs appartiennent à la même catégorie ELO. Nous voyons, en effet, que tous **les taux de fautes ont tendance à diminuer** à mesure que la catégorie ELO augmente.\n",
        "\n",
        "Ce résultat est en accord avec l'hypothèse initiale : Les joueurs appartenant à des catégories plus expérimentées devraient présenter un taux d'erreurs plus faible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGmM--xUgI7N"
      },
      "source": [
        "### Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuH5E2dAgNr7"
      },
      "source": [
        "#### Q2: Win probability depending on opening:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSXAN6fCHjm8"
      },
      "source": [
        "**Hypothèse :** Les openings permettant aux blancs de gagner devrait être différents de ceux permettant aux noirs de gagner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbfRaQZbSsUA"
      },
      "source": [
        "#####  **Q2a: With which opening does White have the best chance to win, by level category (*) and by type of game (Blitz, Fast, Classic).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXkg4q_iK6rM"
      },
      "source": [
        "\n",
        "**Premières observations :**   \n",
        "Nous avons constaté que certaines configurations n’étaient jouées que très rarement et aboutissaient systématiquement à une victoire des Blancs.  \n",
        "Cela introduit un biais et ne permet pas d’identifier correctement quel opening offre réellement le plus de chances de gagner.  \n",
        "En effet, plus de 3 800 configurations présentaient une White_win_probability égale à 1.\n",
        "\n",
        "Nous avons donc décidé de conserver uniquement les configurations avec un nombre élevé de parties jouées afin d’obtenir des résultats plus pertinents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re_28lZVV6vT"
      },
      "source": [
        "Nous allons analyser les configurations possibles, c'est à dire les combinaisons de `Opening`, `White_ELO_category`, et `Game_type`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u75jGBagKp72"
      },
      "outputs": [],
      "source": [
        "# Calculer le nombre de parties pour chaque configuration\n",
        "config_game_counts = df_spark_plus.groupBy(\"Opening\", \"White_ELO_category\", \"Game_type\").agg(count(\"*\").alias(\"Total_games_count\"))\n",
        "config_game_counts.orderBy(\"Total_games_count\", ascending=False).show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJE5RbW9MnpR"
      },
      "outputs": [],
      "source": [
        "# Nombre total de configurations uniques\n",
        "print(f\"Nombre total de configurations possibles : {config_game_counts.count()}\")\n",
        "print(f\"Nombre de configurations possibles pour les différents types de jeux :\")\n",
        "config_game_counts.groupBy(\"Game_type\").count().orderBy(\"count\", ascending=False).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGq_WayW8ppq"
      },
      "outputs": [],
      "source": [
        "# Nombre d'Opening par configurations\n",
        "df_spark_plus.groupBy(\"White_ELO_category\", \"Game_type\").count().orderBy(\"count\", ascending=False).show(34)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3slS8R76SqZ"
      },
      "source": [
        "Nous pouvons voir que le nombre de parties jouées par type de jeux n'est pas répartie de façon uniforme, et que certaines configurations sont très sous représentées."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGq5eexmMrTo"
      },
      "outputs": [],
      "source": [
        "# Filtrer les configurations avec plus de 100 parties jouées\n",
        "filtered_configurations = config_game_counts.filter(col(\"Total_games_count\") > 100)\n",
        "filtered_configurations.orderBy(\"Total_games_count\", ascending=False).show(5)\n",
        "print(f\"Nombre de configurations avec plus de 100 parties jouées : {filtered_configurations.count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeJ6lm0bN_Pn"
      },
      "outputs": [],
      "source": [
        "filtered_df = df_spark_plus.join(filtered_configurations.select(\"Opening\", \"White_ELO_category\", \"Game_type\"), on=[\"Opening\", \"White_ELO_category\", \"Game_type\"], how=\"inner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E65RvfdqMW5E"
      },
      "outputs": [],
      "source": [
        "# Quels sont les différentes valeurs de Game_type ?\n",
        "filtered_df.select(\"Game_type\").distinct().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vf--LJCMux6"
      },
      "source": [
        "L'énoncé précise \"by type of game (Blitz, Fast, Classic)\" mais on voit bien ici que c'est Blitz, \"Rapid\" et \"Classical\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMtXPRSQNDIy"
      },
      "outputs": [],
      "source": [
        "# Comment sont explicités les différentes fin de partie ?\n",
        "filtered_df.select(\"Result\").distinct().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfCDdQADP7Xz"
      },
      "source": [
        "1-0 : Victoire des blancs  \n",
        "0-1 : Victoire des noirs  \n",
        "1/2-1/2 : Match nul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyMMuNQ3glZd"
      },
      "outputs": [],
      "source": [
        "# Récupération des parties voulues (blancs gagnes +  type de jeux Blitz, Fast, Classic)\n",
        "df_white_wins = filtered_df.filter((col(\"Result\") == \"1-0\") & (col(\"Game_type\").isin([\"Blitz\", \"Rapid\", \"Classical\"])))\n",
        "df_total_games = filtered_df.filter(col(\"Game_type\").isin([\"Blitz\", \"Rapid\", \"Classical\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ax5rSGfWcPiO"
      },
      "outputs": [],
      "source": [
        "# Pour chaque ouverture, catégorie et type de jeu on calcule le nombre de victoires des blancs\n",
        "df_white_wins_groupby = df_white_wins.groupBy(\"Opening\", \"White_ELO_category\", \"Game_type\").agg(count(\"*\").alias(\"White_win_count\"))\n",
        "\n",
        "# Pareil mais on calcule le total de parties jouées\n",
        "df_total_games_groupby = df_total_games.groupBy(\"Opening\", \"White_ELO_category\", \"Game_type\").agg(count(\"*\").alias(\"Total_games_count\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2z0MCCPSeZol"
      },
      "outputs": [],
      "source": [
        "df_white_wins_groupby.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvYom_bSejJU"
      },
      "outputs": [],
      "source": [
        "df_total_games_groupby.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JRCvwm1ezys"
      },
      "outputs": [],
      "source": [
        "# Calcule de la probabilité de gagner en fonction de l'ouverture\n",
        "df_opening_stats = df_white_wins_groupby.join(df_total_games_groupby, on=[\"Opening\", \"White_ELO_category\", \"Game_type\"])\n",
        "df_opening_stats = df_opening_stats.withColumn(\"White_win_probability\", col(\"White_win_count\") / col(\"Total_games_count\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCYS9hr6fazc"
      },
      "outputs": [],
      "source": [
        "df_opening_stats.show(5) # TODO ici order by White_win_probability ce sera plus intéressant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bI0zsP9gY4j"
      },
      "outputs": [],
      "source": [
        "df_opening_stats.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5j81vN1RaUaE"
      },
      "outputs": [],
      "source": [
        "# Y a t il toutes les combinaisons de catégorie / type de partie ?\n",
        "df_opening_stats.groupBy(\"White_ELO_category\", \"Game_type\").count().orderBy(\"count\", ascending=False).show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ine3mq-iaweG"
      },
      "source": [
        "Nous pouvons voir que le nombre d'Opening différents (count) pour les combinaisons de catégories ELO et type de jeux n'est pas répartie uniformément, et certaines sont même absentes.\n",
        "\n",
        "Cependant, dans le jeu de données initiale, ces configurations étaient très sous représentées. Notamment :\n",
        "- GMI, World Champions - Rapid -  2163\n",
        "- other upper bound - Blitz - 301\n",
        "- GMI, World Champions - Classical - 232\n",
        "- other upper bound - Rapid - 8\n",
        "- other upper bound - Classical - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DYvuedq_xTv"
      },
      "outputs": [],
      "source": [
        "# Récupération du meilleur opening pour chaque catégorie de joueur et type de partie\n",
        "window_spec = Window.partitionBy(\"White_ELO_category\", \"Game_type\").orderBy(col(\"White_win_probability\").desc())\n",
        "best_openings = df_opening_stats.withColumn(\"rank\", rank().over(window_spec))\n",
        "best_openings = best_openings.filter(col(\"rank\") == 1).select(\"White_ELO_category\", \"Game_type\", \"Opening\", \"White_win_probability\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2faAWk3Dnzp"
      },
      "source": [
        "###### Résultats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2-xcY4-Ddgs"
      },
      "source": [
        "Nous affichons maintenant pour chaque catégorie ELO et type de jeu, l'opening permettant le plus de gagner pour les blancs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQr5WLm9Akvd"
      },
      "outputs": [],
      "source": [
        "best_openings.orderBy(\"White_ELO_category\", \"Game_type\").show(17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L83rRW9pQrtl"
      },
      "outputs": [],
      "source": [
        "best_openings_pandas = best_openings.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2dpsGhbPzrA"
      },
      "outputs": [],
      "source": [
        "best_openings_pandas[\"GameType_Category\"] = (best_openings_pandas[\"Game_type\"] + \" | \" + best_openings_pandas[\"White_ELO_category\"])\n",
        "\n",
        "# Table pivot pour voir le meilleur opening pour chaque configuration\n",
        "pivot_table = best_openings_pandas.pivot_table(\n",
        "    index=\"GameType_Category\",\n",
        "    columns=\"Opening\",\n",
        "    values=\"White_win_probability\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv2RrjNrQ3wW"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
        "plt.title(\"Meilleure opening (plus grande probabilité de victoire) des Blancs pour une catégorie et un Game Type\")\n",
        "plt.xlabel(\"Opening\")\n",
        "plt.ylabel(\"Type de jeu et Catégorie ELO\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRE3qylcSvAR"
      },
      "source": [
        "Nous pouvons voir que l'opening obtenant un meilleur résultat est généralement différent entre les configurations. Cela pourrait montrer qu'il y a un lien entre la victoire, le type de jeu, le niveau du joueur et l'opening choisi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSzOqkhIb368"
      },
      "source": [
        "##### **Q2b: same question with black. You don't need to write again the same but only the results with black.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x85Uley0OQT5"
      },
      "outputs": [],
      "source": [
        "# Calculer le nombre de parties pour chaque configuration\n",
        "config_game_counts = df_spark_plus.groupBy(\"Opening\", \"Black_ELO_category\", \"Game_type\").agg(count(\"*\").alias(\"Total_games_count\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psVamhYVOaXO"
      },
      "outputs": [],
      "source": [
        "# Filtrer les configurations avec plus de 100 parties jouées\n",
        "# TODO : Voir si on adapte le nombre de parties (autre chose que 100)\n",
        "filtered_configurations = config_game_counts.filter(col(\"Total_games_count\") > 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRw162_9ObzZ"
      },
      "outputs": [],
      "source": [
        "filtered_df = df_spark_plus.join(filtered_configurations.select(\"Opening\", \"Black_ELO_category\", \"Game_type\"), on=[\"Opening\", \"Black_ELO_category\", \"Game_type\"], how=\"inner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG4ZJpU3WQXq"
      },
      "outputs": [],
      "source": [
        "df_black_wins = filtered_df.filter((col(\"Result\") == \"0-1\") & (col(\"Game_type\").isin([\"Blitz\", \"Rapid\", \"Classical\"])))\n",
        "df_total_games = filtered_df.filter(col(\"Game_type\").isin([\"Blitz\", \"Rapid\", \"Classical\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuUsplOvdZiD"
      },
      "outputs": [],
      "source": [
        "df_black_wins_groupby = df_black_wins.groupBy(\"Opening\", \"Black_ELO_category\", \"Game_type\").agg(count(\"*\").alias(\"Black_win_count\"))\n",
        "df_total_games_groupby = df_total_games.groupBy(\"Opening\", \"Black_ELO_category\", \"Game_type\").agg(count(\"*\").alias(\"Total_games_count\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypuadmuVdc7l"
      },
      "outputs": [],
      "source": [
        "df_opening_stats = df_black_wins_groupby.join(df_total_games_groupby, on=[\"Opening\", \"Black_ELO_category\", \"Game_type\"])\n",
        "df_opening_stats = df_opening_stats.withColumn(\"Black_win_probability\", col(\"Black_win_count\") / col(\"Total_games_count\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V32knXpTQXXF"
      },
      "source": [
        "Nous affichons maintenant pour chaque catégorie ELO et type de jeu, l'opening (des blancs) permettant le plus de gagner pour les noirs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Vfa2I7odtb1"
      },
      "outputs": [],
      "source": [
        "window_spec = Window.partitionBy(\"Black_ELO_category\", \"Game_type\").orderBy(col(\"Black_win_probability\").desc())\n",
        "best_openings = df_opening_stats.withColumn(\"rank\", rank().over(window_spec))\n",
        "best_openings = best_openings.filter(col(\"rank\") == 1).select(\"Black_ELO_category\", \"Game_type\", \"Opening\", \"Black_win_probability\") # Rank pour garder les égalités\n",
        "best_openings.orderBy(\"Black_ELO_category\", \"Game_type\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Txk0FSCdsrO"
      },
      "outputs": [],
      "source": [
        "best_openings_pandas = best_openings.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuMXExaydc5n"
      },
      "outputs": [],
      "source": [
        "best_openings_pandas[\"GameType_Category\"] = (best_openings_pandas[\"Game_type\"] + \" | \" + best_openings_pandas[\"Black_ELO_category\"])\n",
        "pivot_table = best_openings_pandas.pivot_table(\n",
        "    index=\"GameType_Category\",\n",
        "    columns=\"Opening\",\n",
        "    values=\"Black_win_probability\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9x-fKTidc3n"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
        "plt.title(\"Meilleure opening (plus grande probabilité de victoire) des Noirs pour une catégorie et un Game Type\")\n",
        "plt.xlabel(\"Opening\")\n",
        "plt.ylabel(\"Type de jeu et Catégorie ELO\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "868ZzXFWTPwS"
      },
      "source": [
        "Nous pouvons voir que les openings permettant le plus aux noirs de gagner sont différents de ceux permettant aux blancs de gagner. De plus, nous voyons également que l'opening permettant le plus de gagner est différent selon les configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGaqLjAteep-"
      },
      "outputs": [],
      "source": [
        "# TODO : iuci faut peut etre dire que opening c'est le coup fait par le blanc (à moins que ce soit plusieurs enchainement s?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oWkSNKhdc1S"
      },
      "outputs": [],
      "source": [
        "# TODO : ici on peut regarder si on retrouve les memes choses entre noir et blanc*\n",
        "# C'est différent lol #meilleurConclusionDeLannee\n",
        "\n",
        "# OK ducoup faut conclure que c'est différent (en meme temps je crois que opening c'est le premier coup de blanc... faut vérifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qig_CkT6Tmzk"
      },
      "outputs": [],
      "source": [
        "# TODO : Checker à quoi correspondent les openings permettant de gagner (agressif, ...)\n",
        "# et voir s'il y a un lien entre ces types d'openings et les types de parties"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib5E3BoQP47F"
      },
      "source": [
        "### Question 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPSc8pA7UM9X"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
        "from pyspark.sql.functions import when\n",
        "from pyspark.sql.functions import col, when\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, MinMaxScaler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH7Khn9AP6hA"
      },
      "source": [
        "*Q3: (difficult). Does a line of data in the file predict the outcome of the game (column Result), and with what\n",
        "probability? In other words, can any of the variables, such as the number of errors (mistakes, blunders, inacurracies,\n",
        "ts_blunders), the difference in ELO between the two players, etc., explain the outcome (win/loss)? You are free to\n",
        "define explain as you wish. It can be a correlation, linear or not, or any other relationship that allows this prediction.  \n",
        "Note that the ELO is itself computed from a probability (normal distribution) of victory depending on the difference\n",
        "in ELO of the two players. For instance, for a difference of 100 ELO points, the higher ranked player is expected to\n",
        "win with probability 0.64. For a 200 points difference, it is 0.76.  \n",
        "As we have more data than the ELO difference, your prediction should be more accurate than that.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOyyDpMDLUdf"
      },
      "source": [
        "TODO : Dire un résumé de ce qu'on fait dans cette partie"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour répondre à cette question, nous avons adopté une approche combinant des analyses exploratoires et des techniques de machine learning afin d'évaluer la capacité des variables à expliquer ou prédire le résultat du jeu (colonne *Result*). Cependant, la grande quantité de données disponibles a posé des défis significatifs, notamment en termes de temps d'entraînement pour certains modèles sophistiqués, comme les forêts aléatoires (*Random Forests*) ou les arbres boostés (*Gradient Boosted Trees*), même en réduisant l'échantillon à un pourcentage aléatoire des données.\n",
        "\n",
        "Face à ces contraintes, nous avons opté pour un modèle de régression multinomiale, qui s'est avéré bien plus rapide à entraîner tout en offrant des performances acceptables sur un sous-échantillon de 1 % des données. Cela a toutefois nécessité une adaptation spécifique de la préparation des données. En parallèle, pour mieux comprendre les relations entre les variables et le résultat, nous avons complété l'analyse par des mesures de corrélation, de covariance et des tableaux de contingence, afin de capturer des liens potentiellement explicatifs ou prédictifs entre les caractéristiques comme les erreurs (*mistakes*, *blunders*, etc.), la différence d'ELO entre les joueurs, et d'autres variables pertinentes."
      ],
      "metadata": {
        "id": "p0RMUIoqopII"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1yxXrgMI2mb"
      },
      "source": [
        "#### Préparation des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJgruJiL1X57"
      },
      "outputs": [],
      "source": [
        "df_spark_plus.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjmXfpJhJ9fj"
      },
      "source": [
        "##### **Suppression des colonnes non nécessaires**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMg-uyytJSVn"
      },
      "source": [
        "Nous allons supprimer certaines colonnes du jeu de données qui ne sont pas pertinentes pour la prédiction de la colonne `Result` et/ou qui pourrait introduire un biais.\n",
        "\n",
        "<ins>Suppression des colonnes étant des conséquences du résultat:</ins>\n",
        "* `BlackRatingDiff` :  Variation du classement ELO du joueur noir après la partie\n",
        "* `WhiteRatingDiff` : Variation du classement ELO du joueur blanc après la partie\n",
        "\n",
        "Ces colonnes reflètent directement l'issue de la partie et ne peuvent donc pas être utilisées comme des variables explicatives pour prédire le résultat.\n",
        "\n",
        "TODO : de plus -> gestion de null à pas faire\n",
        "\n",
        "<ins>Suppression des colonnes n'apportant pas d'informations pertinentes :</ins>\n",
        "* `GAME` : Identifiant unique de la partie\n",
        "* `Date`: Date à laquelle la partie a été jouée\n",
        "* `Site`: URL de la partie  \n",
        "* `TimeControl` : Temps de jeu en secondes (temps initial + incrément)\n",
        "* `UTCTime` : Heure à laquelle la partie a été jouée\n",
        "* `Event` : Evenement où la partie a été jouée\n",
        "\n",
        "TODO : ici dire que ccertaines de ces infos ne sont pas standardisées c'est pour ça qu'on ls garde pas\n",
        "\n",
        "\n",
        "Supprimer les colonnes que nous avons calculées (informations redondantes) :\n",
        "- `Black_ELO_categor`\n",
        "- `White_ELO_category`\n",
        "- `Avg_ELO_category`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combien d'instances pour Game_type\n",
        "df_spark_plus.groupBy(\"Game_type\").count().show()"
      ],
      "metadata": {
        "id": "EpdCcfsEVyqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supprimer Game_type = Correspondance pour pouvoir garder starting_time et increment\n",
        "# (où les données peuvent être manquantes)\n",
        "df_spark_plus = df_spark_plus.filter(col(\"Game_type\") != \"Correspondence\")"
      ],
      "metadata": {
        "id": "oDrAkYosYUhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVr43dK_KGwh"
      },
      "outputs": [],
      "source": [
        "# Suppression des colonnes\n",
        "df_preparation = df_spark_plus.drop(\"BlackRatingDiff\", \"WhiteRatingDiff\", \"GAME\", \"Date\", \"Site\", \"TimeControl\", \"UTCTime\", \"Event\",  \"Black_ELO_category\", \"White_ELO_category\", \"Avg_ELO_category\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHKKApAuOq-4"
      },
      "outputs": [],
      "source": [
        "df_preparation.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combien de valeurs nulles par colonne ?\n",
        "df_preparation.select([count(when(col(c).isNull(), c)).alias(c) for c in df_preparation.columns]).show()\n"
      ],
      "metadata": {
        "id": "2RKgwWmqYiNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plus aucune valeur nulle -> ok"
      ],
      "metadata": {
        "id": "3pYxSOh7YxTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Corrélation\n",
        "\n",
        "La corrélation mesure la force et la direction de la relation linéaire entre deux variables.\n",
        "\n",
        "- Une corrélation proche de +1 ou -1 indique une forte relation linéaire.\n",
        "- Une corrélation proche de 0 indique peu ou pas de relation linéaire.\n"
      ],
      "metadata": {
        "id": "0h9972uvttNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quelles sont les colonnes numériques ?\n",
        "numeric_cols = [col[0] for col in df_preparation.dtypes if col[1] in [\"int\", \"double\"]]\n",
        "print(f'Les colonnes numériques sont : {numeric_cols}')"
      ],
      "metadata": {
        "id": "ph3VyrclulJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.stat import Correlation\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Assembler les colonnes numériques en un seul vecteur\n",
        "assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"numeric_features\")\n",
        "data = assembler.transform(data)\n",
        "\n",
        "# Calculer la matrice de corrélation\n",
        "correlation_matrix = Correlation.corr(data, \"numeric_features\").head()[0]\n",
        "\n",
        "# Convertir en DataFrame pour un affichage clair\n",
        "correlation_array = np.array(correlation_matrix.toArray())\n",
        "correlation_df = pd.DataFrame(correlation_array, columns=numeric_cols, index=numeric_cols)\n",
        "print(correlation_df)"
      ],
      "metadata": {
        "id": "28WXBOfVuuSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : analyse"
      ],
      "metadata": {
        "id": "KwYc_YGHu5YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for col1 in numeric_columns:\n",
        "#     for col2 in numeric_columns:\n",
        "#         if col1 != col2:\n",
        "#             corr_value = data.stat.corr(col1, col2)\n",
        "#             print(f\"Corrélation entre {col1} et {col2}: {corr_value}\")\n"
      ],
      "metadata": {
        "id": "06N_WR3utmYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Covariance\n",
        "\n",
        "- Une covariance positive indique que les deux variables augmentent ensemble.\n",
        "- Une covariance négative indique qu'une variable augmente tandis que l'autre diminue."
      ],
      "metadata": {
        "id": "DL4um5BBuRZp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3eUNo5J4tmUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jMadPsZ5tmSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y1cWl7IitmP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d17zv1hLtl6k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CtYRrnxPF6S"
      },
      "source": [
        "##### **Encodage des colonnes non numériques**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un véritable défi dans la préparation des données a été l'encodage des colonnes catégorielles, notamment celles avec un très grand nombre de catégories distinctes. Dans de tels cas, utiliser un encodage classique comme le one-hot encoding aurait été impraticable. Cela aurait non seulement multiplié la taille des données de manière exponentielle, mais également introduit des matrices très clairsemées et difficiles à exploiter efficacement dans les modèles.\n",
        "\n",
        "Pour surmonter cette limitation, nous avons opté pour le target encoding, une approche plus adaptée. Cette méthode consiste à remplacer chaque catégorie par une valeur numérique calculée en fonction de la cible (par exemple, le taux moyen de victoire pour chaque catégorie). Cela nous a permis de conserver l'information tout en réduisant significativement la complexité des données et en améliorant leur utilisabilité dans les modèles d’apprentissage."
      ],
      "metadata": {
        "id": "Jtq3u-CKp_Ru"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJPgCitQRLhb"
      },
      "outputs": [],
      "source": [
        "# Observation des types des colonnes pour savoir comment les traiter\n",
        "schema = df_preparation.schema\n",
        "columns_by_type = defaultdict(list)\n",
        "\n",
        "for field in schema:\n",
        "    columns_by_type[str(field.dataType)].append(field.name)\n",
        "\n",
        "for data_type, columns in columns_by_type.items():\n",
        "    print(f\"Type: {data_type}\")\n",
        "    print(f\"Columns: {columns}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESfrjMwKR-kn"
      },
      "source": [
        "Il y a 5 colonnes de type chaine de caractères, nous allons les encoder afin de pouvoir les utiliser dans nos prédictions."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combien de données différentes contiennent chacune de ces colonnes ?\n",
        "\n",
        "for column in columns_by_type[\"StringType()\"]:\n",
        "  distinct_count = df_preparation.select(column).distinct().count()\n",
        "  print(f\"Nombre de valeurs distinctes pour la colonne '{column}': {distinct_count}\")"
      ],
      "metadata": {
        "id": "UD3k7_c1L-Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6usk1trUQq7y"
      },
      "source": [
        "Nous allons gérer ces colonnes de façons différentes, en fonction de leur nombre de valeurs possibles et de leur type.\n",
        "\n",
        "* `Result` : Colonne à prédire\n",
        "* `ECO`, `Opening` : Beaucoup de valeurs possibles\n",
        "* `Termination`, `Game_type` : Peu de valeurs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSxnOyv7XCbB"
      },
      "outputs": [],
      "source": [
        "# Nombre de valeurs par Result\n",
        "df_preparation.groupBy(\"Result\").count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id8MPwh8XLjk"
      },
      "source": [
        "Il y a seulement 72 valeurs indéfini dans la colonnes Result, nous allons supprimer ces parties (ces lignes), car elles n'ont pas d'intérêts et sont en trop faible nombre pour apporter un réel résultat à notre analyse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MseqjgYC0asN"
      },
      "outputs": [],
      "source": [
        "df_preparation = df_preparation.filter(col(\"Result\") != \"*\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quels sont les game type ?\n",
        "df_preparation.select(\"Game_type\").distinct().show()"
      ],
      "metadata": {
        "id": "HJZmL3a0eAy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Result : colonne cible, 3 valeurs possibles\n",
        "\n",
        "df_preparation = df_preparation.withColumn(\n",
        "    \"Result_index\",\n",
        "    when(col(\"Result\") == \"1-0\", 0)\n",
        "    .when(col(\"Result\") == \"0-1\", 2)\n",
        "    .when(col(\"Result\") == \"1/2-1/2\", 1) # nul \"moyenne\" des deux autres scénarios\n",
        ")\n",
        "\n",
        "# Comment connaitre à quoi correspond chaque index ?\n",
        "df_preparation.select(\"Result\", \"Result_index\").distinct().show()"
      ],
      "metadata": {
        "id": "vC1c-L9Se00T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supprimer alors Result\n",
        "df_preparation = df_preparation.drop(\"Result\")"
      ],
      "metadata": {
        "id": "erm3J1pAszs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Game_type : 4 valeurs, pseudo relation d'ordre\n",
        "df_preparation = df_preparation.withColumn(\n",
        "    \"Game_type_encoded\",\n",
        "    when(col(\"Game_type\") == \"Bullet\", 1)\n",
        "    .when(col(\"Game_type\") == \"Blitz\", 2)\n",
        "    .when(col(\"Game_type\") == \"Rapid\", 3)\n",
        "    .when(col(\"Game_type\") == \"Classical\", 4)\n",
        ")\n",
        "\n",
        "# vérifier\n",
        "df_preparation.select(\"Game_type\", \"Game_type_encoded\").distinct().show()"
      ],
      "metadata": {
        "id": "qADtdg8ailGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supprimer Game_type\n",
        "df_preparation = df_preparation.drop(\"Game_type\")"
      ],
      "metadata": {
        "id": "3_SBF0d1s5l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy du df pour pas tout perdre\n",
        "data = df_preparation"
      ],
      "metadata": {
        "id": "s0gOwpOFtsNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eco et Opening : beaucoup de valeurs possibles\n",
        "# On ne peut pas faire un One-Hot encoding -> cela créerait trop de colonnes\n",
        "# Label encoding pourrait introduire un biais implicite d'ordre (en fonction du modèle choisi)\n",
        "# On va donc utiliser un Target encoding\n",
        "\n",
        "# TODO : blabla explicatif\n",
        "# Le target encoding (encodage cible) est une méthode d'encodage\n",
        "# utilisée principalement pour les colonnes catégoriques avec de\n",
        "# nombreuses valeurs uniques. Au lieu de transformer chaque catégorie\n",
        "# en une variable distincte (comme avec le one-hot encoding),\n",
        "# on associe chaque catégorie à une statistique calculée à partir\n",
        "# de la cible (par exemple, la moyenne de la variable cible pour\n",
        "# cette catégorie).\n",
        "# Target encoding résume l'information de nombreuses catégories dans une seule colonne, ce qui réduit la mémoire nécessaire pour stocker et traiter les données.\n",
        "# Target encoding transforme les colonnes catégoriques en valeurs numériques basées sur la cible, ce qui est mieux adapté aux modèles qui fonctionnent mal avec des données catégoriques brutes (comme les modèles linéaires ou les arbres de décision).\n",
        "\n",
        "from pyspark.sql.functions import col, mean\n",
        "\n",
        "# Target encoding pour \"Opening\"\n",
        "avg_opening_result = data.groupBy(\"Opening\").agg(mean(\"Result_index\").alias(\"opening_score\"))\n",
        "data = data.join(avg_opening_result, on=\"Opening\", how=\"left\")\n",
        "\n",
        "# Target encoding pour \"Eco\"\n",
        "avg_eco_result = data.groupBy(\"Eco\").agg(mean(\"Result_index\").alias(\"eco_score\"))\n",
        "data = data.join(avg_eco_result, on=\"Eco\", how=\"left\")\n",
        "\n",
        "# Vérification des colonnes ajoutées\n",
        "data.select(\"Opening\", \"opening_score\", \"Eco\", \"eco_score\").show(10)"
      ],
      "metadata": {
        "id": "U_1vgQP5f5AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supprimer Opening et Eco\n",
        "data = data.drop(\"Opening\", \"Eco\")"
      ],
      "metadata": {
        "id": "F3Q8k_YwvNxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quelles sont les valeurs de Termination ?\n",
        "data.select(\"Termination\").distinct().show()"
      ],
      "metadata": {
        "id": "-Mecma3Kw0Dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Termination : 4 valeurs possibles\n",
        "# One hot encoding pour éviter relations d'ordre implicite\n",
        "\n",
        "# créer Termination_Abandoned, Termination_Rules_infraction,\n",
        "# Termination_Time_forfeit\n",
        "# Termination_Normal\n",
        "\n",
        "data = data.withColumn(\n",
        "    \"Termination_Abandoned\",\n",
        "    when(col(\"Termination\") == \"Abandoned\", 1)\n",
        "    .otherwise(0)\n",
        ")\n",
        "\n",
        "data = data.withColumn(\n",
        "    \"Termination_Rules_infraction\",\n",
        "    when(col(\"Termination\") == \"Rules infraction\", 1)\n",
        "    .otherwise(0)\n",
        ")\n",
        "\n",
        "data = data.withColumn(\n",
        "    \"Termination_Time_forfeit\",\n",
        "    when(col(\"Termination\") == \"Time forfeit\", 1)\n",
        "    .otherwise(0)\n",
        ")\n",
        "\n",
        "data = data.withColumn(\n",
        "    \"Termination_Normal\",\n",
        "    when(col(\"Termination\") == \"Normal\", 1)\n",
        "    .otherwise(0)\n",
        ")\n",
        "\n",
        "# Afficher Termination et les 4 colonnes créées\n",
        "data.select(\"Termination\", \"Termination_Abandoned\", \"Termination_Rules_infraction\", \"Termination_Time_forfeit\", \"Termination_Normal\").show(10)"
      ],
      "metadata": {
        "id": "3N82r5mIg6w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supprimer Termination\n",
        "data = data.drop(\"Termination\")"
      ],
      "metadata": {
        "id": "iCrg4GRGvMG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérifier les colonnes\n",
        "data.printSchema()"
      ],
      "metadata": {
        "id": "ralck60ytWqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv8ZjhTFqi8b"
      },
      "source": [
        "##### **Normalisation des données**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quelles sont les colonnes numériques ? (normalement toutes)\n",
        "numeric_cols = [col[0] for col in data.dtypes if col[1] in [\"int\", \"double\"]]\n",
        "print(f'Les colonnes numériques sont : {numeric_cols}')\n",
        "\n",
        "# Quelles sont les colonnes non numériques ?\n",
        "non_numeric_cols = [col[0] for col in data.dtypes if col[1] not in [\"int\", \"double\"]]\n",
        "print(f'Les colonnes non numériques sont : {non_numeric_cols}')"
      ],
      "metadata": {
        "id": "UkJTPBtzqJOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
        "# from pyspark.sql.functions import col\n",
        "\n",
        "# # Étape 1 : Sélectionner les colonnes numériques à standardiser\n",
        "# numeric_cols = [\"Black_ELO\", \"White_ELO\", \"Avg_ELO\", \"mistakes\", \"blunders\", \"inaccuracies\", \"ts_blunders\"]\n",
        "\n",
        "# # Étape 2 : Combiner les colonnes numériques dans un seul vecteur pour la standardisation\n",
        "# assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"numeric_features\")\n",
        "# data = assembler.transform(data)\n",
        "\n",
        "# # Étape 3 : Standardiser les données\n",
        "# scaler = StandardScaler(inputCol=\"numeric_features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
        "# scaler_model = scaler.fit(data)\n",
        "# data = scaler_model.transform(data)\n",
        "\n",
        "# # Étape 4 : (Optionnel) Convertir les données standardisées en colonnes séparées\n",
        "# from pyspark.ml.functions import vector_to_array\n",
        "\n",
        "# # Transformer le vecteur en colonnes séparées\n",
        "# data = data.withColumn(\"scaled_features_array\", vector_to_array(col(\"scaled_features\")))\n",
        "\n",
        "# # Réattribuer chaque colonne standardisée à son nom d'origine\n",
        "# for i, col_name in enumerate(numeric_cols):\n",
        "#     data = data.withColumn(f\"{col_name}_scaled\", col(\"scaled_features_array\")[i])\n",
        "\n",
        "# # Étape 5 : Supprimer les colonnes intermédiaires si nécessaire\n",
        "# data = data.drop(\"numeric_features\", \"scaled_features\", \"scaled_features_array\")\n",
        "\n",
        "# # Afficher un aperçu des données\n",
        "# data.select(*[f\"{col}_scaled\" for col in numeric_cols]).show(5)\n"
      ],
      "metadata": {
        "id": "PFcGwlQ9qNHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKsSpWhpp__0"
      },
      "outputs": [],
      "source": [
        "# # Normalisation des colonnes numériques\n",
        "# numeric_cols = [\n",
        "#     'Total_moves', 'Black_blunders', 'White_blunders', 'Black_mistakes', 'White_mistakes',\n",
        "#     'Black_inaccuracies', 'White_inaccuracies', 'Black_inferior_moves', 'White_inferior_moves',\n",
        "#     'Black_ts_moves', 'White_ts_moves', 'Black_ts_blunders', 'White_ts_blunders',\n",
        "#     'Black_ts_mistakes', 'White_ts_mistake', 'Black_long_moves', 'White_long_moves',\n",
        "#     'Black_bad_long_moves', 'White_bad_long_moves', 'Game_flips', 'Game_flips_ts',\n",
        "#     'white_moves', 'black_moves'\n",
        "# ]\n",
        "\n",
        "# assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"features_raw\")\n",
        "# df_prepared = assembler.transform(df_preparation)\n",
        "\n",
        "# scaler = MinMaxScaler(inputCol=\"features_raw\", outputCol=\"scaled_features\")\n",
        "# scaler_model = scaler.fit(df_prepared)\n",
        "# df_prepared = scaler_model.transform(df_prepared)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# toutes les colonnes sauf \"Result_index\"\n",
        "feature_columns = data.columns\n",
        "feature_columns.remove(\"Result_index\")"
      ],
      "metadata": {
        "id": "wGPwMT03zkuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zCZFAy8qnZU"
      },
      "outputs": [],
      "source": [
        "# Combinaison des colonnes finales\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "df_final = assembler.transform(data)\n",
        "\n",
        "# ARCHIVE :\n",
        "# feature_cols = ['scaled_features', 'ECO_index', 'Opening_index'] + [f\"{col}_ohe\" for col in columns_to_encode]\n",
        "# final_assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"final_features\")\n",
        "# df_prepared = final_assembler.transform(df_prepared)\n",
        "\n",
        "# # Suppression des colonnes inutiles\n",
        "# cols_to_drop = ['ECO', 'Opening', 'Result', 'Termination', 'Black_ELO_category', 'White_ELO_category', 'Game_type',\n",
        "#                 'features_raw', 'scaled_features'] + numeric_cols\n",
        "# df_prepared = df_prepared.drop(*cols_to_drop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxIagKMupKsY"
      },
      "outputs": [],
      "source": [
        "df_final.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_features = df_final.select(\"features\", \"Result_index\")"
      ],
      "metadata": {
        "id": "t2Mgiocv07kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YsPDldrMrxB1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zx8zeckOryYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x1qVwwjPr2KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4t_mJw2or2H-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dB-BC1htr2Ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train test"
      ],
      "metadata": {
        "id": "XpfBp44y0BtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diviser les données en 80% pour l'entrainement et 20% pour le test\n",
        "train_data, test_data = df_features.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "0hKL2ThT0BcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SI c'est vraiment trop chiant à réduire -> CORRÉLATION et hop tant pis"
      ],
      "metadata": {
        "id": "mS3N6v8j32H0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utiliser un sous-ensemble des données (par exemple, 10% des données d'entraînement)\n",
        "small_train_data = train_data.sample(withReplacement=False, fraction=0.01, seed=1234)\n"
      ],
      "metadata": {
        "id": "9QcSQrnj3WdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ARCHIVE\n",
        "#  from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "# # Entraînement du modèle\n",
        "# rf = RandomForestClassifier(\n",
        "#     featuresCol=\"features\",\n",
        "#     labelCol='Result_index',\n",
        "#     numTrees=10,\n",
        "#     maxDepth=5,\n",
        "#     maxBins=32,\n",
        "#     seed=42\n",
        "#     )\n",
        "# model = rf.fit(small_train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "74mQvBbS0N9V",
        "outputId": "66ffcc7d-aabb-4644-a181-b93eb64d071d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:KeyboardInterrupt while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-153-853e22d20b27>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     )  \n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mJM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Prédictions sur l'ensemble de test\n",
        "# predictions = model.transform(test_data)\n",
        "\n",
        "# # Évaluer la performance du modèle (par exemple, avec la précision, F1-score, etc.)\n",
        "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# evaluator = MulticlassClassificationEvaluator(labelCol='Result_index', predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "# accuracy = evaluator.evaluate(predictions)\n",
        "# print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "nJuO6CqR0gE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Extraire l'importance des features\n",
        "# rf_model = model.stages[1]  # Le modèle est dans la deuxième étape du pipeline\n",
        "# print(\"Feature Importances: \", rf_model.featureImportances)\n"
      ],
      "metadata": {
        "id": "ueJT0pRx0pLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Gradient Boosted Trees aussi\n",
        "# model.featureImportances\n",
        "\n",
        "# # Importance des features\n",
        "# feature_importance = model.featureImportances\n",
        "# print(\"Feature Importances:\", feature_importance)\n",
        "\n",
        "# MulticlassClassificationEvaluator"
      ],
      "metadata": {
        "id": "Z4rXQOHueRen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GBTClassifier"
      ],
      "metadata": {
        "id": "6t6G4jyt4ZVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyspark.ml.classification import GBTClassifier\n",
        "# from pyspark.ml.feature import VectorAssembler\n",
        "# from pyspark.ml import Pipeline\n",
        "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# gbt = GBTClassifier(labelCol=\"Result_index\", featuresCol=\"features\", maxIter=100, maxDepth=10)\n",
        "\n",
        "# model = gbt.fit(small_train_data)\n"
      ],
      "metadata": {
        "id": "U6oIR78N4XX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Prédictions sur l'ensemble de test\n",
        "# predictions = model.transform(test_data)\n",
        "\n",
        "# # Évaluation du modèle (multiclasse)\n",
        "# evaluator = MulticlassClassificationEvaluator(labelCol=\"Result\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "# # Calculer l'accuracy\n",
        "# accuracy = evaluator.evaluate(predictions)\n",
        "# print(f\"Test Accuracy = {accuracy}\")\n"
      ],
      "metadata": {
        "id": "E_JMKknC4p0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST regression multinomiale\n"
      ],
      "metadata": {
        "id": "RS8VcQvf_FrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO ; normaliser (pcq ducoup je pensais pas avoir besoin de le faire avec les autres modèles...)"
      ],
      "metadata": {
        "id": "sSb_RRzrBo9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"Result_index\", family=\"multinomial\")\n",
        "\n",
        "model = lr.fit(small_train_data)"
      ],
      "metadata": {
        "id": "ZjZCRWtv_J16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 minutes quand je sous sample à 1%"
      ],
      "metadata": {
        "id": "7V2yXdhqAjfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(test_data)\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Result_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VALpM1HY_bnq",
        "outputId": "261f4385-99ee-42c2-dd41-cf17528de17a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy 0.9212"
      ],
      "metadata": {
        "id": "338OVPHXBBaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Récupérer les noms des caractéristiques utilisées dans le modèle\n",
        "feature_names = assembler.getInputCols()\n"
      ],
      "metadata": {
        "id": "35w2HdJtBjm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intercept pour chaque classe\n",
        "intercepts = model.interceptVector\n",
        "print(\"Intercepts pour chaque classe :\")\n",
        "for i, intercept in enumerate(intercepts):\n",
        "    print(f\"Classe {i}: {intercept}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krupteQpBcEs",
        "outputId": "3d9048c6-d1c8-4cb3-974c-a4fb3474d142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intercepts pour chaque classe :\n",
            "Classe 0: 1.1398609749416944\n",
            "Classe 1: -4.157891449476688\n",
            "Classe 2: 3.0180304745349935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Coefficient matrix : chaque ligne représente les coefficients pour une classe\n",
        "coeff_matrix = model.coefficientMatrix\n",
        "coeff_matrix\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_9PW1jH_bez",
        "outputId": "51620c61-38ce-41c2-93f5-2ed2201764cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseMatrix(3, 34, [-0.0009, 0.0006, -0.0, -0.0078, -0.0048, 0.5875, -0.586, 0.1092, ..., 3.0389, -0.032, -0.0434, 0.5532, 0.0, 14.7637, 0.3378, -0.3487], 1)"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher les coefficients pour chaque classe\n",
        "for i in range(coeff_matrix.numRows):\n",
        "    print(f\"Classe {i}:\")\n",
        "    for j in range(coeff_matrix.numCols):\n",
        "        print(f\"  {feature_names[j]}: {coeff_matrix[i, j]}\")\n",
        "    print(f\"Intercept: {intercepts[i]}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYiTGHUIB7It",
        "outputId": "5fc3898f-390e-4176-d191-f1bd4f7dec49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classe 0:\n",
            "  BlackElo: -0.0008627894265885027\n",
            "  WhiteElo: 0.0006435208705830123\n",
            "  starting_time: -1.2604804978628722e-05\n",
            "  increment: -0.007765580723689031\n",
            "  Total_moves: -0.004762512873655772\n",
            "  Black_blunders: 0.587524784500537\n",
            "  White_blunders: -0.5860058305651812\n",
            "  Black_mistakes: 0.10921304924053668\n",
            "  White_mistakes: -0.10127464010489716\n",
            "  Black_inaccuracies: 0.0017889578703905074\n",
            "  White_inaccuracies: 0.018476742763017303\n",
            "  Black_inferior_moves: 0.15236576954628575\n",
            "  White_inferior_moves: -0.14341690483634156\n",
            "  Black_ts_moves: 0.026714173656729567\n",
            "  White_ts_moves: -0.018849833615327674\n",
            "  Black_ts_blunders: 0.14196772293367765\n",
            "  White_ts_blunders: -0.05798953861367102\n",
            "  Black_ts_mistakes: 0.05933747402765618\n",
            "  White_ts_mistake: -0.023267330361138646\n",
            "  Black_long_moves: 0.11589606688560793\n",
            "  White_long_moves: -0.15523469201900184\n",
            "  Black_bad_long_moves: -0.041547128904023664\n",
            "  White_bad_long_moves: 0.10113506236862892\n",
            "  Game_flips: -0.024288216479384173\n",
            "  Game_flips_ts: -0.053764136547848417\n",
            "  white_moves: 3.017406474426136\n",
            "  black_moves: -3.0344512286594156\n",
            "  Game_type_encoded: 0.019788785269627057\n",
            "  opening_score: -0.1395653865708146\n",
            "  eco_score: -0.44550704174880235\n",
            "  Termination_Abandoned: 0.0\n",
            "  Termination_Rules_infraction: 18.118918556196963\n",
            "  Termination_Time_forfeit: 0.3337135819391179\n",
            "  Termination_Normal: -0.3470624887985211\n",
            "Intercept: 1.1398609749416944\n",
            "\n",
            "\n",
            "Classe 1:\n",
            "  BlackElo: -6.870695345812443e-05\n",
            "  WhiteElo: 0.000549945776798982\n",
            "  starting_time: -6.085487643612567e-06\n",
            "  increment: 0.008858994917123362\n",
            "  Total_moves: 0.008554527436384312\n",
            "  Black_blunders: -0.02275576821856116\n",
            "  White_blunders: -0.026417380755590737\n",
            "  Black_mistakes: -0.011012414043781291\n",
            "  White_mistakes: -0.023722384954734558\n",
            "  Black_inaccuracies: -0.028556113912737727\n",
            "  White_inaccuracies: -0.014433976962782107\n",
            "  Black_inferior_moves: -0.014017294646560917\n",
            "  White_inferior_moves: -0.015095153123243488\n",
            "  Black_ts_moves: 0.0003078097435225889\n",
            "  White_ts_moves: -0.009391297580042294\n",
            "  Black_ts_blunders: -0.11801912198165573\n",
            "  White_ts_blunders: -0.001151950605139276\n",
            "  Black_ts_mistakes: -0.02859826804985944\n",
            "  White_ts_mistake: -0.03623421463350521\n",
            "  Black_long_moves: 0.014117010017814473\n",
            "  White_long_moves: 0.015291580791358962\n",
            "  Black_bad_long_moves: 0.03846197907338836\n",
            "  White_bad_long_moves: -0.08037152578123073\n",
            "  Game_flips: 0.05594067200393847\n",
            "  Game_flips_ts: 0.13683482591558627\n",
            "  white_moves: 0.03864054924401275\n",
            "  black_moves: -0.004420136600948694\n",
            "  Game_type_encoded: 0.012186567722264608\n",
            "  opening_score: 0.18297670155743082\n",
            "  eco_score: -0.10771136750528858\n",
            "  Termination_Abandoned: 0.0\n",
            "  Termination_Rules_infraction: -32.88262245597797\n",
            "  Termination_Time_forfeit: -0.6715354448682225\n",
            "  Termination_Normal: 0.6957354084296469\n",
            "Intercept: -4.157891449476688\n",
            "\n",
            "\n",
            "Classe 2:\n",
            "  BlackElo: 0.0009314963800466271\n",
            "  WhiteElo: -0.0011934666473819944\n",
            "  starting_time: 1.869029262224129e-05\n",
            "  increment: -0.0010934141934343313\n",
            "  Total_moves: -0.0037920145627285393\n",
            "  Black_blunders: -0.5647690162819757\n",
            "  White_blunders: 0.6124232113207718\n",
            "  Black_mistakes: -0.0982006351967554\n",
            "  White_mistakes: 0.12499702505963171\n",
            "  Black_inaccuracies: 0.026767156042347223\n",
            "  White_inaccuracies: -0.004042765800235197\n",
            "  Black_inferior_moves: -0.13834847489972482\n",
            "  White_inferior_moves: 0.15851205795958506\n",
            "  Black_ts_moves: -0.027021983400252157\n",
            "  White_ts_moves: 0.02824113119536997\n",
            "  Black_ts_blunders: -0.023948600952021913\n",
            "  White_ts_blunders: 0.059141489218810295\n",
            "  Black_ts_mistakes: -0.030739205977796738\n",
            "  White_ts_mistake: 0.05950154499464386\n",
            "  Black_long_moves: -0.1300130769034224\n",
            "  White_long_moves: 0.13994311122764289\n",
            "  Black_bad_long_moves: 0.003085149830635307\n",
            "  White_bad_long_moves: -0.020763536587398188\n",
            "  Game_flips: -0.0316524555245543\n",
            "  Game_flips_ts: -0.08307068936773784\n",
            "  white_moves: -3.056047023670149\n",
            "  black_moves: 3.0388713652603645\n",
            "  Game_type_encoded: -0.031975352991891665\n",
            "  opening_score: -0.04341131498661623\n",
            "  eco_score: 0.5532184092540909\n",
            "  Termination_Abandoned: 0.0\n",
            "  Termination_Rules_infraction: 14.763703899781012\n",
            "  Termination_Time_forfeit: 0.3378218629291046\n",
            "  Termination_Normal: -0.3486729196311258\n",
            "Intercept: 3.0180304745349935\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-VoUgv2CB9Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9WxPJedQBQc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eAHUCjrKBQX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8VyAsslqtT0"
      },
      "source": [
        "## TODO EN DESSOUS ICI : ARCHIVE\n",
        "#### Regression logistique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8L6ZQP8w605"
      },
      "outputs": [],
      "source": [
        "# TODO : revoir Réduction dataset car modele trop long"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjbWT4TKq_UJ"
      },
      "outputs": [],
      "source": [
        "# Modèle\n",
        "lr = LogisticRegression(featuresCol=\"final_features\", labelCol=\"Result_encoded\", maxIter=100, regParam=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NneQ0eI5rCIg"
      },
      "outputs": [],
      "source": [
        "# Entrainement\n",
        "lr_model = lr.fit(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KLd46YtLrGnq"
      },
      "outputs": [],
      "source": [
        "# TODO : Pas fais en dessous, le modele met trop de temps à s'entrainer\n",
        "\n",
        "# Prédictions sur données test\n",
        "predictions = lr_model.transform(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oP8rjWfnrKvf",
        "outputId": "18db4c89-1b9a-444a-d359-e6c6f1186db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Précision du modèle : 0.92\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"Result_encoded\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"accuracy\"\n",
        ")\n",
        "\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Précision du modèle : {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uF4hJW9wrRkq",
        "outputId": "e25a82de-111b-4b88-b592-102f95df95d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+----------+---------------------------------------------------------------+\n",
            "|Result_encoded|prediction|probability                                                    |\n",
            "+--------------+----------+---------------------------------------------------------------+\n",
            "|0             |0.0       |[0.4852223483087187,0.3983852504454461,0.11639240124583522]    |\n",
            "|0             |2.0       |[0.03763188951043819,0.0350863758181692,0.9272817346713925]    |\n",
            "|0             |2.0       |[0.05410912227532556,0.0024939558790958863,0.9433969218455786] |\n",
            "|0             |2.0       |[0.15809157999837423,0.055600991284210755,0.786307428717415]   |\n",
            "|0             |2.0       |[0.05387077054362171,0.01772021348825698,0.9284090159681213]   |\n",
            "|0             |0.0       |[0.5332238586420255,0.3841649855695599,0.08261115578841464]    |\n",
            "|0             |1.0       |[0.03245277903401656,0.9289826945799053,0.03856452638607809]   |\n",
            "|0             |2.0       |[0.015059057817542274,4.5888203106949407E-4,0.9844820601513883]|\n",
            "|0             |1.0       |[0.010435996771061613,0.9041681710392918,0.08539583218964662]  |\n",
            "|0             |1.0       |[0.06102653868450788,0.9290704159285561,0.009903045386935995]  |\n",
            "+--------------+----------+---------------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Coefficients du modèle :\n"
          ]
        },
        {
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling o5764.coefficients.\n: org.apache.spark.SparkException: Multinomial models contain a matrix of coefficients, use coefficientMatrix instead.\n\tat org.apache.spark.ml.classification.LogisticRegressionModel.coefficients(LogisticRegression.scala:1085)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-246-24ccdf8574d4>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Analyse des coefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Coefficients du modèle :\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_prepared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{col_name}: {coef}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/classification.py\u001b[0m in \u001b[0;36mcoefficients\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0mAn\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthrown\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmultinomial\u001b[0m \u001b[0mlogistic\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \"\"\"\n\u001b[0;32m-> 1537\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"coefficients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_call_java\u001b[0;34m(self, name, *args)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o5764.coefficients.\n: org.apache.spark.SparkException: Multinomial models contain a matrix of coefficients, use coefficientMatrix instead.\n\tat org.apache.spark.ml.classification.LogisticRegressionModel.coefficients(LogisticRegression.scala:1085)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n"
          ]
        }
      ],
      "source": [
        "# Résultats de prédiction\n",
        "predictions.select(\"Result_encoded\", \"prediction\", \"probability\").show(10, truncate=False)\n",
        "\n",
        "# Analyse des coefficients\n",
        "print(\"Coefficients du modèle :\")\n",
        "for coef, col_name in zip(lr_model.coefficients.toArray(), df_prepared.columns[:-1]):\n",
        "    print(f\"{col_name}: {coef}\")\n",
        "\n",
        "print(f\"Intercept : {lr_model.intercept}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IMfuw3DmVpi"
      },
      "source": [
        "#### Brouillon Q3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9o1E_jtBrGx"
      },
      "outputs": [],
      "source": [
        "# Encodage des colonnes non-numériques\n",
        "\n",
        "# Beaucoup de valeurs : ECO et Opening\n",
        "# ==> StringIndexer\n",
        "indexer_eco = StringIndexer(inputCol=\"ECO\", outputCol=\"ECO_index\")\n",
        "indexer_opening = StringIndexer(inputCol=\"Opening\", outputCol=\"Opening_index\")\n",
        "\n",
        "df_preparation = indexer_eco.fit(df_preparation).transform(df_preparation)\n",
        "df_preparation = indexer_opening.fit(df_preparation).transform(df_preparation)\n",
        "\n",
        "# Peu de valeurs : Termination, Black_elo_category, White_elo_category, Game_type, Event_type\n",
        "# ==> StringIndexer et OneHotEncoder\n",
        "columns_to_encode = ['Termination', 'Black_ELO_category', 'White_ELO_category', 'Game_type']\n",
        "\n",
        "for column in columns_to_encode:\n",
        "    indexer = StringIndexer(inputCol=column, outputCol=f\"{column}_index\")\n",
        "    encoder = OneHotEncoder(inputCol=f\"{column}_index\", outputCol=f\"{column}_ohe\")\n",
        "\n",
        "    # Appliquer StringIndexer et OneHotEncoder\n",
        "    df_preparation = indexer.fit(df_preparation).transform(df_preparation)\n",
        "    df_preparation = encoder.fit(df_preparation).transform(df_preparation)\n",
        "\n",
        "# Colonne à prédire : Result\n",
        "# ==> Encodage numérique\n",
        "df_preparation = df_preparation.withColumn(\n",
        "    \"Result_encoded\",\n",
        "    when(col(\"Result\") == \"1-0\", 1)\n",
        "    .when(col(\"Result\") == \"0-1\", 0)\n",
        "    .when(col(\"Result\") == \"1/2-1/2\", -1)\n",
        "    .otherwise(None) # TODO le * on en fait quoi ?\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwccrLvOe0Eh"
      },
      "outputs": [],
      "source": [
        "# Supprimer colonnes string remplacées si dessus\n",
        "df_preparation = df_preparation.drop('ECO', 'Opening','Termination', 'Black_ELO_category', 'White_ELO_category', 'Game_type', 'Result')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xgdkWG06d214",
        "outputId": "e287e899-c30c-4817-db4e-ab54b9d6a264"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Total_moves: integer (nullable = true)\n",
            " |-- Black_blunders: integer (nullable = true)\n",
            " |-- White_blunders: integer (nullable = true)\n",
            " |-- Black_mistakes: integer (nullable = true)\n",
            " |-- White_mistakes: integer (nullable = true)\n",
            " |-- Black_inaccuracies: integer (nullable = true)\n",
            " |-- White_inaccuracies: integer (nullable = true)\n",
            " |-- Black_inferior_moves: integer (nullable = true)\n",
            " |-- White_inferior_moves: integer (nullable = true)\n",
            " |-- Black_ts_moves: integer (nullable = true)\n",
            " |-- White_ts_moves: integer (nullable = true)\n",
            " |-- Black_ts_blunders: integer (nullable = true)\n",
            " |-- White_ts_blunders: integer (nullable = true)\n",
            " |-- Black_ts_mistakes: integer (nullable = true)\n",
            " |-- White_ts_mistake: integer (nullable = true)\n",
            " |-- Black_long_moves: integer (nullable = true)\n",
            " |-- White_long_moves: integer (nullable = true)\n",
            " |-- Black_bad_long_moves: integer (nullable = true)\n",
            " |-- White_bad_long_moves: integer (nullable = true)\n",
            " |-- Game_flips: integer (nullable = true)\n",
            " |-- Game_flips_ts: integer (nullable = true)\n",
            " |-- white_moves: double (nullable = true)\n",
            " |-- black_moves: double (nullable = true)\n",
            " |-- ECO_index: double (nullable = false)\n",
            " |-- Opening_index: double (nullable = false)\n",
            " |-- Termination_index: double (nullable = false)\n",
            " |-- Termination_ohe: vector (nullable = true)\n",
            " |-- Black_ELO_category_index: double (nullable = false)\n",
            " |-- Black_ELO_category_ohe: vector (nullable = true)\n",
            " |-- White_ELO_category_index: double (nullable = false)\n",
            " |-- White_ELO_category_ohe: vector (nullable = true)\n",
            " |-- Game_type_index: double (nullable = false)\n",
            " |-- Game_type_ohe: vector (nullable = true)\n",
            " |-- Result_encoded: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_preparation.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ktvrdi5bX7Od",
        "outputId": "76dc1035-cf34-4022-ef71-f33baf9e9b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+--------------+--------------+--------------+--------------+------------------+------------------+--------------------+--------------------+--------------+--------------+-----------------+-----------------+-----------------+----------------+----------------+----------------+--------------------+--------------------+----------+-------------+-----------+-----------+---------+-------------+-----------------+---------------+------------------------+----------------------+------------------------+----------------------+---------------+-------------+--------------+\n",
            "|Total_moves|Black_blunders|White_blunders|Black_mistakes|White_mistakes|Black_inaccuracies|White_inaccuracies|Black_inferior_moves|White_inferior_moves|Black_ts_moves|White_ts_moves|Black_ts_blunders|White_ts_blunders|Black_ts_mistakes|White_ts_mistake|Black_long_moves|White_long_moves|Black_bad_long_moves|White_bad_long_moves|Game_flips|Game_flips_ts|white_moves|black_moves|ECO_index|Opening_index|Termination_index|Termination_ohe|Black_ELO_category_index|Black_ELO_category_ohe|White_ELO_category_index|White_ELO_category_ohe|Game_type_index|Game_type_ohe|Result_encoded|\n",
            "+-----------+--------------+--------------+--------------+--------------+------------------+------------------+--------------------+--------------------+--------------+--------------+-----------------+-----------------+-----------------+----------------+----------------+----------------+--------------------+--------------------+----------+-------------+-----------+-----------+---------+-------------+-----------------+---------------+------------------------+----------------------+------------------------+----------------------+---------------+-------------+--------------+\n",
            "|         66|             4|             2|             0|             3|                 3|                 1|                   7|                   6|             8|             8|                0|                0|                0|               0|               2|               1|                   1|                   1|         8|            0|       33.0|       33.0|     57.0|         60.0|              1.0|  (3,[1],[1.0])|                     3.0|         (6,[3],[1.0])|                     3.0|         (6,[3],[1.0])|            0.0|(4,[0],[1.0])|             0|\n",
            "|         64|             2|             1|             1|             1|                 7|                 5|                  10|                   7|             0|             0|                0|                0|                0|               0|               0|               1|                   0|                   0|         6|            0|       32.0|       32.0|     16.0|         80.0|              0.0|  (3,[0],[1.0])|                     0.0|         (6,[0],[1.0])|                     1.0|         (6,[1],[1.0])|            0.0|(4,[0],[1.0])|             0|\n",
            "|         70|             0|             1|             1|             2|                 8|                 8|                   9|                  11|             0|             2|                0|                0|                0|               0|               1|               1|                   1|                   0|         5|            0|       35.0|       35.0|      8.0|          1.0|              1.0|  (3,[1],[1.0])|                     2.0|         (6,[2],[1.0])|                     1.0|         (6,[1],[1.0])|            0.0|(4,[0],[1.0])|             0|\n",
            "|         86|             4|             2|             1|             5|                 3|                 4|                   8|                  11|            18|             0|                4|                0|                0|               0|               3|               1|                   1|                   0|         8|            1|       43.0|       43.0|     30.0|         88.0|              0.0|  (3,[0],[1.0])|                     0.0|         (6,[0],[1.0])|                     4.0|         (6,[4],[1.0])|            0.0|(4,[0],[1.0])|             0|\n",
            "|         71|             1|             0|             1|             1|                 6|                 2|                   8|                   3|             0|             0|                0|                0|                0|               0|               0|               0|                   0|                   0|         2|            0|       36.0|       35.0|     85.0|         79.0|              0.0|  (3,[0],[1.0])|                     0.0|         (6,[0],[1.0])|                     4.0|         (6,[4],[1.0])|            1.0|(4,[1],[1.0])|             1|\n",
            "+-----------+--------------+--------------+--------------+--------------+------------------+------------------+--------------------+--------------------+--------------+--------------+-----------------+-----------------+-----------------+----------------+----------------+----------------+--------------------+--------------------+----------+-------------+-----------+-----------+---------+-------------+-----------------+---------------+------------------------+----------------------+------------------------+----------------------+---------------+-------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_preparation.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9chbRKDHYDft"
      },
      "source": [
        "##### **Normalisation des données**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8N6GUwfYfE3"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler, MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZxNl_TJf0QK"
      },
      "outputs": [],
      "source": [
        "# TODO : Peut etre revoir je suis pas sure, faut normaliser en vecteurs en Spark lol (envie de crever)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlowJ7c_qhPt"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9XHsv3Qd6uK"
      },
      "outputs": [],
      "source": [
        "numeric_cols = [col_name for col_name, dtype in df_preparation.dtypes if dtype in ('int', 'double') and col_name != 'Result_encoded' and \"_index\" not in col_name]\n",
        "\n",
        "# Assemblage dans un vecteur des colonnes numériques\n",
        "assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"features\")\n",
        "df_with_features = assembler.transform(df_preparation)\n",
        "\n",
        "# Normalisation\n",
        "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
        "scaler_model = scaler.fit(df_with_features)\n",
        "df_normalized = scaler_model.transform(df_with_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q01UAR73fmjK",
        "outputId": "aea524ea-f370-44e2-9dd0-18129f4f0884"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|            features|     scaled_features|\n",
            "+--------------------+--------------------+\n",
            "|[66.0,4.0,2.0,0.0...|[0.18465909090909...|\n",
            "|(23,[0,1,2,3,4,5,...|(23,[0,1,2,3,4,5,...|\n",
            "|[70.0,0.0,1.0,1.0...|[0.19602272727272...|\n",
            "|[86.0,4.0,2.0,1.0...|[0.24147727272727...|\n",
            "|(23,[0,1,3,4,5,6,...|(23,[0,1,3,4,5,6,...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Vérification\n",
        "df_normalized.select(\"features\", \"scaled_features\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHzmqybyjuWV",
        "outputId": "ceb55372-c480-49cf-e0c7-50996a264a74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+--------------+--------------+--------------+--------------+------------------+------------------+--------------------+--------------------+--------------+--------------+-----------------+-----------------+-----------------+----------------+----------------+----------------+--------------------+--------------------+----------+-------------+-----------+-----------+---------+-------------+-----------------+---------------+------------------------+----------------------+------------------------+----------------------+---------------+-------------+--------------+--------------------+--------------------+--------------------+-------------------+---------------------+---------------------+---------------------+---------------------+-------------------------+-------------------------+---------------------------+---------------------------+---------------------+---------------------+------------------------+------------------------+------------------------+-----------------------+-----------------------+-----------------------+---------------------------+---------------------------+--------------------+--------------------+-------------------+-------------------+\n",
            "|Total_moves|Black_blunders|White_blunders|Black_mistakes|White_mistakes|Black_inaccuracies|White_inaccuracies|Black_inferior_moves|White_inferior_moves|Black_ts_moves|White_ts_moves|Black_ts_blunders|White_ts_blunders|Black_ts_mistakes|White_ts_mistake|Black_long_moves|White_long_moves|Black_bad_long_moves|White_bad_long_moves|Game_flips|Game_flips_ts|white_moves|black_moves|ECO_index|Opening_index|Termination_index|Termination_ohe|Black_ELO_category_index|Black_ELO_category_ohe|White_ELO_category_index|White_ELO_category_ohe|Game_type_index|Game_type_ohe|Result_encoded|            features|     scaled_features|        scaled_array| scaled_Total_moves|scaled_Black_blunders|scaled_White_blunders|scaled_Black_mistakes|scaled_White_mistakes|scaled_Black_inaccuracies|scaled_White_inaccuracies|scaled_Black_inferior_moves|scaled_White_inferior_moves|scaled_Black_ts_moves|scaled_White_ts_moves|scaled_Black_ts_blunders|scaled_White_ts_blunders|scaled_Black_ts_mistakes|scaled_White_ts_mistake|scaled_Black_long_moves|scaled_White_long_moves|scaled_Black_bad_long_moves|scaled_White_bad_long_moves|   scaled_Game_flips|scaled_Game_flips_ts| scaled_white_moves| scaled_black_moves|\n",
            "+-----------+--------------+--------------+--------------+--------------+------------------+------------------+--------------------+--------------------+--------------+--------------+-----------------+-----------------+-----------------+----------------+----------------+----------------+--------------------+--------------------+----------+-------------+-----------+-----------+---------+-------------+-----------------+---------------+------------------------+----------------------+------------------------+----------------------+---------------+-------------+--------------+--------------------+--------------------+--------------------+-------------------+---------------------+---------------------+---------------------+---------------------+-------------------------+-------------------------+---------------------------+---------------------------+---------------------+---------------------+------------------------+------------------------+------------------------+-----------------------+-----------------------+-----------------------+---------------------------+---------------------------+--------------------+--------------------+-------------------+-------------------+\n",
            "|         66|             4|             2|             0|             3|                 3|                 1|                   7|                   6|             8|             8|                0|                0|                0|               0|               2|               1|                   1|                   1|         8|            0|       33.0|       33.0|     57.0|         60.0|              1.0|  (3,[1],[1.0])|                     3.0|         (6,[3],[1.0])|                     3.0|         (6,[3],[1.0])|            0.0|(4,[0],[1.0])|             0|[66.0,4.0,2.0,0.0...|[0.18465909090909...|[0.18465909090909...| 0.1846590909090909|                0.125|  0.05555555555555555|                  0.0|  0.07692307692307693|      0.13043478260869565|     0.037037037037037035|        0.13725490196078433|         0.1111111111111111|  0.08163265306122448|  0.07692307692307693|                     0.0|                     0.0|                     0.0|                    0.0|    0.06060606060606061|    0.03225806451612903|        0.07142857142857142|        0.09090909090909091|  0.0963855421686747|                 0.0|0.18181818181818182|             0.1875|\n",
            "|         64|             2|             1|             1|             1|                 7|                 5|                  10|                   7|             0|             0|                0|                0|                0|               0|               0|               1|                   0|                   0|         6|            0|       32.0|       32.0|     16.0|         80.0|              0.0|  (3,[0],[1.0])|                     0.0|         (6,[0],[1.0])|                     1.0|         (6,[1],[1.0])|            0.0|(4,[0],[1.0])|             0|(23,[0,1,2,3,4,5,...|(23,[0,1,2,3,4,5,...|[0.17897727272727...|0.17897727272727273|               0.0625| 0.027777777777777776|  0.03571428571428571|  0.02564102564102564|      0.30434782608695654|      0.18518518518518517|        0.19607843137254902|        0.12962962962962962|                  0.0|                  0.0|                     0.0|                     0.0|                     0.0|                    0.0|                    0.0|    0.03225806451612903|                        0.0|                        0.0| 0.07228915662650603|                 0.0|0.17613636363636365|0.18181818181818182|\n",
            "|         70|             0|             1|             1|             2|                 8|                 8|                   9|                  11|             0|             2|                0|                0|                0|               0|               1|               1|                   1|                   0|         5|            0|       35.0|       35.0|      8.0|          1.0|              1.0|  (3,[1],[1.0])|                     2.0|         (6,[2],[1.0])|                     1.0|         (6,[1],[1.0])|            0.0|(4,[0],[1.0])|             0|[70.0,0.0,1.0,1.0...|[0.19602272727272...|[0.19602272727272...|0.19602272727272727|                  0.0| 0.027777777777777776|  0.03571428571428571|  0.05128205128205128|      0.34782608695652173|       0.2962962962962963|         0.1764705882352941|         0.2037037037037037|                  0.0| 0.019230769230769232|                     0.0|                     0.0|                     0.0|                    0.0|   0.030303030303030304|    0.03225806451612903|        0.07142857142857142|                        0.0|0.060240963855421686|                 0.0|0.19318181818181818|0.19886363636363638|\n",
            "|         86|             4|             2|             1|             5|                 3|                 4|                   8|                  11|            18|             0|                4|                0|                0|               0|               3|               1|                   1|                   0|         8|            1|       43.0|       43.0|     30.0|         88.0|              0.0|  (3,[0],[1.0])|                     0.0|         (6,[0],[1.0])|                     4.0|         (6,[4],[1.0])|            0.0|(4,[0],[1.0])|             0|[86.0,4.0,2.0,1.0...|[0.24147727272727...|[0.24147727272727...|0.24147727272727273|                0.125|  0.05555555555555555|  0.03571428571428571|   0.1282051282051282|      0.13043478260869565|      0.14814814814814814|         0.1568627450980392|         0.2037037037037037|  0.18367346938775508|                  0.0|                     0.2|                     0.0|                     0.0|                    0.0|    0.09090909090909091|    0.03225806451612903|        0.07142857142857142|                        0.0|  0.0963855421686747|0.022727272727272728|0.23863636363636365|0.24431818181818182|\n",
            "|         71|             1|             0|             1|             1|                 6|                 2|                   8|                   3|             0|             0|                0|                0|                0|               0|               0|               0|                   0|                   0|         2|            0|       36.0|       35.0|     85.0|         79.0|              0.0|  (3,[0],[1.0])|                     0.0|         (6,[0],[1.0])|                     4.0|         (6,[4],[1.0])|            1.0|(4,[1],[1.0])|             1|(23,[0,1,3,4,5,6,...|(23,[0,1,3,4,5,6,...|[0.19886363636363...|0.19886363636363638|              0.03125|                  0.0|  0.03571428571428571|  0.02564102564102564|       0.2608695652173913|      0.07407407407407407|         0.1568627450980392|        0.05555555555555555|                  0.0|                  0.0|                     0.0|                     0.0|                     0.0|                    0.0|                    0.0|                    0.0|                        0.0|                        0.0|0.024096385542168676|                 0.0|0.19886363636363638|0.19886363636363638|\n",
            "+-----------+--------------+--------------+--------------+--------------+------------------+------------------+--------------------+--------------------+--------------+--------------+-----------------+-----------------+-----------------+----------------+----------------+----------------+--------------------+--------------------+----------+-------------+-----------+-----------+---------+-------------+-----------------+---------------+------------------------+----------------------+------------------------+----------------------+---------------+-------------+--------------+--------------------+--------------------+--------------------+-------------------+---------------------+---------------------+---------------------+---------------------+-------------------------+-------------------------+---------------------------+---------------------------+---------------------+---------------------+------------------------+------------------------+------------------------+-----------------------+-----------------------+-----------------------+---------------------------+---------------------------+--------------------+--------------------+-------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.functions import vector_to_array\n",
        "\n",
        "# Convertir le vecteur \"scaled_features\" en colonnes individuelles\n",
        "df_final = df_normalized.withColumn(\"scaled_array\", vector_to_array(col(\"scaled_features\")))\n",
        "\n",
        "# Réattribuer les colonnes normalisées\n",
        "for i, column in enumerate(numeric_cols):\n",
        "    df_final = df_final.withColumn(f\"scaled_{column}\", col(\"scaled_array\")[i])\n",
        "\n",
        "# Afficher les données finalisées\n",
        "df_final.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKT8UK5TkEwX"
      },
      "outputs": [],
      "source": [
        "# drop numeric_cols\n",
        "df_final = df_final.drop(*numeric_cols, \"features\", \"scaled_features\", \"scaled_array\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO4UCj3NkiK0",
        "outputId": "41815b23-9580-4be9-fb9d-f87d033aa03c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-------------+-----------------+---------------+------------------------+----------------------+------------------------+----------------------+---------------+-------------+--------------+-------------------+---------------------+---------------------+---------------------+---------------------+-------------------------+-------------------------+---------------------------+---------------------------+---------------------+---------------------+------------------------+------------------------+------------------------+-----------------------+-----------------------+-----------------------+---------------------------+---------------------------+--------------------+--------------------+-------------------+-------------------+\n",
            "|ECO_index|Opening_index|Termination_index|Termination_ohe|Black_ELO_category_index|Black_ELO_category_ohe|White_ELO_category_index|White_ELO_category_ohe|Game_type_index|Game_type_ohe|Result_encoded| scaled_Total_moves|scaled_Black_blunders|scaled_White_blunders|scaled_Black_mistakes|scaled_White_mistakes|scaled_Black_inaccuracies|scaled_White_inaccuracies|scaled_Black_inferior_moves|scaled_White_inferior_moves|scaled_Black_ts_moves|scaled_White_ts_moves|scaled_Black_ts_blunders|scaled_White_ts_blunders|scaled_Black_ts_mistakes|scaled_White_ts_mistake|scaled_Black_long_moves|scaled_White_long_moves|scaled_Black_bad_long_moves|scaled_White_bad_long_moves|   scaled_Game_flips|scaled_Game_flips_ts| scaled_white_moves| scaled_black_moves|\n",
            "+---------+-------------+-----------------+---------------+------------------------+----------------------+------------------------+----------------------+---------------+-------------+--------------+-------------------+---------------------+---------------------+---------------------+---------------------+-------------------------+-------------------------+---------------------------+---------------------------+---------------------+---------------------+------------------------+------------------------+------------------------+-----------------------+-----------------------+-----------------------+---------------------------+---------------------------+--------------------+--------------------+-------------------+-------------------+\n",
            "|     57.0|         60.0|              1.0|  (3,[1],[1.0])|                     3.0|         (6,[3],[1.0])|                     3.0|         (6,[3],[1.0])|            0.0|(4,[0],[1.0])|             0| 0.1846590909090909|                0.125|  0.05555555555555555|                  0.0|  0.07692307692307693|      0.13043478260869565|     0.037037037037037035|        0.13725490196078433|         0.1111111111111111|  0.08163265306122448|  0.07692307692307693|                     0.0|                     0.0|                     0.0|                    0.0|    0.06060606060606061|    0.03225806451612903|        0.07142857142857142|        0.09090909090909091|  0.0963855421686747|                 0.0|0.18181818181818182|             0.1875|\n",
            "|     16.0|         80.0|              0.0|  (3,[0],[1.0])|                     0.0|         (6,[0],[1.0])|                     1.0|         (6,[1],[1.0])|            0.0|(4,[0],[1.0])|             0|0.17897727272727273|               0.0625| 0.027777777777777776|  0.03571428571428571|  0.02564102564102564|      0.30434782608695654|      0.18518518518518517|        0.19607843137254902|        0.12962962962962962|                  0.0|                  0.0|                     0.0|                     0.0|                     0.0|                    0.0|                    0.0|    0.03225806451612903|                        0.0|                        0.0| 0.07228915662650603|                 0.0|0.17613636363636365|0.18181818181818182|\n",
            "|      8.0|          1.0|              1.0|  (3,[1],[1.0])|                     2.0|         (6,[2],[1.0])|                     1.0|         (6,[1],[1.0])|            0.0|(4,[0],[1.0])|             0|0.19602272727272727|                  0.0| 0.027777777777777776|  0.03571428571428571|  0.05128205128205128|      0.34782608695652173|       0.2962962962962963|         0.1764705882352941|         0.2037037037037037|                  0.0| 0.019230769230769232|                     0.0|                     0.0|                     0.0|                    0.0|   0.030303030303030304|    0.03225806451612903|        0.07142857142857142|                        0.0|0.060240963855421686|                 0.0|0.19318181818181818|0.19886363636363638|\n",
            "|     30.0|         88.0|              0.0|  (3,[0],[1.0])|                     0.0|         (6,[0],[1.0])|                     4.0|         (6,[4],[1.0])|            0.0|(4,[0],[1.0])|             0|0.24147727272727273|                0.125|  0.05555555555555555|  0.03571428571428571|   0.1282051282051282|      0.13043478260869565|      0.14814814814814814|         0.1568627450980392|         0.2037037037037037|  0.18367346938775508|                  0.0|                     0.2|                     0.0|                     0.0|                    0.0|    0.09090909090909091|    0.03225806451612903|        0.07142857142857142|                        0.0|  0.0963855421686747|0.022727272727272728|0.23863636363636365|0.24431818181818182|\n",
            "|     85.0|         79.0|              0.0|  (3,[0],[1.0])|                     0.0|         (6,[0],[1.0])|                     4.0|         (6,[4],[1.0])|            1.0|(4,[1],[1.0])|             1|0.19886363636363638|              0.03125|                  0.0|  0.03571428571428571|  0.02564102564102564|       0.2608695652173913|      0.07407407407407407|         0.1568627450980392|        0.05555555555555555|                  0.0|                  0.0|                     0.0|                     0.0|                     0.0|                    0.0|                    0.0|                    0.0|                        0.0|                        0.0|0.024096385542168676|                 0.0|0.19886363636363638|0.19886363636363638|\n",
            "+---------+-------------+-----------------+---------------+------------------------+----------------------+------------------------+----------------------+---------------+-------------+--------------+-------------------+---------------------+---------------------+---------------------+---------------------+-------------------------+-------------------------+---------------------------+---------------------------+---------------------+---------------------+------------------------+------------------------+------------------------+-----------------------+-----------------------+-----------------------+---------------------------+---------------------------+--------------------+--------------------+-------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Afficher les données finalisées\n",
        "df_final.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjeDyr6Gg6Mt"
      },
      "outputs": [],
      "source": [
        "# TODO : Je comprend rien on va voir plus tard si ca a marché lol\n",
        "# Ajouter les colonnes OneHot mais je sais pas comment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4fIC5KrhhEm"
      },
      "source": [
        "# Questions supplémentaires"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distribution des parties nulles selon l'ouverture et le niveau\n",
        "\n",
        "- Quelles ouvertures ont une probabilité plus élevée de mener à une partie nulle ?\n",
        "- Quelle est la distribution des parties nulles en fonction de l'ouverture et des catégories ELO des joueurs ?\n",
        "\n",
        "Hypothèses :\n",
        "- Certaines ouvertures pourraient être plus susceptibles de mener à des parties nulles, par exemple des ouvertures symétriques ou très solides qui tendent à se stabiliser.\n",
        "- Les joueurs dans les catégories ELO plus élevées pourraient être plus enclins à jouer des ouvertures qui mènent à des positions équilibrées, avec une probabilité plus élevée de nulles.\n",
        "- Le niveau des joueurs pourrait avoir une influence sur les ouvertures choisies, et des catégories plus faibles (joueurs avec un ELO plus bas) pourraient avoir un taux plus faible de parties nulles, car leurs erreurs stratégiques ou tactiques peuvent rendre la partie plus dynamique et moins susceptible de se terminer par une nulle.\n",
        "- Le type d'ouverture pourrait aussi influencer le taux de parties nulles, certaines ouvertures plus complexes ou agressives entraînant plus de gains et de pertes, alors que des ouvertures plus passives pourraient mener à des parties plus équilibrées et donc à davantage de nulles."
      ],
      "metadata": {
        "id": "AAe5YswC6W_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark_null = df_spark\n",
        "# ne garder que les données où le Result est 1/2-1/2\n",
        "df_spark_null = df_spark_null.filter(col(\"Result\") == \"1/2-1/2\")"
      ],
      "metadata": {
        "id": "1aXsdA5n8Zzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution des parties nulles selon l'ouverture\n",
        "distribution_null = df_spark_null.groupBy(\"Opening\") \\\n",
        "                                        .agg(count(\"*\").alias(\"num_draws\"),\n",
        "                                             (count(\"*\") / df_spark.count()).alias(\"draw_rate\")) \\\n",
        "                                        .orderBy(col(\"draw_rate\").desc())\n"
      ],
      "metadata": {
        "id": "FhQ19nc18Zxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distribution_null.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOwcZaRD8ZvY",
        "outputId": "3f2b537f-054d-42a7-81f3-37e22cff24d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+--------------------+\n",
            "|             Opening|num_draws|           draw_rate|\n",
            "+--------------------+---------+--------------------+\n",
            "|Queen's Pawn Game...|     2459|6.575026290746647E-4|\n",
            "|         Indian Game|     1859|4.970709180357062E-4|\n",
            "|    Sicilian Defense|     1631| 4.36106867840902E-4|\n",
            "|   Caro-Kann Defense|     1552|4.149833592207725E-4|\n",
            "|    Philidor Defense|     1532|4.096356355194739E-4|\n",
            "|Scandinavian Defe...|     1440|3.850361064935002E-4|\n",
            "|French Defense: K...|     1238|3.310240971103842...|\n",
            "|        Pirc Defense|     1172|3.133766088960988...|\n",
            "|Sicilian Defense:...|     1148|3.069593404545404...|\n",
            "|         Scotch Game|     1133|3.029485476785665E-4|\n",
            "|      Modern Defense|     1132|3.026811614935016E-4|\n",
            "|   Queen's Pawn Game|     1132|3.026811614935016E-4|\n",
            "|Queen's Pawn Game...|     1112| 2.97333437792203E-4|\n",
            "|     Horwitz Defense|     1070|2.861032180194758...|\n",
            "|Sicilian Defense:...|     1007|2.692578883603852E-4|\n",
            "|Four Knights Game...|      870|2.326259810064897...|\n",
            "|French Defense: E...|      850|2.272782573051911...|\n",
            "|Van't Kruijs Opening|      831|2.221979197889574...|\n",
            "|Queen's Pawn Game...|      766|2.048178177597369...|\n",
            "|        Queen's Pawn|      746|1.994700940584383...|\n",
            "+--------------------+---------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution des parties nulles en fonction de la catégorie ELO des joueurs\n",
        "distribution_null_by_elo = distribution_null_by_elo = df_spark_null.groupBy(\"Black_ELO_category\", \"White_ELO_category\") \\\n",
        "                                    .agg(count(\"*\").alias(\"num_draws\"),\n",
        "                                         (count(\"*\") / df_spark.count()).alias(\"draw_rate\")) \\\n",
        "                                    .orderBy(col(\"draw_rate\").desc())\n"
      ],
      "metadata": {
        "id": "gk6TWC5D8Zs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distribution_null_by_elo.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khk9fiAs9HpW",
        "outputId": "02d8feaf-07f0-4815-a54d-32d2f418499e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------------+---------+--------------------+\n",
            "|Black_ELO_category|White_ELO_category|num_draws|           draw_rate|\n",
            "+------------------+------------------+---------+--------------------+\n",
            "|        Low rating|        Low rating|    67121|0.017947228127743214|\n",
            "|       High rating|       High rating|    28864|0.007717834845714161|\n",
            "|       High rating|        Low rating|     4569|0.001221687479561...|\n",
            "|        Low rating|       High rating|     4257| 0.00113826298982141|\n",
            "|         GM rating|         GM rating|     2229|5.960038065097305E-4|\n",
            "|         GM rating|       High rating|     1254|3.353022760714231...|\n",
            "|       High rating|         GM rating|     1157|3.093658161201248...|\n",
            "|         GM rating|        Low rating|       54|1.443885399350625...|\n",
            "|        Low rating|         GM rating|       43|1.149760595779202...|\n",
            "+------------------+------------------+---------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Croiser les données des ouvertures et des catégories ELO des joueurs pour analyser les probabilités de nulles\n",
        "distribution_null_by_opening_elo = df_spark_null.groupBy(\"Opening\", \"Black_ELO_category\", \"White_ELO_category\") \\\n",
        "                                           .agg(count(\"*\").alias(\"num_draws\"),\n",
        "                                                (count(\"*\") / df_spark.count()).alias(\"draw_rate\")) \\\n",
        "                                           .orderBy(col(\"draw_rate\").desc())\n"
      ],
      "metadata": {
        "id": "PcEmTS3p9HnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distribution_null_by_opening_elo.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSq56-Fq9Hks",
        "outputId": "aa5e6b5d-65f4-49b9-a225-4dc267037bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+------------------+---------+--------------------+\n",
            "|             Opening|Black_ELO_category|White_ELO_category|num_draws|           draw_rate|\n",
            "+--------------------+------------------+------------------+---------+--------------------+\n",
            "|Queen's Pawn Game...|        Low rating|        Low rating|     1878|5.021512555519399E-4|\n",
            "|    Philidor Defense|        Low rating|        Low rating|     1347|3.601691912824617E-4|\n",
            "|    Sicilian Defense|        Low rating|        Low rating|     1167|3.120396779707741...|\n",
            "|Scandinavian Defe...|        Low rating|        Low rating|     1049|2.804881081331123...|\n",
            "|   Caro-Kann Defense|        Low rating|        Low rating|     1032|2.759425429870085E-4|\n",
            "|         Scotch Game|        Low rating|        Low rating|     1008|2.695252745454502E-4|\n",
            "|         Indian Game|        Low rating|        Low rating|      999|2.671187988798658E-4|\n",
            "|French Defense: K...|        Low rating|        Low rating|      952|2.545516481818140...|\n",
            "|   Queen's Pawn Game|        Low rating|        Low rating|      893|2.387758632629831...|\n",
            "|Queen's Pawn Game...|        Low rating|        Low rating|      892|2.385084770779182E-4|\n",
            "|Sicilian Defense:...|        Low rating|        Low rating|      862|2.304868915259702...|\n",
            "|Sicilian Defense:...|        Low rating|        Low rating|      794| 2.12304630941555E-4|\n",
            "|      Modern Defense|        Low rating|        Low rating|      785|2.098981552759706...|\n",
            "|Four Knights Game...|        Low rating|        Low rating|      753|2.013417973538928...|\n",
            "|     Horwitz Defense|        Low rating|        Low rating|      738|1.973310045779188...|\n",
            "|        Pirc Defense|        Low rating|        Low rating|      722|  1.9305282561688E-4|\n",
            "|Van't Kruijs Opening|        Low rating|        Low rating|      661|1.767422683279192E-4|\n",
            "|Italian Game: Ant...|        Low rating|        Low rating|      630|1.684532965909063...|\n",
            "|         Indian Game|       High rating|       High rating|      599|1.601643248538935E-4|\n",
            "|Scandinavian Defense|        Low rating|        Low rating|      564|1.508058083766209...|\n",
            "+--------------------+------------------+------------------+---------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO COMMENTER"
      ],
      "metadata": {
        "id": "TTyxrm_C8ZoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Influence du temps passé par coup sur les erreurs\n",
        "\n",
        "- Existe-t-il une corrélation entre le temps moyen passé par coup et le nombre d'rreurs commises pendant la partie ?\n",
        "- Quelle est l'influence de cette relation en fonction du niveau des joueures et du type de jeu ?\n",
        "\n",
        "Hypothèses =\n",
        "- il est possible que les joueures prennents plus de risques lorsq'uils ont moins de temps, ce qui pourrait entraîner un plus grand nombre d'erreurs\n",
        "- Les joueurs de niveau inférieur pourraient être plus affectés par une pression temporelle (moins de temps par coup) que les joueurs de niveau supérieur.\n",
        "- Le type de jeu (par exemple, Blitz ou Rapid) pourrait avoir un impact significatif, car les parties plus rapides (Blitz) laissent moins de temps pour réfléchir, ce qui pourrait augmenter le nombre d'erreurs."
      ],
      "metadata": {
        "id": "TcLoxAnb5507"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# obligé de faire l'hypothese que les 2 joueurs mettent le meme temps (pas possible de décomposer)\n",
        "# et idem avg errors"
      ],
      "metadata": {
        "id": "GkdYNGpu7K5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : y a pas de total time ..."
      ],
      "metadata": {
        "id": "sufTv1xU-lY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculer le temps moyen par coup\n",
        "df_spark_plus = df_spark.withColumn(\"Time_per_move\", col(\"Total_time\") / col(\"Total_moves\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "fUX8YXUV5wKN",
        "outputId": "a0606f89-d772-42ce-d443-860d8a653b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `Total_time` cannot be resolved. Did you mean one of the following? [`Total_moves`, `Date`, `Game_type`, `UTCTime`, `starting_time`].;\n'Project [GAME#17, BlackElo#18, BlackRatingDiff#19, Date#20, ECO#21, Event#22, Opening#23, Result#24, Site#25, Termination#26, TimeControl#27, UTCTime#28, WhiteElo#29, WhiteRatingDiff#30, Black_elo_category#31, White_elo_category#32, starting_time#33, increment#34, Game_type#35, Total_moves#36, Black_blunders#37, White_blunders#38, Black_mistakes#39, White_mistakes#40, ... 17 more fields]\n+- Relation [GAME#17,BlackElo#18,BlackRatingDiff#19,Date#20,ECO#21,Event#22,Opening#23,Result#24,Site#25,Termination#26,TimeControl#27,UTCTime#28,WhiteElo#29,WhiteRatingDiff#30,Black_elo_category#31,White_elo_category#32,starting_time#33,increment#34,Game_type#35,Total_moves#36,Black_blunders#37,White_blunders#38,Black_mistakes#39,White_mistakes#40,... 16 more fields] csv\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-154-8cd4d94263c2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculer le temps moyen par coup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_spark_plus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time_per_move\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total_time\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total_moves\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   5174\u001b[0m                 \u001b[0mmessage_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"arg_name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"col\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"arg_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5175\u001b[0m             )\n\u001b[0;32m-> 5176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexisting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `Total_time` cannot be resolved. Did you mean one of the following? [`Total_moves`, `Date`, `Game_type`, `UTCTime`, `starting_time`].;\n'Project [GAME#17, BlackElo#18, BlackRatingDiff#19, Date#20, ECO#21, Event#22, Opening#23, Result#24, Site#25, Termination#26, TimeControl#27, UTCTime#28, WhiteElo#29, WhiteRatingDiff#30, Black_elo_category#31, White_elo_category#32, starting_time#33, increment#34, Game_type#35, Total_moves#36, Black_blunders#37, White_blunders#38, Black_mistakes#39, White_mistakes#40, ... 17 more fields]\n+- Relation [GAME#17,BlackElo#18,BlackRatingDiff#19,Date#20,ECO#21,Event#22,Opening#23,Result#24,Site#25,Termination#26,TimeControl#27,UTCTime#28,WhiteElo#29,WhiteRatingDiff#30,Black_elo_category#31,White_elo_category#32,starting_time#33,increment#34,Game_type#35,Total_moves#36,Black_blunders#37,White_blunders#38,Black_mistakes#39,White_mistakes#40,... 16 more fields] csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculer la moyenne des erreurs\n",
        "df_spark_plus = df_spark_plus.withColumn(\"Average_errors\", col(\"Black_inferior_moves\") + col(\"White_inferior_moves\"))"
      ],
      "metadata": {
        "id": "HzUmw9eT632P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculer la moyenne du temps par coup et des erreurs en fonction\n",
        "# des catégories de joueurs et du type de jeu\n",
        "from pyspark.sql.functions import col, mean\n",
        "grouped_data = df_spark_plus.groupBy(\"Black_ELO_category\", \"White_ELO_category\", \"Game_type\") \\\n",
        "    .agg(\n",
        "        mean(\"Time_per_move\").alias(\"Average_time_per_move\"),\n",
        "        mean(\"Average_errors\").alias(\"Average_errors\")\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0t_VbOET7Uxn",
        "outputId": "6cdb2356-0695-4798-a45d-e23674f5fdcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `Time_per_move` cannot be resolved. Did you mean one of the following? [`TimeControl`, `White_ts_moves`, `white_moves`, `Total_moves`, `White_long_moves`].;\n'Aggregate [Black_ELO_category#344, White_ELO_category#385, Game_type#35], [Black_ELO_category#344, White_ELO_category#385, Game_type#35, avg('Time_per_move) AS Average_time_per_move#9427, avg(Average_errors#9337) AS Average_errors#9429]\n+- Project [GAME#17, BlackElo#18, BlackRatingDiff#19, Date#20, ECO#21, Event#22, Opening#23, Result#24, Site#25, Termination#26, TimeControl#27, UTCTime#28, WhiteElo#29, WhiteRatingDiff#30, Black_ELO_category#344, White_ELO_category#385, starting_time#33, increment#34, Game_type#35, Total_moves#36, Black_blunders#37, White_blunders#38, Black_mistakes#39, White_mistakes#40, ... 20 more fields]\n   +- Filter NOT (Game_type#35 = Correspondence)\n      +- Filter NOT (Game_type#35 = Correspondence)\n         +- Project [GAME#17, BlackElo#18, BlackRatingDiff#19, Date#20, ECO#21, Event#22, Opening#23, Result#24, Site#25, Termination#26, TimeControl#27, UTCTime#28, WhiteElo#29, WhiteRatingDiff#30, Black_ELO_category#344, White_ELO_category#385, starting_time#33, increment#34, Game_type#35, Total_moves#36, Black_blunders#37, White_blunders#38, Black_mistakes#39, White_mistakes#40, ... 19 more fields]\n            +- Project [GAME#17, BlackElo#18, BlackRatingDiff#19, Date#20, ECO#21, Event#22, Opening#23, Result#24, Site#25, Termination#26, TimeControl#27, UTCTime#28, WhiteElo#29, WhiteRatingDiff#30, Black_ELO_category#344, White_ELO_category#385, starting_time#33, increment#34, Game_type#35, Total_moves#36, Black_blunders#37, White_blunders#38, Black_mistakes#39, White_mistakes#40, ... 18 more fields]\n               +- Project [GAME#17, BlackElo#18, BlackRatingDiff#19, Date#20, ECO#21, Event#22, Opening#23, Result#24, Site#25, Termination#26, TimeControl#27, UTCTime#28, WhiteElo#29, WhiteRatingDiff#30, Black_ELO_category#344, White_ELO_category#385, starting_time#33, increment#34, Game_type#35, Total_moves#36, Black_blunders#37, White_blunders#38, Black_mistakes#39, White_mistakes#40, ... 17 more fields]\n                  +- Project [GAME#17, BlackElo#18, BlackRatingDiff#19, Date#20, ECO#21, Event#22, Opening#23, Result#24, Site#25, Termination#26, TimeControl#27, UTCTime#28, WhiteElo#29, WhiteRatingDiff#30, Black_ELO_category#344, White_ELO_category#385, starting_time#33, increment#34, Game_type#35, Total_moves#36, Black_blunders#37, White_blunders#38, Black_mistakes#39, White_mistakes#40, ... 17 more fields]\n                     +- Project [GAME#17, BlackElo#18, BlackRatingDiff#19, Date#20, ECO#21, Event#22, Opening#23, Result#24, Site#25, Termination#26, TimeControl#27, UTCTime#28, WhiteElo#29, WhiteRatingDiff#30, Black_ELO_category#344, CASE WHEN ((WhiteElo#29 >= 1200) AND (WhiteElo#29 <= 1499)) THEN occasional player WHEN ((WhiteElo#29 >= 1500) AND (WhiteElo#29 <= 1799)) THEN good club player WHEN ((WhiteElo#29 >= 1800) AND (WhiteElo#29 <= 1999)) THEN very good club player WHEN ((WhiteElo#29 >= 2000) AND (WhiteElo#29 <= 2399)) THEN national and international level WHEN ((WhiteElo#29 >= 2400) AND (WhiteElo#29 <= 2800)) THEN GMI, World Champions WHEN (WhiteElo#29 < 1200) THEN other lower bound ELSE other upper bound END AS White_ELO_category#385, starting_time#33, increment#34, Game_type#35, Total_moves#36, Black_blunders#37, White_blunders#38, Black_mistakes#39, White_mistakes#40, ... 16 more fields]\n                        +- Project [GAME#17, BlackElo#18, BlackRatingDiff#19, Date#20, ECO#21, Event#22, Opening#23, Result#24, Site#25, Termination#26, TimeControl#27, UTCTime#28, WhiteElo#29, WhiteRatingDiff#30, CASE WHEN ((BlackElo#18 >= 1200) AND (BlackElo#18 <= 1499)) THEN occasional player WHEN ((BlackElo#18 >= 1500) AND (BlackElo#18 <= 1799)) THEN good club player WHEN ((BlackElo#18 >= 1800) AND (BlackElo#18 <= 1999)) THEN very good club player WHEN ((BlackElo#18 >= 2000) AND (BlackElo#18 <= 2399)) THEN national and international level WHEN ((BlackElo#18 >= 2400) AND (BlackElo#18 <= 2800)) THEN GMI, World Champions WHEN (BlackElo#18 < 1200) THEN other lower bound ELSE other upper bound END AS Black_ELO_category#344, White_elo_category#32, starting_time#33, increment#34, Game_type#35, Total_moves#36, Black_blunders#37, White_blunders#38, Black_mistakes#39, White_mistakes#40, ... 16 more fields]\n                           +- Relation [GAME#17,BlackElo#18,BlackRatingDiff#19,Date#20,ECO#21,Event#22,Opening#23,Result#24,Site#25,Termination#26,TimeControl#27,UTCTime#28,WhiteElo#29,WhiteRatingDiff#30,Black_elo_category#31,White_elo_category#32,starting_time#33,increment#34,Game_type#35,Total_moves#36,Black_blunders#37,White_blunders#38,Black_mistakes#39,White_mistakes#40,... 16 more fields] csv\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-156-66e24f4ac38e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgrouped_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_spark_plus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Black_ELO_category\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"White_ELO_category\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Game_type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     .agg(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time_per_move\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average_time_per_move\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average_errors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average_errors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/group.py\u001b[0m in \u001b[0;36magg\u001b[0;34m(self, *exprs)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexprs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"all exprs should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mexprs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mColumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexprs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexprs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexprs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `Time_per_move` cannot be resolved. Did you mean one of the following? [`TimeControl`, `White_ts_moves`, `white_moves`, `Total_moves`, `White_long_moves`].;\n'Aggregate [Black_ELO_category#344, White_ELO_category#385, Game_type#35], [Black_ELO_category#344, White_ELO_category#385, Game_type#35, avg('Time_per_move) AS Average_time_per_move#9427, avg(Average_errors#9337) AS Average_errors#9429]\n+- Project [GAME#17, BlackElo#18, BlackRatingDiff#19, Date#20, ECO#21, Event#22, Opening#23, Result#24, Site#25, Termination#26, TimeControl#27, UTCTime#28, WhiteElo#29, WhiteRatingDiff#30, Black_ELO_category#344, White_ELO_category#385, starting_time#33, increment#34, Game_type#35, Total_moves#36, Black_blunders#37, White_blunders#38, Black_mistakes#39, White_mistakes#40, ... 20 more fields]\n   +- Filter NOT (Game_type#35 = Correspondence)\n      +- Filter NOT (Game_type#35 = Correspondence)\n         +- Project [GAME#17, BlackElo#18, BlackRatingDiff#19, Date#20, ECO#21, Event#22, Opening#23, Result#24, Site#25, Termination#26, TimeControl#27, UTCTime#28, WhiteElo#29, WhiteRatingDiff#30, Black_ELO_category#344, White_ELO_category#385, starting_time#33, increment#34, Game_type#35, Total_moves#36, Black_blunders#37, White_blunders#38, Black_mistakes#39, White_mistakes#40, ... 19 more fields]\n            +- Project [GAME#17, BlackElo#18, BlackRatingDiff#19, Date#20, ECO#21, Event#22, Opening#23, Result#24, Site#25, Termination#26, TimeControl#27, UTCTime#28, WhiteElo#29, WhiteRatingDiff#30, Black_ELO_category#344, White_ELO_category#385, starting_time#33, increment#34, Game_type#35, Total_moves#36, Black_blunders#37, White_blunders#38, Black_mistakes#39, White_mistakes#40, ... 18 more fields]\n               +- Project [GAME#17, BlackElo#18, BlackRatingDiff#19, Date#20, ECO#21, Event#22, Opening#23, Result#24, Site#25, Termination#26, TimeControl#27, UTCTime#28, WhiteElo#29, WhiteRatingDiff#30, Black_ELO_category#344, White_ELO_category#385, starting_time#33, increment#34, Game_type#35, Total_moves#36, Black_blunders#37, White_blunders#38, Black_mistakes#39, White_mistakes#40, ... 17 more fields]\n                  +- Project [GAME#17, BlackElo#18, BlackRatingDiff#19, Date#20, ECO#21, Event#22, Opening#23, Result#24, Site#25, Termination#26, TimeControl#27, UTCTime#28, WhiteElo#29, WhiteRatingDiff#30, Black_ELO_category#344, White_ELO_category#385, starting_time#33, increment#34, Game_type#35, Total_moves#36, Black_blunders#37, White_blunders#38, Black_mistakes#39, White_mistakes#40, ... 17 more fields]\n                     +- Project [GAME#17, BlackElo#18, BlackRatingDiff#19, Date#20, ECO#21, Event#22, Opening#23, Result#24, Site#25, Termination#26, TimeControl#27, UTCTime#28, WhiteElo#29, WhiteRatingDiff#30, Black_ELO_category#344, CASE WHEN ((WhiteElo#29 >= 1200) AND (WhiteElo#29 <= 1499)) THEN occasional player WHEN ((WhiteElo#29 >= 1500) AND (WhiteElo#29 <= 1799)) THEN good club player WHEN ((WhiteElo#29 >= 1800) AND (WhiteElo#29 <= 1999)) THEN very good club player WHEN ((WhiteElo#29 >= 2000) AND (WhiteElo#29 <= 2399)) THEN national and international level WHEN ((WhiteElo#29 >= 2400) AND (WhiteElo#29 <= 2800)) THEN GMI, World Champions WHEN (WhiteElo#29 < 1200) THEN other lower bound ELSE other upper bound END AS White_ELO_category#385, starting_time#33, increment#34, Game_type#35, Total_moves#36, Black_blunders#37, White_blunders#38, Black_mistakes#39, White_mistakes#40, ... 16 more fields]\n                        +- Project [GAME#17, BlackElo#18, BlackRatingDiff#19, Date#20, ECO#21, Event#22, Opening#23, Result#24, Site#25, Termination#26, TimeControl#27, UTCTime#28, WhiteElo#29, WhiteRatingDiff#30, CASE WHEN ((BlackElo#18 >= 1200) AND (BlackElo#18 <= 1499)) THEN occasional player WHEN ((BlackElo#18 >= 1500) AND (BlackElo#18 <= 1799)) THEN good club player WHEN ((BlackElo#18 >= 1800) AND (BlackElo#18 <= 1999)) THEN very good club player WHEN ((BlackElo#18 >= 2000) AND (BlackElo#18 <= 2399)) THEN national and international level WHEN ((BlackElo#18 >= 2400) AND (BlackElo#18 <= 2800)) THEN GMI, World Champions WHEN (BlackElo#18 < 1200) THEN other lower bound ELSE other upper bound END AS Black_ELO_category#344, White_elo_category#32, starting_time#33, increment#34, Game_type#35, Total_moves#36, Black_blunders#37, White_blunders#38, Black_mistakes#39, White_mistakes#40, ... 16 more fields]\n                           +- Relation [GAME#17,BlackElo#18,BlackRatingDiff#19,Date#20,ECO#21,Event#22,Opening#23,Result#24,Site#25,Termination#26,TimeControl#27,UTCTime#28,WhiteElo#29,WhiteRatingDiff#30,Black_elo_category#31,White_elo_category#32,starting_time#33,increment#34,Game_type#35,Total_moves#36,Black_blunders#37,White_blunders#38,Black_mistakes#39,White_mistakes#40,... 16 more fields] csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_data.show()"
      ],
      "metadata": {
        "id": "94qN9Sb47uGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corrélation globale entre le temps moyen par coup et les erreurs\n",
        "corr_time_errors = data.stat.corr(\"TimePerMove\", \"AverageErrors\")\n",
        "print(f\"Corrélation entre le temps moyen par coup et les erreurs : {corr_time_errors}\")\n"
      ],
      "metadata": {
        "id": "wbDrRMV47qWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for row in grouped_data.collect():\n",
        "    print(f\"\\nAnalyse pour {row['Black_ELO_category']}, {row['White_ELO_category']} et {row['GameType']}:\")\n",
        "    subset = data.filter((col(\"Black_ELO_category\") == row['Black_ELO_category']) &\n",
        "                         (col(\"White_ELO_category\") == row['White_ELO_category']) &\n",
        "                         (col(\"GameType\") == row['GameType']))\n",
        "    corr_time_errors_group = subset.stat.corr(\"TimePerMove\", \"AverageErrors\")\n",
        "    print(f\"  Corrélation entre le temps moyen par coup et les erreurs : {corr_time_errors_group}\")"
      ],
      "metadata": {
        "id": "eHdjKe217ygJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGu7vG1wgku2"
      },
      "source": [
        "## Idées questions supplémentaires"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYj6SLZ1zt3K"
      },
      "source": [
        "- influence of time spent per move on errors\n",
        "  - existe t il une corrélation entre le temps moyen par coup et le nombre d'erreurs ?\n",
        "  - analyse par niveau et type de jeu\n",
        "\n",
        "- distribtion of drawn games by opening and level\n",
        "  - quelles ouvertures ont une probabilité plus élevée de conduire à une partie nulle ?\n",
        "  - analyse des taux de parties nulles en fonciton de l'ouverture et des catégories ELO\n",
        "\n",
        "- impact of ELO difference on game length\n",
        "  - les parties avec une grande différence d'ELO durent-elles moins longtemps (en nombre de coups) ?\n",
        "\n",
        "- most common mistakes by level\n",
        "  - quels types d'erreurs sont les plus fréquents selon les catégories ELO ?\n",
        "  - comparaison entre joueurs de niveau débutant et expert\n",
        "\n",
        "- optimal strategy for specific openings\n",
        "  - pour une ouverture donnée (à sélectionner manuellement), quelle est la stratégie optiale selon le niveau des joueurs ?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MoCDA5c1McJt",
        "MoOwUYVF0r4O",
        "T74gZM0NPDmJ",
        "YGmM--xUgI7N"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}